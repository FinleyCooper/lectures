#separator:tab
#html:true
#tags column:3
#deck:Lecture Notes
<b>Definition</b>: Pointwise limit<br><i>[Analysis II]</i>	We say that \( (f_n) \) converges <i>pointwise</i> if for all \( x \) in its domain we have that<br>\[<br>f(x)=\lim_{n\to\infty}f_n(x)<br>\]<br>converges. We write that \( f_n\to f \) pointwise.	Analysis_II definition Uniform_Convergence
<b>Definition</b>: Uniform convergence<br><i>[Analysis II]</i>	Let \( f_n,f: E\to \mathbb{R} \), for \( n\in\mathbb{N} \). We say that \( (f_n) \) converges <i>uniformly</i> on \( E \) if the following holds. For all \( \varepsilon>0 \), \( \exists N=N(\varepsilon) \) such that for every \( n\ge N \) and for every \( x\in E \) we have that \( |f_n(x)-f(x)|<\varepsilon \).	Analysis_II definition Uniform_Convergence
<b>Definition</b>: Uniformly Cauchy<br><i>[Analysis II]</i>	Let \( f_n:E\to \mathbb{R} \) be a sequence of functions. We say that \( (f_n) \) is <i>uniformly Cauchy</i> on \( E \) if<br>\[<br>\forall \varepsilon >0, \exists N=N(\varepsilon) \text{ s.t.\ } n,m\ge N\implies \sup_{x\in E}|f_n(x)-f_m(x)|<\varepsilon.<br>\]	Analysis_II definition Uniform_Convergence
<b>Theorem</b>: Cauchy criterion for uniform convergence<br><i>[Analysis II]</i>	Let \( (f_n) \) be a sequence of functions with \( f_n:E\to \mathbb{R} \). The \( (f_n) \) converges uniformly on \( E \) if and only if \( (f_n) \) is uniformly Cauchy on \( E \).	Analysis_II theorem Uniform_Convergence
<b>Theorem</b>: Continuity is preserved under uniform limits<br><i>[Analysis II]</i>	Let \( f_n,f:[a, b]\to \mathbb{R} \). Suppose that \( (f_n) \) converges to \( f \) uniformly on \( [a,b] \). If \( x\in [a,b] \) is such that \( f_n \) is continuous at \( x \) for all \( n\in \mathbb{N} \), then \( f \) is continuous at \( x \).	Analysis_II theorem Uniform_Convergence
<b>Corollary</b>: Uniform limits of continuous functions are continuous<br><i>[Analysis II]</i>	If \( f_n,f:[a,b]\to \mathbb{R} \), and \( f_n\to f \) uniformly on \( [a,b] \) and if \( f_n \) is continuous on \( [a,b] \) for every \( n \) then \( f \) is continuous on \( [a,b] \).	Analysis_II corollary Uniform_Convergence
<b>Theorem</b> (Uniform Convergence)<br><i>[Analysis II]</i>	Let \( (f_n) \) be a uniformly Cauchy sequence of functions in \( C([a,b]) \) the it converges to a function in \( C([a,b]) \).	Analysis_II theorem Uniform_Convergence
<b>Theorem</b>: Uniform convergence implies convergence of integrals<br><i>[Analysis II]</i>	For \( f_n,f:[a,b]\to \mathbb{R} \) be such that \( f_n,f \) are bounded and integrable on \( [a,b] \). If \( f_n\to f \) uniformly on \( [a,b] \) then<br>\[<br>\int_a^bf_n(x)\mathrm dx\to \int_a^bf(x)\mathrm dx<br>\]	Analysis_II theorem Uniform_Convergence
<b>Theorem</b> (Uniform Convergence > Differentation and uniform convergence)<br><i>[Analysis II]</i>	Let \( f_n:[a,b]\to \mathbb{R} \) be a sequence of differentiable functions (at the end points this means that the one-sided derivative exists). Suppose that:<br>\smallskip<ol><li>\( f_n'\to g \) uniformly for some function \( g:[a,b]\to \mathbb{R} \).</li><li>For some \( c\in[a,b] \) the sequence \( (f_n(c)) \) converges.</li></ol>\smallskip<br>Then \( (f_n) \) converges uniformly to some function \( f:[a,b]\to \mathbb{R} \) where \( f \) is differentiable everywhere on \( [a,b] \) and \( f'(x)=g(x) \) for all \( x\in[a,b] \).	Analysis_II theorem Uniform_Convergence
<b>Proposition</b> (Uniform Convergence > Differentation and uniform convergence)<br><i>[Analysis II]</i>	If \( f_n,g_n:E\to \mathbb{R} \) with \( f_n\to f \) uniformly on \( E \) and \( g_n\to g \) uniformly on \( E \) then \( f_n+g_n \) converges uniformly to \( f+g \) on \( E \), and if \( h:E\to \mathbb{R} \) is a bounded function then \( hf_n\to hf \) uniformly on \( E \) also.	Analysis_II proposition Uniform_Convergence
<b>Definition</b>: Convergence of a series of functions<br><i>[Analysis II]</i>	Let \( g_n: E\to \mathbb{R} \) for \( n\in\mathbb{N} \) then write<br>\[<br>f_n=\sum_{j=1}^ng_j<br>\]<br>defined pointwise. Then we say that that,<br><ol><li>The series of functions \( \sum_{n=1}^\infty g_n \) is convergent at a point \( x\in E \) if the sequence of partial sums \( (f_n(x)) \) converges.</li><li>The series of functions \( \sum_{n=1}^\infty g_n \) uniformly on \( E \) if the sequence \( (f_n) \) converges uniformly on \( E \).</li><li>\( \sum_{n=1}^\infty g_n \) converges absolutely at \( x\in E \) if the series \( \sum_{n=1}^\infty |g_n(x)| \) converges.</li><li>\( \sum_{n=1}^\infty g_n \) converges absolutely uniformly on \( E \) if \( \sum_{n=1}^\infty |g_n| \) converges uniformly on \( E \).</li></ol	Analysis_II definition Series_of_functions
<b>Proposition</b>: Absolute uniform convergence implies uniform convergence<br><i>[Analysis II]</i>	If \( g_n:E\to \mathbb{R} \) and if \( \sum_{n=1}^\infty g_n \) converges absolutely uniformly on \( E \) then \( \sum_{n=1}^\infty g_n\) converges uniformly on \( E \).	Analysis_II proposition Series_of_functions
<b>Theorem</b>: Weierstrass M-test<br><i>[Analysis II]</i>	Let  \( g_n:E\to\mathbb{R} \) be a sequence of functions and suppose that \( \exists M_n \) such that<br>\[<br>\sup_{x\in E}|g_n(x)|\le M_n<br>\]<br>and that<br>\[<br>\sum_{n=1}^\infty M_n<br>\]<br>converges. Then<br>\[<br>\sum_{n=1}^\infty g_n<br>\]<br>converges absolutely uniformly on \( E \).	Analysis_II theorem Series_of_functions
<b>Theorem</b>: Radius of convergence<br><i>[Analysis II]</i>	Let \( \sum_{n=0}^\infty c_n(x-a)^n \) be a real power series then there exists a \( R\in[0,\infty] \) called the <i>radius of convergence</i> of the power series such that<br><ol><li>If \( |x-a|<R \) then the power series converges absolutely.</li><li>If \( |x-a|>R \) then the power series diverges.</li><li>R is given by<br>\[<br>R=\frac{1}{\limsup_{n\rightarrow\infty}|c_n|^{\frac 1n}}<br>\]<br>where if the limit is zero, then \( R=\infty \).</li><li>For any \( r\in (0,R) \) we have the power series converges uniformly on \( [a-r,a+r] \), in particular the function that the power series converges to is continuous on \( (a-R,a+R) \).</li></ol	Analysis_II theorem Series_of_functions
<b>Theorem</b>: Differentation of power series<br><i>[Analysis II]</i>	Let \( \sum_{n=0}^\infty c_n(x-a)^n \) be a power series with radius of convergent \( R>0 \). Let<br>\[<br>f(x)=\sum_{n=0}^\infty c_n(x-a)^n<br>\]<br>defined on \( (a-R,a+R) \). We have the following<br><ol><li>The derived series \[<br>\sum_{n=1}^\infty nc_n(x-a)^{n-1}<br>\]<br>has radius of convergent \( R \).</li><li>\( f \) is differentiable on \( (a-R,a+R) \) with<br>\[<br>f'(x)=\sum_{n=1}^\infty nc_n(x-a)^{n-1}\quad\forall x\in(a-R,a+R)<br>\]</li></ol	Analysis_II theorem Series_of_functions
<b>Definition</b> (Series of functions > Power series)<br><i>[Analysis II]</i>	If \( (a_n) \) is a sequence of reals let<br>\[\begin{aligned}<br>p_n&= \sup\{a_m: m\ge n\}\\<br>q_n&=\inf\{a_m:m\ge n\}.<br>\end{aligned}\]<br>Then we define<br>\[\begin{aligned}<br>\limsup_{n\to\infty}a_n&=\lim_{n\to\infty}p_n\\<br>\liminf_{n\to\infty}a_n&=\lim_{n\to\infty}q_n.<br>\end{aligned}\]<br>which exists in \( \mathbb{R}\cup\{\infty\} \) since \( (q_n) \) and \( (p_n) \) are monotone.	Analysis_II definition Series_of_functions
<b>Definition</b>: Uniform continuity<br><i>[Analysis II]</i>	Let \( E\subseteq \mathbb{R} \) and let \( f:E\to \mathbb{R} \). We say that \( f \) is <i>Uniformly continuous</i> on \( E \) if \( \forall \varepsilon>0 \) there exists a \( \delta>0 \) such that \( \forall x,y\in E \) we have that<br>\[<br>|x-y|<\delta\implies |f(x)-f(y)|<\varepsilon<br>\]	Analysis_II definition Uniform_continuity_and_Riemann_integrability
<b>Theorem</b> (Uniform continuity and Riemann integrability > Uniform continuity)<br><i>[Analysis II]</i>	Let \( [a,b] \) be a closed, bounded interval and \( f:[a,b]\to \mathbb{R} \) a continuous function. Then \( f \) is uniformly continuous.	Analysis_II theorem Uniform_continuity_and_Riemann_integrability
<b>Theorem</b> (Uniform continuity and Riemann integrability > Uniform continuity)<br><i>[Analysis II]</i>	Let \( f:[a,b]\to \mathbb{R} \) where \( -\infty<a<b<\infty \) be any function. Suppose that there is a collection \( \mathcal C \) of open intevals \( I\subseteq \mathbb{R} \) such that if<br>\[<br>F=[a,b]\setminus\bigcup_{I\in\mathcal C}I<br>\]<br>then \( f \) is continuous at every point in \( F \) (i.e. the set of discontinuities is contained in the union). Then \( \forall \varepsilon>0 \exists\delta>0\text{ s.t.\ } \) \( x\in F,y\in [a,b] \), with \( |x-y|<\delta \implies |f(x)-f(y)|<\varepsilon \).	Analysis_II theorem Uniform_continuity_and_Riemann_integrability
<b>Theorem</b>: Riemann criterion for integrability<br><i>[Analysis II]</i>	For \( f:[a,b]\to \mathbb{R} \) bounded, \( f \) is integrable if and only if for all \( \varepsilon>0 \) there exists a partition \( P \) of \( [a,b] \) such that<br>\[<br>U(P,f)-L(P,f)<\varepsilon<br>\]	Analysis_II theorem Uniform_continuity_and_Riemann_integrability
<b>Theorem</b> (Uniform continuity and Riemann integrability > Riemann Integration)<br><i>[Analysis II]</i>	Let \( f:[a,b]\to[A,B] \) be integrable and \( g:[A,B]\to\mathbb{R} \) continuous. Then the composite function \( g\circ f:[a,b]\to\mathbb{R} \) is integrable.	Analysis_II theorem Uniform_continuity_and_Riemann_integrability
<b>Corollary</b> (Uniform continuity and Riemann integrability > Riemann Integration)<br><i>[Analysis II]</i>	If \( f \) is continuous then it is integrable	Analysis_II corollary Uniform_continuity_and_Riemann_integrability
<b>Theorem</b>: Uniform limits of integrable functions are integrable<br><i>[Analysis II]</i>	Suppose we have \( f_n:[a,b]\to\mathbb{R} \) be a sequence of Riemann integrable functions and \( f_n\to f \) uniformly. Then \( f \) is bounded, Riemann integrable and<br>\[<br>\int_a^bf_n\to \int_a^bf<br>\]	Analysis_II theorem Uniform_continuity_and_Riemann_integrability
<b>Definition</b>: Null set<br><i>[Analysis II]</i>	A subset \( \mathcal R\subseteq \mathbb{R} \) is said to be a <i>null set</i> (or a set of <i>Lebesgue measure zero</i>) if \( \forall\varepsilon>0 \) there exists an at most countable collection of open intevals \( I_j=(a_i,b_i) \) such that<br>\[<br>\mathcal D\subseteq \bigcup_{i=1}^nI_i<br>\]<br>and<br>\[<br>\sum_{j=1}^\infty|I_j|\le \varepsilon<br>\]<br>where \( |I_j|=b_j-a_j \).	Analysis_II definition Uniform_continuity_and_Riemann_integrability
<b>Theorem</b>: Lebesgue's theorem on the Riemann integral<br><i>[Analysis II]</i>	Let \( f:[a,b]\to\mathbb{R} \) bounded. Then \( f \) is Riemann integrable if and only if \( \mathcal D_f \) is a null set.	Analysis_II theorem Uniform_continuity_and_Riemann_integrability
<b>Corollary</b> (Uniform continuity and Riemann integrability > Riemann Integration)<br><i>[Analysis II]</i>	If \( f :[a,b]\to \mathbb{R} \) is integrable, then \( |f| \) is integrable on \( [a,b] \). Moreover<br>\[<br>\int_a^b|f|=0\iff f=0\ \text{except on a null set}<br>\]<br>So there exists a null set \( N\subseteq [a,b] \) such that \( f(x)=0 \) for all \( x\in [a,b]\setminus N \). We say that \( f=0 \) <i>almost everywhere</i> on \( [a,b] \).	Analysis_II corollary Uniform_continuity_and_Riemann_integrability
<b>Definition</b>: Metric Space<br><i>[Analysis II]</i>	Let \( X \) be any set. A <i>metric</i> (or distance function) on \( X \) is a function, \( d:X\times X\to \mathbb{R} \) satisfying the following for any \( x,y,z\in X \),<br><ol><li>\( d(x,y)\ge 0 \) and \( d(x,y)=0\iff x=y \);</li><li>\( d(x,y)=d(y,x) \);</li><li>\( d(x,y)\le d(x,z) + d(z,y) \).</li></ol><br>We call such a pair \( (X,d) \) a <i>metric space</i>.	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Normed Space<br><i>[Analysis II]</i>	Let \( V \) be a real vector space. A <i>norm</i> on \( V \) is a function \( ||\cdot ||: V\to \mathbb{R} \) satisfying for any \( x,y\in V \), and any \( \lambda \in\mathbb{R} \),<br><ol><li>\( ||x||\ge 0 \) and \( ||x||=0\iff x=0 \);</li><li>\( ||\lambda x||=|\lambda|\cdot||x||\);</li><li>\( ||x+y||\le ||x||+||y|| \).</li></ol><br>We say that \( (V,||\cdot ||) \) is a <i>normed space</i>.	Analysis_II definition Metric_and_Normed_Spaces
<b>Proposition</b> (Metric and Normed Spaces)<br><i>[Analysis II]</i>	If \( (V,||\cdot||) \) is a normed space, and if \( d:V\times V\to \mathbb{R} \) is defined by \( d(x,y)=||x-y|| \), then \( (V,d) \) is a metric space.	Analysis_II proposition Metric_and_Normed_Spaces
<b>Definition</b>: Metric subspaces<br><i>[Analysis II]</i>	If \( (X,d) \) is a metric space, let \( Y\subseteq X \) be any subset. Then the restriction<br>\[<br>d\mid_{Y\times Y}:Y\times Y\to \mathbb{R}<br>\]<br>is a metric on \( Y \) called the <i>induced metric</i> or the <i>subset metric</i>.	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Open ball<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. Then for any \( a\in X \) and any \( r>0 \). The <i>open ball</i> with radius \( r \) and centre \( a \) is the set<br>\[<br>B_r(a)=\{x\in X:d(x,a)<r\}.<br>\]<br>This is our abstraction of \( \varepsilon \)-neighbourhoods on \( \mathbb{R} \) for general metric spaces.	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Open set<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. Then a subset \( U\subseteq X \) is <i>open</i> if for all \( a\in U \) there exists a radius \( r>0 \) such that \( B_r(a)\subseteq U \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Closed set<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. Then a subset \( E\subseteq X \) is <i>closed</i> if \( X\setminus E \) is open.	Analysis_II definition Metric_and_Normed_Spaces
<b>Proposition</b> (Metric and Normed Spaces > Open and closed subsets)<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. Then<br><ol><li>Any open ball \( B_r(a) \) is an open set;</li><li>Any singleton \( \{x\} \), \( x\in X \) is closed.</li></ol	Analysis_II proposition Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Open and closed subsets)<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. We have the following,<br><ol><li>The union of any (possibly uncountable) collection of open set is open.</li><li>The intersection of any finite collection of open sets is open.</li><li>The empty set, \( \emptyset \), and the whole set, \( X \), are both open.</li></ol	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Open and closed subsets)<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. We have the following,<br><ol><li>The intersection of any (possibly uncountable) collection of closed sets is closed.</li><li>The union of any finite collection of closed sets is closed.</li><li>The empty set, \( \emptyset \), and the whole set, \( X \), are both closed.</li></ol	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Convergence of sequences in metric spaces<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. A sequence \( (x_k) \) in \( X \) is said to converge to a point \( x\in X \) if \( d(x_k,x)\to 0 \) as \( k\to\infty \). So \( \forall \varepsilon>0 \), \( \exists N \) such that \( k>N\implies d(x_k,x)<\varepsilon \iff x_k\in B_\varepsilon(x) \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Proposition</b>: Uniquness of the limits<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space, and \( (x_k) \) be a sequence in \( X \) with \( x_k\to x \) and \( x_k\to y \), then \( x=y \).	Analysis_II proposition Metric_and_Normed_Spaces
<b>Proposition</b>: Convergence in $ \mathbb{R}^n $ with the $ \ell_2 $ norm<br><i>[Analysis II]</i>	Convergence in \( \mathbb{R}^n \) with respect to the Euclidean norm is equivalent to the convergence of the coordinates (as real numbers). Formally, if \( x^{(k)}=\left(x^{(k)}_1,\dots, x^{(k)}_n\right) \) is a sequence in \( \mathbb{R}^n \) with \( k\in \mathbb{N} \), and \( x=(x_1,\dots, x_n)\in \mathbb{R}^n \), then<br>\[<br>x^{(k)}\to x\ \text{in}\ ||\cdot||_2\iff x^{(k)}_j\to x_j\ \forallj\in \{1,2,\dots, n\}.<br>\]	Analysis_II proposition Metric_and_Normed_Spaces
<b>Definition</b>: Bounded subset<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. A subset \( E\subseteq X \) is <i>bounded</i> if \( E\subseteq B_R(a) \) for some \( a\in X \) and some \( R>0 \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Theorem</b>: Bolzano-Weierstrass in $ \mathbb{R}^n $<br><i>[Analysis II]</i>	Every bounded sequence in \( \mathbb{R}^n \) with respect to the Euclidean metric has a convergent subsequence.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Limit point<br><i>[Analysis II]</i>	If \( (X,d) \) is a metric space and we have a subset \( E\subseteq X \) and a point \( x\in X \), then say that \( x \) is a <i>limit point</i> of \( E \) if there is a sequence \( (x_k)\in E \) with \( x_k\ne x \) for all \( k \) and \( x_k\to x \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Isolated point<br><i>[Analysis II]</i>	If \( (X,d) \) is a metric space and we have a subset \( E\subseteq X \) then \( x\in E \) is a <i>isolated point</i> of \( E \) if \( x\in E \) and \( x \) is not a limit point of \( E \). Equivalently there exists a \( r>0 \) such that \( E\cap B_r(x)=\{x\} \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Closure<br><i>[Analysis II]</i>	If \( (X,d) \) is a metric space and we have a subset \( E\subseteq X \) then the <i>closure</i> of \( E \) denoted as \( \bar E \) is the union of \( E \) and all of its limit points. (i.e. it's all the points which are the limit of some sequence in \( E \).)	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Interior point<br><i>[Analysis II]</i>	If \( (X,d) \) is a metric space and we have a subset \( E\subseteq X \) then \( x\in X \) is a <i>interior point</i> if there exists a \( r>0 \) such that<br>\[<br>B_r(x)\subseteq E.<br>\]	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Interior<br><i>[Analysis II]</i>	If \( (X,d) \) is a metric space and we have a subset \( E\subseteq X \) then the <i>interior</i> of \( E \) denoted as \( \mathring E \) is the set of interior points of \( E \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Proposition</b> (Metric and Normed Spaces > Open and closed subsets)<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. For any \( E\subseteq X \), the \( \bar E \) is a closed set and in fact<br>\[<br>\bar E=\bigcap_{\substack{E\subseteq F\\ F \text{closed}}}F<br>\]	Analysis_II proposition Metric_and_Normed_Spaces
<b>Proposition</b> (Metric and Normed Spaces > Open and closed subsets)<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space and let \( E\subseteq X \). Then the following statements are equivalent,<br><ol><li>If \( (x_k) \) is a sequence in \( E \) with \( (x_k)\to x \in X \), then \( x\in E \);</li><li>\( E=\bar E \);</li><li>\( E \) is closed in \( X \).</li></ol	Analysis_II proposition Metric_and_Normed_Spaces
<b>Definition</b>: Cauchy sequence<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. A sequence \( (x_n) \) in \( X \) is a <i>Cauchy sequence</i> if<br>\[<br>(\forall\varepsilon)(\exists N)(\forall n,m\ge N)\ d(x_n,x_m)<\varepsilon.<br>\]	Analysis_II definition Metric_and_Normed_Spaces
<b>Proposition</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. Then we have the following,<br><ol><li>Any convergent sequence is Cauchy;</li><li>Any Cauchy sequence is bounded;</li><li>If \( (x_k) \) is a Cauchy sequence that has a convergent subsequence, converging to \( x\in X \), then the whole sequence convergence to \( x \).</li></ol	Analysis_II proposition Metric_and_Normed_Spaces
<b>Definition</b>: Complete metric space<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. We say that \( X \) is a <i>complete metric space</i> if every Cauchy sequence in \( X \) converges to some element in \( X \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Complete normed space<br><i>[Analysis II]</i>	A normed space \( (V,||\cdot ||) \) is <i>complete</i> if \( V \) with the metric defined by \( ||\cdot || \) is complete.	Analysis_II definition Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	\( (\mathbb{R}^n, ||\cdot||_2) \) is complete.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	Any finite dimensional normed space is complete.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	The metric space \( (C[a,b],||\cdot ||_\infty) \) is complete.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	The metric spaces \( (\ell_1, ||\cdot ||_1) \), \( (\ell_2, ||\cdot ||_2) \), and \( (\ell_\infty ||\cdot ||_\infty) \) are complete.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	Let \( (X,d) \) be a complete metric space, and \( Y\subseteq X \) any subset. Then \( (Y,d|_Y) \) is complete if and only if \( Y \) is closed.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	If \( V \) is a finite dimensional real vector space and if \( ||\cdot || \), \( ||\cdot ||' \) are two norms on \( V \) then \( ||\cdot ||,||\cdot ||' \) are <i>Lipchitz-equivalent</i> (i.e there are constants \( C_1,C_2 >0\) such that<br>\[<br>C||x||'\le ||x||\le C||x||'<br>\]<br>for all \( x\in V\).	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Sequential Compactness<br><i>[Analysis II]</i>	A metric space \( (X,d) \) is <i>sequentially compact</i> if every sequence \( (x_n) \) is the space has a convergent subsequence, \( x_{k_j}\to x \). A subset \( K\subseteq X \) is sequentially compact if \((K,d) \) is sequentially compact.	Analysis_II definition Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	A subset \( S\subseteq \mathbb{R}^n \) is compact if and only if it is closed and bounded.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	If \( (X,d) \) is compact, then \( (X,d) \) is bounded and complete.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	If \( K\subseteq X \) is a compact subset of a metric space \( X \), then \( K \) is closed and bounded.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	\( K\subseteq \mathbb{R}^n \) with the Euclidean metric is compact if and only if \( K \) is closed and bounded.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Totally bounded<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. We say that \( (X,d) \) is <i>totally bounded</i> if for every \( \varepsilon>0 \) there is a finite set \( \{x_1,\dots, x_n\}\in X \) such that<br>\[<br>X\subseteq \bigcup_{j=1}^B_\varepsilon(x_j).<br>\]	Analysis_II definition Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Cauchy sequences and completeness)<br><i>[Analysis II]</i>	\( (X,d) \) is compact if and only if \( (X,d) \) is complete and totally bounded.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Continuous<br><i>[Analysis II]</i>	Let \( (X,d) \), \( (X',d') \) be metric spaces, and suppose we have a function \( f:X\to X' \). We say that \( f \) is <i>conmtinuous</i> at \( x\in X \) if \( \forall\varepsilon>0 \) there exists a \( \delta>0 \) such that<br>\[<br>d(y,x)<\delta \implies d'(f(y),f(x))<\varepsilon.<br>\]<br>Equivalently we have that \( \forall\varepsilon>0,\ \exists \delta>0 \) such that \( f(B_\delta(x))\subseteq B_\varepsilon(f(x)) \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Theorem</b>: Sequential definition of continuity<br><i>[Analysis II]</i>	Let \( f:X\to X' \). Then \( f \) is continuous at \( x \) if and only if for every sequence \( x_n\to x \) we have that \( f(x_n)\to f(x) \).	Analysis_II theorem Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Continuous mappings between metric spaces)<br><i>[Analysis II]</i>	Let \( (X,d) \) and \( (X',d') \) be metric spaces. Then the following are equivalent.<br><ol><li>\( f \) is continuous;</li><li>For every sequence \( x_n\to x \), \( f(x_n)\to f(x) \);</li><li>\( \inv f(v)=\{x\in X:f(x)\in V\} \) is open in \( X \) for every open \( V\subseteq X' \).</li></ol	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Uniformly continuous<br><i>[Analysis II]</i>	Let \( f:X\to X' \). We say that \( f \) is <i>uniformly continuous</i> if there exists some \( \varepsilon>0 \) such that there exists \( \delta>0 \) with \( \forall x,y\in X \)<br>\[<br>d(x,y)<\delta\implies d'(f(x),f(y))<\varepsilon.<br>\]<br>Equivalently \( B_\delta(x)\subseteq \inv f(B_\varepsilon(f(x))) \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b> (Metric and Normed Spaces > Continuous mappings between metric spaces)<br><i>[Analysis II]</i>	We say that \( f:X\to X' \) is Lipschitz if there exists an \( L \) such that \( \forall x,y\in X \),<br>\[<br>d'(f(x),f(y))\le Ld(x,y).<br>\]	Analysis_II definition Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Continuous mappings between metric spaces)<br><i>[Analysis II]</i>	If \( f:X\to X' \) is continuous, and \( (X,d) \) is compact and \( (X',d') \) is any metric space then,<br><ol><li>\( f \) is uniformly continuous;</li><li>\( f(X) \) is a compact subspace of \( X' \);</li><li>\( f(X) \) is closed and bounded;</li><li>If \( X'=\mathbb{R} \), and \( d' \) is the Euclidean metric, then \( f \) attains its supremum and infimum.</li></ol	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Topology<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. The <i>topology</i> on \( X \) induced by \( d \) is the collection of open subsets of \( X \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Topologically equivalent<br><i>[Analysis II]</i>	Two metrics \( d,d' \) on \( X \) are <i>topologically equivalent</i> if they induce the same topology. So \( U\subseteq X \) is open with resepct to \( d \) if and only if \( U \) is open with resepct to \( d' \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b>: Lipschitz equivalent<br><i>[Analysis II]</i>	Two metrices \( d,d' \) on \( X \) are <i>lipschitz equivalent</i> if there exists fixed \( a,b>0 \) such that<br>\[<br>ad(x,y)\le d'(x,y)\le bd(x,y)<br>\]<br>for all \( x,y\in X \).	Analysis_II definition Metric_and_Normed_Spaces
<b>Definition</b> (Metric and Normed Spaces > Equivalence of metrics and norms)<br><i>[Analysis II]</i>	The norms \( ||\cdot ||' \) on a vector space \( V \) are Lipschitz equivalent if there are \( a,b>0 \) such that<br>\[<br>a||x||\le ||x||'\le b||x||\quad\forall x\in V<br>\]	Analysis_II definition Metric_and_Normed_Spaces
<b>Proposition</b> (Metric and Normed Spaces > Equivalence of metrics and norms)<br><i>[Analysis II]</i>	\( ||\cdot|| \) and \( ||\cdot ||' \) are Lipschitz equiavelnt if and only if there exists \( r,R>0 \) such that<br>\[<br>B^{||\cdot ||}_r(0)\subseteq B_1^{||\cdot||'}(0)\subseteq B_R^{||\cdot ||}(0)<br>\]	Analysis_II proposition Metric_and_Normed_Spaces
<b>Theorem</b> (Metric and Normed Spaces > Equivalence of metrics and norms)<br><i>[Analysis II]</i>	Any two norms on a finite dimensional real vector space \( V \) are Lipschitz equivalent.	Analysis_II theorem Metric_and_Normed_Spaces
<b>Definition</b>: Limit<br><i>[Analysis II]</i>	Let \( E\subseteq \mathbb{R}^n \), let \( a\in \mathbb{R}^n \) be a limit point of \( E \). If \( f:E\to \mathbb{R}^m \) and \( b\in \mathbb{R}^m \). Then<br>\[<br>\lim_{x\to a}f(x)=b<br>\]<br>means that \( \forall \varepsilon>0 \) there exists \( \delta>0 \) such that \( x\in E \) with \( 0<||x-a||<\delta \implies ||f(x)-b||<\varepsilon\).	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Definition</b>: Differentiable<br><i>[Analysis II]</i>	Let \( U\subseteq \mathbb{R}^n \) be open and let \( f:U\to \mathbb{R}^m \) and let \( a\in U \). Then we say that \( f \) is <i>differentiable</i> at \( a \) if there is a linear map \( A:\mathbb{R}^n\to\mathbb{R}^m \) such that<br>\[<br>\lim_{h\to 0}\frac{f(a+h)-f(a)-Ah}{||h||}=0.<br>\]<br>We say that \( A \) is the derivative of \( f \) at \( a \) and write \( A=Df(a) \).	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Proposition</b> (Differentiation in $ \R^n $)<br><i>[Analysis II]</i>	Let \( U\subseteq \mathbb{R}^n \) be open and \( f:U\to \mathbb{R}^m \).<br><ol><li>If \( f \) is differentiable at \( a\in U \), then \( Df(a) \) is unique.</li><li>If \( f \) is differentiable at \( a\in U \), then \( f \) is continuous at \( a \).</li><li>Write \( f = (f_1,f_2,\dots, f_m) \), where \( f_j:U\to \mathbb{R} \), then \( f \) is differentiable at \( a\in U \) if and only if \( f_j \) is differentiable at \( a \) and<br>\[<br>Df(a)=\begin{pmatrix}<br>Df_1(a) \\<br>\vdots \\<br>Df_m(a)<br>\end{pmatrix}<br>\].</li></ol	Analysis_II proposition Differentiation_in_$_\R^n_$
<b>Definition</b>: Directional derivative<br><i>[Analysis II]</i>	Let \( f:U\to \mathbb{R}^m \) with \( U\subseteq \mathbb{R}^n \) open. Let \( a\in U\). The <i>directional derivative</i> of \( f \) at \( a \) in the direction of \( u \) (where \( u\in \mathbb{R}^n \) is fixed), is<br>\[<br>D_uf(a)=\lim_{t\to 0}\frac{f(a+tu)-f(a)}t<br>\]<br>if the limit exists.	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Proposition</b> (Differentiation in $ \R^n $ > Directional Derivatives)<br><i>[Analysis II]</i>	If \( f \) is differentiable at \( a\in U \), then for any \( u\in \mathbb{R}^n \), the directional derivative \( D_uf(a) \) exists and is equal to \( Df(a)u \). In particular the map \( u\to D_uf(a) \) is linear.	Analysis_II proposition Differentiation_in_$_\R^n_$
<b>Proposition</b> (Differentiation in $ \R^n $ > Directional Derivatives)<br><i>[Analysis II]</i>	If \( U\subseteq \mathbb{R}^n \) is open and \( f:U\to \mathbb{R}^m \), is differentiable at \( a\in U \) then the partial derivatives \( D_jf_i(a) \) all exist and the matrix for \( Df(a) \) is given by \( A=(D_jf_i(a)) \).	Analysis_II proposition Differentiation_in_$_\R^n_$
<b>Theorem</b>: Continuity of partial derivatives guarantees differentiability<br><i>[Analysis II]</i>	Let \( f: U \to \mathbb{R}^m \) with \( U\subseteq \mathbb{R}^n \) open. Let \( a\in U \) and suppose that for some \( B_r(a)\in U \) the partial derivatives \( D_jf_i(x) \) exist for every \( x\in B_r(a) \). Suppose also that \( D_jf_i \) is continuous at \( a \) for every \( 1\le i \le n \) and \( 1\le j \le n \). Then \( f \) is differentiable at \( a \).	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Definition</b>: Operator norm on $ \mathcal L(\mathbb{R}^n,\mathbb{R}^m<br><i>[Analysis II]</i>	\() For \) A\in \mathcal L(\mathbb{R}^n,\mathbb{R}^m) $ and define<br>\[<br>||A||_{\text{op}}=\sup_{|x|=1}||A(x)||=\sup_{x\in \mathbb{R}^n, x\ne 0}\frac{||A(x)||}{||x||}.<br>\]	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Proposition</b> (Differentiation in $ \R^n $ > Directional Derivatives)<br><i>[Analysis II]</i>	For the operator norm,<br><ol><li>If \( A\in \mathcal L(\mathbb{R},\mathbb{R}^m) \) then \( A(x)=xa \) for some fixed \( a\in\mathbb{R}^m \). In this case \( ||A||_{\text{op}}=||a||_2 \).</li><li>If \( A\in \mathcal L(\mathbb{R}^n,\mathbb{R}) \) then \( A(x)= x\cdot a \) for some fixed \( a\in\mathbb{R}^n \) and \( ||A||_{\text{op}}=||a||_2 \).</li><li>If \((A_{ij})  \) is the matrix of \( A\in\mathcal L(\mathbb{R}^n,\mathbb{R}^m) \) with respect to the standard basis for \( \mathbb{R}^n \) and \( \mathbb{R}^m \) then we have that<br>\[<br>\frac1{\sqrt n}\left(\sum A^2_{ij}\right)\le ||A||_{\text{op}}\le \left(\sum A^2_{ij}\right)^{1/2}.<br>\]</li></ol	Analysis_II proposition Differentiation_in_$_\R^n_$
<b>Theorem</b> (Differentiation in $ \R^n $ > Directional Derivatives)<br><i>[Analysis II]</i>	Let \( U\subseteq \mathbb{R}^n \) be open and \( f:U\to \mathbb{R}^m \) and \( a\in U \). Assume that \( f \) is differentiable at \( a \). Let \( V\subseteq \mathbb{R}^m \) be open, with \( f(U)\subseteq V \), \( g:V\to \mathbb{R}^p \) and suppose that \( g \) is differentiable at \( f(a) \). Then \( g\circ f: U\to \mathbb{R}^p \) is differentiable at \( a \) and moreover,<br>\[<br>D(g\circ f)(a)=Dg(f(a))\circ Df(a).<br>\]	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Theorem</b>: Mean value inequality<br><i>[Analysis II]</i>	Let \( f:[a,b]\to \mathbb{R}^m \) be continuous and assume that \( f \) is differentiable on \( (a,b) \). Suppose that \( ||Df(a)||_{\text{op}} \le M\) for some constant \( M \) and all \( t\in (a,b) \). Then<br>\[<br>||f(b)-f(a)||\le M(b-a).<br>\]	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Theorem</b> (Differentiation in $ \R^n $ > Directional Derivatives)<br><i>[Analysis II]</i>	Let \( B_r(a)\subseteq \mathbb{R}^n \), \( f:B_r(a)\to \mathbb{R}^m \) and suppoes that \( f \) is differentiable at \( x \) for each \( x\in B_r(a) \). Suppose further that \( ||Df(x)||_{\text{op}}\le M \). Then for any \( b_1,b_2\in B_r(a) \) we have that<br>\[<br>||f(b_2)-f(b_1)||\le M||b_2-b_1||.<br>\]	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Corollary</b> (Differentiation in $ \R^n $ > Directional Derivatives)<br><i>[Analysis II]</i>	If a function as in the theorem has derivative zero on the ball then it is constant on the ball.	Analysis_II corollary Differentiation_in_$_\R^n_$
<b>Definition</b>: Path connected<br><i>[Analysis II]</i>	A subset \( E\subseteq \mathbb{R}^n \) is <i>path connected</i> if for any two points \( a,b\in E \) then there is a continuous function \( \gamma:[0,1]\to E \) such that \( \gamma(0)=a \) and \( \gamma(1)=b \).	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Theorem</b> (Differentiation in $ \R^n $ > Directional Derivatives)<br><i>[Analysis II]</i>	Let \( U\subseteq R^n \) be open and path connected. If \( f:U\to \mathbb{R}^m \) is differentiable with \( Df(x)=0 \) for all \( x\in U \), then \( f \) is constant.	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Definition</b>: $ C^1 $ function<br><i>[Analysis II]</i>	A function \( f:U\to \mathbb{R} \), \( U\subseteq \mathbb{R}^n \) is said to be \( C^1 \) on \( U \) if all partial derivatives \( D_jf=\frac{tial f}{tial x_j} \) exist and are continuous on \( U \).	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Theorem</b> (Differentiation in $ \R^n $ > The second derivative)<br><i>[Analysis II]</i>	Let \( f:U\to \mathbb{R} \), \( U\subseteq \mathbb{R}^n \) open and \( a\in U \) and \( B_r(a)\subseteq U \). Fix \( i,j \) and assume that the partial derivatives \( D_iD_jf(x), D_jD_if(x)\) exist for all \( x\in B_r(a) \) and are continuous at \( x=a \). Then we have that<br>\[<br>D_iD_jf(a)=D_jD_if(a).<br>\]	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Definition</b> (Differentiation in $ \R^n $ > The second derivative)<br><i>[Analysis II]</i>	Suppose that \( Df \) is differentiable at \( a \). Define \( D^2f(a):\mathbb{R}^n\times \mathbb{R}^n\to \mathbb{R}^m \) by \( D^2f(a)(u,v)=D(Df)(a)(u)(v) \).	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Theorem</b> (Differentiation in $ \R^n $ > The second derivative)<br><i>[Analysis II]</i>	Suppose \( f \) is \( C^2 \) on \( U \). Then \( D^2f(a) \) exists and is a symmetric bilinear map. Moreover for \( u= \sum_{i=1}^n u_ie_i, v=\sum_{i=1}^n v_ie_i \), where \( \{e_i\}_{i=1}^n \) is the standard basis for \( \mathbb{R}^n \), we have that<br>\[<br>D^2f(a)(u,v)=\left(\sum_{j=1}^n\sum_{i=1}^n D_{ij}f_k(a)u_iv_j\right)_{1\le k \le m}\in \mathbb{R}^m.<br>\]	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Definition</b>: Positive definite<br><i>[Analysis II]</i>	A quadratic map is said to be <i>positive definite</i> if \( Q(u)>0 \) for all \( u\in \mathbb{R}^n\setminus \{0\} \). If \( Q(u)\ge 0 \) for all \( u\in \mathbb{R}^n \) we say that \( Q \) is positive semi-definite. Similarly we can define negative definite and negative semi-definite.	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Definition</b> (Differentiation in $ \R^n $ > The second derivative)<br><i>[Analysis II]</i>	Let \( f:U\to \mathbb{R} \) be \( C^2 \) and let \( a\in U \),<br><ol><li>The point \( a \) is a <i>critical point</i> of \( f \) is \( Df(a)=0 \).</li><li>\( f \) has a <i>local minimum</i> at \( x=a \) if \( \exists r>0 \) such that \( f(x)\ge f(a) \) for all \( x\in B_r(a) \).</li><li>\( f \) has a <i>strict local minimum</i> at \( x=a \) if \( \exists r>0 \) such that \( f(x)>f(a) \) for all \( x\in B_r(a)\setminus \{a\} \).</li><li>Similarly we define <i>local maximum</i> and <i>strict local maximum</i>.</li></ol	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Theorem</b> (Differentiation in $ \R^n $ > The second derivative)<br><i>[Analysis II]</i>	Let \( f:U\to \mathbb{R} \) with \( U\subseteq \mathbb{R}^n \) open be a \( C^2 \) function. Let \( a\in U \). THen<br><ol><li>\( f(a+h)=f(a)=Df(a)h+\frac 12D^2f(a)(h,h)  +E(h)\), with \( E(h)=o(||h||^2) \).</li><li>\begin{enumerate}</li><li>If \( x=a \) is a critical point of \( f \) and \( H_{f,a}(h)=D^2f(a)(h,h) \) is positive definite, then \( f \) has a strict local minimum at \( a \).</li><li>If \( x=a \) is a critical point of \( f \) and \( H_{f,a}(h)=D^2f(a)(h,h) \) is negative definite, then \( f \) has a strict local maximum at \( a \).</li><li>If \( f \) has a local minimum (respectively local maximum), then \( Df(a)=0 \) and \( H_{f,a}(h) \) is positive (respectively negative) semi-definite.</li></ol><br>\end{enumerate}	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Definition</b>: Contraction mapping<br><i>[Analysis II]</i>	Let \( (X,d) \) be a metric space. A <i>contraction mapping</i> is a function \( f:X\to X \) such that there exists a \( \lambda \) with \( 0\le \lambda < 1 \) such that \( d(f(x),f(y))\le \lambda d(x,y) \), for all \( x,y\in X \).	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Theorem</b>: Contraction mapping theorem<br><i>[Analysis II]</i>	If \( (X,d) \) is a non-empty, complete metric space and if \( f \) is a contractionm mapping, then \( f \) has a unique fixed point \( x\in X \).	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Definition</b>: Diffeomorphism<br><i>[Analysis II]</i>	A function \( f \) is a <i>diffeomorphism</i> if it is a bijection which is \( C^1 \) with a \( C^1 \) inverse.	Analysis_II definition Differentiation_in_$_\R^n_$
<b>Theorem</b>: Inverse function theorem<br><i>[Analysis II]</i>	Let \( U\subseteq \mathbb{R}^n \) be open and let \( f:U\to \mathbb{R}^n \) be a \( C^1 \) map. Let \( a\in U \) and suppose that \( Df(a)\in \mathcal L(\mathbb{R}^n,\mathbb{R}^n) \) is invertible. Then there exists an open set \( V \subseteq U \) with \( a\in V \), and an open set \( W\subseteq \mathbb{R}^n \) such that \( f|_V:V\to W \) is a diffeomorphism.	Analysis_II theorem Differentiation_in_$_\R^n_$
<b>Definition</b>: Open disc<br><i>[Complex Analysis]</i>	An <i>open disc</i> or <i>open ball</i> centred at \( a \) with radius \( r \) in \( \mathbb{C} \) is the set \( \{z\in \mathbb{C}\mid |z-a|<r\}  = B(a,r)= D(a,r)\).	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Path<br><i>[Complex Analysis]</i>	A <i>path</i> in \( U\subseteq \mathbb{C} \) is a continuous map \( \gamma:[a,b]\to U \).	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Path-connected<br><i>[Complex Analysis]</i>	We say that \( U\subseteq \mathbb{C} \) is <i>path-connected</i> if for all \( x,y\in U \) there exists a path \( \gamma:[0,1]\to U \) such that \( \gamma(0) = x \) and \( \gamma(1) = y \).	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Domain<br><i>[Complex Analysis]</i>	A <i>domain</i> in \( \mathbb{C} \) is a non-empty path-connected subset of \( \mathbb{C} \).	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Closed path<br><i>[Complex Analysis]</i>	If \( \gamma \) is a path and \( \gamma(a)=\gamma(b) \) then we say that \( \gamma \) is a <i>closed path</i>.	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: $ C^1 $ path<br><i>[Complex Analysis]</i>	We say a path is \( C^1 \) if it is continuously differentiable. We say a path is <i>piecewise</i> \( C^1 \) if it has finitely many non-differentiable points but still globally continuous.	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Simple path<br><i>[Complex Analysis]</i>	A path is <i>simple</i> if it is injective except perhaps at the endpoints.	Complex_Analysis definition Complex_Differentiation
<b>Definition</b> (Complex Differentiation > Definitions)<br><i>[Complex Analysis]</i>	Let \( U\subseteq \mathbb{C} \) be open.<br><ol><li>We say that \( f:U\to \mathbb{C} \) is <i>differentiable</i> at \( w\in U \) if<br>\[<br>f'(w)=\lim_{z\to w}\frac{f(z)-f(w)}{z-w}<br>\]<br>exists.</li><li>We say that \( f \) is <i>holomorphic</i> at \( w\in U \) if \( \exists \varepsilon>0 \) such that \( f \) is differentiable on \( B(w,\varepsilon)\subseteq U \).</li><li>If \( f \) is holomorphic everywhere, we say \( f \) is <i>entire</i>.</li></ol	Complex_Analysis definition Complex_Differentiation
<b>Proposition</b>: Cauchy-Riemann equations<br><i>[Complex Analysis]</i>	Let \( f:U\to \mathbb{C} \) be defined on an open set \( U \) and write \( f=u+iv \), then \( f \) is differentiable t \( w= c+id\in U \) with \( f'(w)=p+iq \) if and only if \( u \) and \( w \) are both differentiable at \( (c,d) \) and \( u_x=v_y = p \) and \( -u_y = v_x=q \) at \( (c,d) \). Then \( f'(w) = u_x(c,d)+iv_x(c,d) \).	Complex_Analysis proposition Complex_Differentiation
<b>Proposition</b> (Complex Differentiation > Conformal maps)<br><i>[Complex Analysis]</i>	Let \( U\subseteq \mathbb{C} \) be a domain and suppose that \( f:U\to\mathbb{C} \) is holomorphic and \( f'(z)=0 \) on \( U \). Then \( f \) is constant.	Complex_Analysis proposition Complex_Differentiation
<b>Lemma</b> (Complex Differentiation > Conformal maps)<br><i>[Complex Analysis]</i>	If \( U \) is a domain and \( \gamma:[0,1]\to U \) is a path with \( \gamma(0)=a \) and \( \gamma(1)=b \). Then there is another path \( \bar\gamma:[0,1]\to U \) with \( \bar\gamma(0)=a \) and \( \bar\gamma(1)=b \) where \( \bar\gamma \) is composed of finitely many segments, each parallel to the \( x \) or \( y \) axis, so \( \bar\gamma \) is piecewise-\( C^1 \).	Complex_Analysis lemma Complex_Differentiation
<b>Definition</b>: Conformal<br><i>[Complex Analysis]</i>	If \( f \) is holomorphc at a point \( w \) and \( f'(w)\ne 0 \) we say that \( f \) is <i>conformal</i> at \( w \).	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Conformal equivalence<br><i>[Complex Analysis]</i>	If \( U,V \) are open in \( \mathbb{C} \) and \( f:U\to V \) is a holomorphic bijection which is everywhere conformal on \( U \) we say that \( f \) is a <i>conformal equivalence</i> and \( U \) and \( V \) are conformally equivalent.	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Simply connceted<br><i>[Complex Analysis]</i>	Let \( U\in \mathbb{C} \) be a domain. We say that \( U \) is <i>simply connected</i> if every continuous map \( \gamma: S^1 \to U \) extends to a map  \( \hat\gamma:\overline{\mathbb{D}}\to U \) such that \( \hat\gamma\mid_{tial \mathbb{D}} = \gamma \).	Complex_Analysis definition Complex_Differentiation
<b>Theorem</b>: Riemann mapping theorem<br><i>[Complex Analysis]</i>	If \( U\subset \mathbb{C} \) is a proper subdomain and \( U \) is simply connected, then \( U \) is conformally equivalent to the disc, \( \mathbb D = \{z:|z|<1\} \).	Complex_Analysis theorem Complex_Differentiation
<b>Theorem</b> (Complex Differentiation > Power series)<br><i>[Complex Analysis]</i>	Suppose that<br>\[<br>f(z) = \sum_{n=0}^\infty c_n(z-a)^n<br>\]<br>is a complex power series with radius of convergence \( R>0 \). Then<br><ol><li>\( f \) is holomorphic on \( B(a,R) = \{z:|z-a|<R\} \);</li><li>\( f'(z) = \sum nc_n(z-a)^{n-1} \) which also has radius of convergence \( R \);</li><li>\( f \) is infinitely complex differentiable on \( B(a,R) \) with<br>\[<br>f^{(n)}(a)= n!c_n.<br>\]</li></ol	Complex_Analysis theorem Complex_Differentiation
<b>Corollary</b> (Complex Differentiation > Power series)<br><i>[Complex Analysis]</i>	Suppose we have a power series<br>\[<br>f(z) = \sum_{n=-0}^\infty c_n(z-a)^n<br>\]<br>with \( R>0 \) and suppose that \( f \) vanishes on \( B(a,\varepsilon) \) with \( \varepsilon\in (0,R) \). Then \( f \) vanishes identically.	Complex_Analysis corollary Complex_Differentiation
<b>Definition</b>: Exponential function<br><i>[Complex Analysis]</i>	We define the function<br>\[<br>e^z = \exp(z) = \sum_{n=0}^\infty \frac{z^n}{n!},<br>\]<br>which has the properties<br><ol><li>Radius of convergence is \( \infty \);</li><li>\( \frac d{dz} e^z = e^z \);</li><li>\( e^0 =1 \). If we fix \( w \) and let \( F(z) = e^{z+w}e^{-z} \) then \( F'(z) \) vanishes, hence \( F \) is constant, and \( F(0) = e^w \), so \( e^{z+w} = e^ze^w \) holds for all \( z,w\in \mathbb{C} \).</li><li>\( e^z \) never vanishes on \( \mathbb{C} \).</li></ol	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Branch of the logarithm<br><i>[Complex Analysis]</i>	Let \( U\subseteq \mathbb{C}^* = \mathbb{C} \setminus \{0\} \) open. A continuous function \( \lambda: U\to \mathbb{C} \) is <i>branch of the logarithm</i> on \( U \) if \( e^{\lambda(z)} = z \) for all \( z\in U \).	Complex_Analysis definition Complex_Differentiation
<b>Proposition</b> (Complex Differentiation > Exponentials, logarithms, and branch cuts)<br><i>[Complex Analysis]</i>	\( \mathrm{Log} \) is holomorphic on \( \mathbb{C}\setminus \mathbb{R}_{\le 0} \) with<br><ol><li>\( \frac{d}{dz}\mathrm{Log}(z) = \frac 1z \);</li><li>If \( |z|<1 \) then<br>\[<br>\mathrm{Log}(1+z) = \sum_{n=1}^\infty (-1)^{n-1}\frac {z^n}n.<br>\]</li></ol	Complex_Analysis proposition Complex_Differentiation
<b>Definition</b>: Multivalued power function<br><i>[Complex Analysis]</i>	For a value \( \alpha\in \mathbb{C} \), the multivalued function \( z^\alpha \) is by definition \( \exp(\alpha\log(z)). \).	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Branch point<br><i>[Complex Analysis]</i>	A point \( p\in \mathbb{C} \) is a <i>branch point</i> of a multivalued function \( \phi \) if there is no continuous single-value definition of \( \phi \) in \( B(0,\varepsilon) \) for any \( \varepsilon > 0 \).	Complex_Analysis definition Complex_Differentiation
<b>Definition</b>: Riemann integrablility in $ \mathbb{C} $<br><i>[Complex Analysis]</i>	A function \( f:[a,b]\to\mathbb{C} \) is <i>Riemann integrable</i> if it's real and imaginary parts are both Riemann integrable and<br>\[<br>\int_a^b f(t)\mathrm dt = \int_a^b \operatorname{Re}(f(t)) \mathrm dt + i\int_a^b \operatorname{Im}(f(t)) \mathrm dt.<br>\]	Complex_Analysis definition Contour_Integration
<b>Proposition</b> (Contour Integration > Basic properties)<br><i>[Complex Analysis]</i>	For \( f:[a,b]\to \mathbb{C} \) we have that<br>\[<br>\left|\int_a^b f(t)\mathrm dt\right| \le \sup_{t\in[a,b]}|f(t)|(b-a)<br>\]<br>with equality if and only if \( f \) is constant.	Complex_Analysis proposition Contour_Integration
<b>Definition</b>: Contour<br><i>[Complex Analysis]</i>	A <i>contour</i> is a simple, closed path.	Complex_Analysis definition Contour_Integration
<b>Definition</b>: Contour integral<br><i>[Complex Analysis]</i>	If \( U \) is a domain, \( f:U\to \mathbb{C} \) is continuous and \( \gamma:[a,b]\to U \) is a \( C^1 \)-smooth curve then<br>\[<br>\int_\gamma f(z) \mathrm dz = \int_a^b f(\gamma(t))\gamma'(t)\mathrm dt.<br>\]	Complex_Analysis definition Contour_Integration
<b>Theorem</b>: Fundamental Theorem of Calculus<br><i>[Complex Analysis]</i>	Suppose that \( U \) is a domain \( F:U\to \mathbb{C} \) is holomorphic and \( F'(z) \) is continuous on \( U \). Then for a path \( \gamma:[a,b]\to U \)<br>\[<br>\int_\gamma F'(z)\mathrm dz = F(\gamma(b)) - F(\gamma(a)).<br>\]<br>In particular if \( \gamma \) is closed then we get zero.	Complex_Analysis theorem Contour_Integration
<b>Definition</b>: Antiderivative<br><i>[Complex Analysis]</i>	If \( U \) is a domain and \( f:U\to \mathbb{C} \) is continuous and \( F:U\to \mathbb{C} \) is holomorphic with \( F'(z)=f(z) \) then we say that \( F \) is an <i>antiderivative</i> for \( f \) on \( U \).	Complex_Analysis definition Contour_Integration
<b>Lemma</b> (Contour Integration > Cauchy's theorem)<br><i>[Complex Analysis]</i>	If \( \gamma \) is a \( C^1 \) path and \( f \) is continuous then<br>\[<br>\left|\int_\gamma f(z)\mathrm dz\right|\le \mathrm{length}(\gamma)\sup_\gamma|f|.<br>\]	Complex_Analysis lemma Contour_Integration
<b>Theorem</b> (Contour Integration > Cauchy's theorem)<br><i>[Complex Analysis]</i>	Let \( U \) be a domain and \( f:U\to \mathbb{C} \) be continuous. Assume that<br>\[<br>\int_\gamma f(z)\mathrm dz = 0<br>\]<br>for all piecewise-\( C_1 \) closed curves \( \gamma \) in \( U \). Then \( f \) has an antiderivative \( F(z) \) on \( U \).	Complex_Analysis theorem Contour_Integration
<b>Definition</b>: Convex<br><i>[Complex Analysis]</i>	A domain \( U \) is <i>convex</i> if \( \forall p,q\in U \), the straight line segment connecting \( p \) and \( q \) lies in \( U \). i.e.<br>\[<br>pt+(1-t)q \in U,\quad\forall t\in[0,1].<br>\]	Complex_Analysis definition Contour_Integration
<b>Definition</b>: Star-shaped<br><i>[Complex Analysis]</i>	A domain \( U \) is <i>star-shaped</i> if there exists a \( p_0 \) such that for all \( q\in U \), the line segment \( p_0, q\) lies in \( U \).	Complex_Analysis definition Contour_Integration
<b>Lemma</b> (Contour Integration > Cauchy's theorem)<br><i>[Complex Analysis]</i>	Let \( U \) be star-shaped and \( f:U\to \mathbb{C} \) be continuous and suppose that<br>\[<br>\int_\gamma f = 0<br>\]<br>where \( \gamma \) is a <i>triangle</i> in \( U \) where a <i>triangle</i> is a piecewise-\( C_1 \) path formed by \( 3 \) edges of a Euclidean triangle and the whole triangle including its interior is contained in \( U \). Then \( f \) has an antiderivative on \( U \).	Complex_Analysis lemma Contour_Integration
<b>Theorem</b>: Cauchy's theorem for triangles<br><i>[Complex Analysis]</i>	Let \( U \) be a domain and \( T\in U \) be a triangle in \( U \). If \( f: U \to \mathbb{C} \) is holomorphic then<br>\[<br>\int_{tial T} f = 0<br>\]<br>where \( tial T \) is the piecewise-\( C_1 \) closed path given by the boundary of \( T \).	Complex_Analysis theorem Contour_Integration
<b>Corollary</b>: Convex Cauchy<br><i>[Complex Analysis]</i>	Let \( f \) be a holomorphic on a star-shaped domain \( U \). Then \( \int_\gamma f =0 \) for any piecewise-\( C_1 \) closed curve \( \gamma \).	Complex_Analysis corollary Contour_Integration
<b>Proposition</b> (Contour Integration > Cauchy's theorem)<br><i>[Complex Analysis]</i>	Let \( U \) be a domain and \( f:U \to \mathbb{C} \) be continuous. Suppose that there exists a finite set \( S\subset U \) such that \( f \) is holomorphic on \( U\setminus S \). THen if \( T \subseteq U \) is a triangle, then<br>\[<br>\int_{tial T}f = 0.<br>\]	Complex_Analysis proposition Contour_Integration
<b>Corollary</b> (Contour Integration > Cauchy's theorem)<br><i>[Complex Analysis]</i>	If \( U \) is star-shaped and \( S\subset U \) is finite and \( f:U\to \mathbb{C} \) is continuous and holomorphic on \( U\setminus S \) then<br>\[<br>\int_\gamma f =0<br>\]<br>for all closed curves \( \gamma\in U \).	Complex_Analysis corollary Contour_Integration
<b>Theorem</b> (Contour Integration > The Cauchy integral formula)<br><i>[Complex Analysis]</i>	Let \( U\in \mathbb{C} \) be a domain, \( f:U\to \mathbb{C} \) be holomorphic on \( U \) and \( \overline{B(a,r)}\subseteq U \). For all \( z\in B(a,r) \) and \( 0<\rho \le r \), \( |z-a|<\rho \), we have that<br>\[<br>f(z) = \frac 1{2\pi i}\int_{|w-a|=\rho} \frac{f(w)}{w-z}\mathrm dw.<br>\]	Complex_Analysis theorem Contour_Integration
<b>Corollary</b>: Mean value property<br><i>[Complex Analysis]</i>	If \( f:U\to \mathbb{C} \) is holomorphic on a domain \( U \) and \( \overline{B(a,r)}\subseteq U \), then<br>\[<br>f(a) = \int_0^1 f(a+re^{2\pi i t}) \ \mathrm dt.<br>\]<br>So the value of \( f \) at \( a \) is the average of its values over a small linking circle.	Complex_Analysis corollary Contour_Integration
<b>Corollary</b>: Local maximum principle<br><i>[Complex Analysis]</i>	If \( f: B(a,r)\to \mathbb{C} \) is holomorphic and \( |f(z)|\le |f(a)| \) for all \( z\in B(a,r) \) then \( f \) is constant.	Complex_Analysis corollary Contour_Integration
<b>Theorem</b>: Liouville's Theorem<br><i>[Complex Analysis]</i>	Let \( f:\mathbb{C}\to\mathbb{C} \) be entire. Then if \( f \) is bounded it is constant.	Complex_Analysis theorem Contour_Integration
<b>Corollary</b>: Fundamental theorem of algebra<br><i>[Complex Analysis]</i>	Every non-constant complex polynomial has a root in \( \mathbb{C} \).	Complex_Analysis corollary Contour_Integration
<b>Theorem</b>: Taylor's Theorem<br><i>[Complex Analysis]</i>	Let \( f:B(a,r) \to \mathbb{C} \) be holomorphic. Then \( f \) has a convergent power series representation<br>\[<br>f(z) = \sum_{n=0}^\infty c_n(z-a)^n<br>\]<br>with<br>\[<br>c_n = \frac{f^{(n)}(a)}{n!} = \frac 1{2\pi i} \int_{tial B(a,\rho)} \frac {f(w)}{(w-a)^{n+1}}\ \mathrm dw<br>\]<br>for any \( 0<\rho <r \).	Complex_Analysis theorem Contour_Integration
<b>Corollary</b> (Contour Integration > Taylor and Morera's theorem)<br><i>[Complex Analysis]</i>	If \( f \) is holomorphic on a domain \( U \), then \( f \) is infinitely differentiable on \( U \).	Complex_Analysis corollary Contour_Integration
<b>Theorem</b>: Morera's theorem<br><i>[Complex Analysis]</i>	Let \( U \) be a domain and \( f:U\to\mathbb{C} \) be continuous. If<br>\[<br>\int_\gamma f = 0<br>\]<br>for all piecewise-\( C^1 \) closed paths in \( U \), the \( f \) is holomorphic on \( U \).	Complex_Analysis theorem Contour_Integration
<b>Corollary</b> (Contour Integration > Taylor and Morera's theorem)<br><i>[Complex Analysis]</i>	Let \( f_n:U\to \mathbb{C} \) be a sequence of holomorphic functions and suppose \( f_n\to f \) uniformly. Then \( f \) is holomorphic on \( U \) and<br>\[<br>f'(z) = \lim_{n\to \infty} f_n'(z)<br>\]<br>for \( z\in U \).	Complex_Analysis corollary Contour_Integration
<b>Corollary</b> (Contour Integration > Taylor and Morera's theorem)<br><i>[Complex Analysis]</i>	If \( U \) is a domain, \( f:U\to \mathbb{C} \) is continuous and for some finite set \( S\subseteq U \), \( f \) is holomorphic on \( U\setminus S \), then \( f \) is holomorphic on \( U \).	Complex_Analysis corollary Contour_Integration
<b>Theorem</b>: Cauchy for simply connected domains<br><i>[Complex Analysis]</i>	If \( U\subseteq \mathbb{C} \) is a simply connected domain and \( f:U\to \mathbb{C} \) is holomorphic then<br>\[<br>\int_\gamma =0<br>\]<br>for all closed piecewise-\( C^1 \) curves \( \gamma \) in \( U \).	Complex_Analysis theorem Contour_Integration
<b>Definition</b>: Homotopic<br><i>[Complex Analysis]</i>	Let \( \phi,\psi \) be closed paths in a domain \( U \), say \( \phi,\psi: [a,b] \to U \). We say that \( \phi,\psi \) are <i>homotopic</i> if there exists a \( \Phi:[a,b]\times [0,1] \to U \) continuous such that \( \Phi\mid_{[a,b] \times \{0\}} = \phi \) and \( \Phi\mid_{[a,b]\times \{1\}} = \psi \) and for all \( t \) \( \Phi\mid_{[a,b]\times \{t\}} \) is a closed path.	Complex_Analysis definition Contour_Integration
<b>Proposition</b> (Contour Integration > Homotopy)<br><i>[Complex Analysis]</i>	If \( U \) is a domain, \( \psi,\phi \) are homotopic piecewise-\( C^1 \) closed paths and if \( f:U\to \mathbb{C} \) is holomorphic, then<br>\[<br>\int_\phi f = \int_\psi f.<br>\]	Complex_Analysis proposition Contour_Integration
<b>Proposition</b>: Principle of isolated zeros<br><i>[Complex Analysis]</i>	If \( f:B(a,r)\to \mathbb{C} \) is holomorphic and \( f\not\equiv =0 \) then there exists \( 0<\rho <r \) such that<br>\[<br>f(z) \ne 0 \quad\forall z\in B(a,\rho)\setminus \{a\} = B(a,\rho)^*.<br>\]	Complex_Analysis proposition Contour_Integration
<b>Definition</b>: Accumulation point<br><i>[Complex Analysis]</i>	We say that a set \( X\subseteq \mathbb{C} \) has an accumulation point at \( a\in \mathbb{C} \) if for all \( \varepsilon>0 \) we have that \( B(a,\varepsilon)^* \cap X \ne \emptyset \).	Complex_Analysis definition Contour_Integration
<b>Theorem</b>: Identity theorem<br><i>[Complex Analysis]</i>	Let \( U\subseteq \mathbb{C} \) be a domain and \( f,g:U\to\mathbb{C} \) be holomorphic functions on \( U \). Let \( S = \{z\in U: f(z) = g(z)\} \). If \( S \) has an accumulation point in \( U \) then \( f(z) =g (z) \) for all \( z\in U \).	Complex_Analysis theorem Contour_Integration
<b>Corollary</b>: Global maximum principle<br><i>[Complex Analysis]</i>	Let \( U\subseteq \mathbb{C} \) be a bounded d omain. Let \( f:\overline U \to \mathbb{C} \) be continuous and holomorphic on \( U \). Then \( |f| \) achieves its maximum on \( tial U \).	Complex_Analysis corollary Contour_Integration
<b>Definition</b>: Analytic continuation<br><i>[Complex Analysis]</i>	Let \( U\subseteq U'\subseteq \mathbb{C} \) be domains and \( f:U\to \mathbb{C} \) holomorphic. We say that a holomorphic function \( h: U'\to \mathbb{C} \) such that \( h\mid_U = f \) is an <i>analytic continuation</i> of \( f \) (to \( U' \)).	Complex_Analysis definition Contour_Integration
<b>Corollary</b> (Contour Integration > Zeros)<br><i>[Complex Analysis]</i>	Analytic continuations are unique.	Complex_Analysis corollary Contour_Integration
<b>Definition</b>: Natural boundary<br><i>[Complex Analysis]</i>	If \( f:U\to \mathbb{C} \) is holomorphic and admits no analytic continuation to any domain \( U'\not\supseteq U \) we say that \( tial U \) is the <i>natural boundary</i> of \( f \).	Complex_Analysis definition Contour_Integration
<b>Proposition</b>: Removal of singularities<br><i>[Complex Analysis]</i>	Let \( U \) be a domain and \( z_0 \in U \), \( f:U\setminus \{z_0\} \to \mathbb{C} \) is holomorphic and \( f \) is bounded near \( z_0 \). Then there exists a \( a\in \mathbb{C} \) such that \( f(z) \to a \) as \( z\to z_0 \) and set<br>\[<br>g(z) = \begin{cases}<br>f(z) & z\in U\setminus \{z_0\}\\<br>a & z=z_0<br>\end{cases}<br>\]<br>then \( g \) is holomorphic on \( U \).	Complex_Analysis proposition Contour_Integration
<b>Definition</b>: Maxwell's equations<br><i>[Electromagnetism]</i>	\[\begin{aligned}<br>\nabla \cdot \mathbf E&=\frac{\rho}{\varepsilon_0}\\<br>\nabla\cdot \mathbf B &= 0 \\<br>\nabla\times \mathbf E &= -\frac{tial \mathbf B}{tial t} \\<br>\nabla \times  \mathbf B &= \mu_0\left(\mathbf J + \varepsilon_0\frac{tial \mathbf E}{tial t}\right).<br>\end{aligned}\]	Electromagnetism definition Introduction
<b>Definition</b>: Potential difference<br><i>[Electromagnetism]</i>	The <i>potential difference</i> or \text{voltage} between two points \( \mathbf{x}_1 \) and \( \mathbf{x}_2 \) is<br>\[<br>\Phi(\mathbf{x}_2)-\Phi(\mathbf{x}_1) &= \int\mathrm d\Phi \\<br>&= - \int_{\mathbf{x}_1}^{\mathbf{x}_2} \mathbf E\cdot\mathrm d\mathbf{x}<br>\]<br>and is path independent since \( \nabla\times \mathbf E = 0 \) is zero and the region is simply connected, so the field is conservative .	Electromagnetism definition Electrostatics
<b>Definition</b>: Electric force<br><i>[Electromagnetism]</i>	The <i>electric force</i> on a particle of charge \( q \) is<br>\[<br>\mathbf F = q\mathbf E = -q\nabla\Phi.<br>\]	Electromagnetism definition Electrostatics
<b>Definition</b>: Earthed/Grounded conductor<br><i>[Electromagnetism]</i>	An <i>earthed</i> or <i>grounded</i> conductor is connected to the ground, usually taken as \( \Phi = 0 \).	Electromagnetism definition Electrostatics
<b>Definition</b>: Capacitor<br><i>[Electromagnetism]</i>	A simple <i>capacitor</i> constants of two seperated conductors carrying charges \( \pm Q \). If the potential difference between them is \( V \), then the capacitance is defined by<br>\[<br>C = \frac QV<br>\]<br>and depends only on the geometry, because \( \Phi \) depends linearly on \( Q \).	Electromagnetism definition Electrostatics
<b>Definition</b>: Magnetic vector potential<br><i>[Electromagnetism]</i>	For a magnetic field \( \mathbf B \), the <i>magnetic vector potential</i> is the vector \( \mathbf A(\mathbf{x}) \) such that<br>\[<br>\mathbf B = \nabla\times \mathbf A.<br>\]	Electromagnetism definition Magnetostatics
<b>Theorem</b>: Biot-Savart law<br><i>[Electromagnetism]</i>	\[\begin{aligned}<br>\mathbf B(\mathbf{x})=\frac{\mu_0}{4\pi}\int\frac{\mathbf J(\mathbf{x}')\times (\mathbf{x}-\mathbf{x}')}{|\mathbf{x}-\mathbf{x}'|^3}\mathrm d^3\mathbf{x}'<br>\end{aligned}\]	Electromagnetism theorem Magnetostatics
<b>Definition</b>: Magnetic dipole moment<br><i>[Electromagnetism]</i>	\[<br>\mathbf m = \frac 12\int_V \mathbf{x}\times \mathbf J \mathrm d^3 \mathbf{x}<br>\]<br>or in component form<br>\[<br>m_i = \frac 12\varepsilon_{ijk}\int_V x_jJ_k\mathrm d^3 \mathbf{x}.<br>\]	Electromagnetism definition Magnetostatics
<b>Definition</b>: Permanent magnets<br><i>[Electromagnetism]</i>	A bar magnet has north and south poles and a dipole moment. This comes from the superposition of aligned dipoles on the atomic scale. Atoms contain electrons whihc are spinning charges particles with a magnetic dipole moment.	Electromagnetism definition Magnetostatics
<b>Definition</b>: Inductance<br><i>[Electromagnetism]</i>	If a current \( I \) around a circuit \( C \) generates a magnetic field with flux \( \mathcal F \) then the <i>inductance</i> of the circuit is defined by<br>\[<br>L = \frac {\mathcal F}I<br>\]<br>and depends only on the geometry.	Electromagnetism definition Electrodynamics
<b>Definition</b>: Perfect conductor<br><i>[Electromagnetism]</i>	A <i>perfect conductor</i> corresponds to \( \sigma\to\infty \) so \( \mathbf E = 0 \).	Electromagnetism definition Electrodynamics
<b>Definition</b>: Perfect insulator<br><i>[Electromagnetism]</i>	A <i>perfect insulator</i> corresponds to \( \sigma\to 0 \) so \( \mathbf J = 0 \).	Electromagnetism definition Electrodynamics
<b>Definition</b>: Streamlines<br><i>[Fluid Dynamics]</i>	These are curves that are everywhere parallel to the flow at a given instant.	Fluid_Dynamics definition Kinematics
<b>Definition</b>: Pathlines<br><i>[Fluid Dynamics]</i>	A <i>pathline</i> is the trajectory of a fluid particle (a very small bit of fluid). The pathline \( \mathbf{x}=\mathbf{x}(t,\mathbf{x}_0) \) of a fluid which is at \( \mathbf{x}_0 \) at \( t=0 \) is such that<br>\[<br>\frac{d\mathbf{x}}{dt}=\mathbf u(\mathbf{x},t)<br>\]<br>with \( \mathbf{x}(0,\mathbf{x}_0)=\mathbf{x}_0 \).	Fluid_Dynamics definition Kinematics
<b>Definition</b>: Incompressible<br><i>[Fluid Dynamics]</i>	A fluid flow is <i>incompressible</i> if \( \frac{D\rho}{Dt}=0 \).	Fluid_Dynamics definition Kinematics
<b>Definition</b>: Inviscid<br><i>[Fluid Dynamics]</i>	A fluid is said to be <i>inviscid</i> if we can neglect viscosity.	Fluid_Dynamics definition Dynamics_of_inviscid_flow
<b>Theorem</b>: Euler momentum integral equation<br><i>[Fluid Dynamics]</i>	\[\begin{aligned}<br>\frac d{dt} \int_V\rho \mathbf u\  \mathrm dV &= -\int_{tial V}\rho \mathbf u (\mathbf u \cdot \mathbf n)\ \mathrm d A + \underbrace{\int_V \mathbf f\mathrm dV}_{\text{volume force}} + \underbrace{\int_{tial V} - p\mathbf n \ \mathrm dA}_{\text{surface force}}.<br>\end{aligned}\]	Fluid_Dynamics theorem Dynamics_of_inviscid_flow
<b>Definition</b>: Circulation<br><i>[Fluid Dynamics]</i>	Given a closed curve \( \Gamma \), the <i>circulation</i> around \( \Gamma \) is defined as<br>\[<br>C(t)=\int_\Gamma \mathbf u \cdot\mathrm d\boldsymbol\ell.<br>\]	Fluid_Dynamics definition Dynamics_of_inviscid_flow
<b>Theorem</b> (Dynamics of inviscid flow > Vorticity > Vortex stretching)<br><i>[Fluid Dynamics]</i>	i>Non-examinable</i> (Kelvine circulation theorem) For an inviscid fluid with constant density and conservative body forces then if we take \( \Gamma \) to be a material line then<br>\[<br>\frac{d}{dt}C = 0<br>\]	Fluid_Dynamics theorem Dynamics_of_inviscid_flow
<b>Definition</b>: Dynamic viscosity<br><i>[Fluid Dynamics]</i>	The <i>dynamic viscosity</i>, \( \mu \), of a fluid is the proportionality constant from above, so<br>\[<br>\tau = \mu \frac Uh.<br>\]<br>We usually write this as<br>\[<br>\tau = \mu \frac{tial u}{tial n},<br>\]<br>the viscous tangential stress exerted by the positive side to the negative side, where the normal is pointing from the interface to the positive side.	Fluid_Dynamics definition Viscosity
<b>Definition</b> (Review of IA Groups > Definitions)<br><i>[Groups, Rings, and Modules]</i>	A group is a <i>triple</i>, \( (G,\circ,e) \) consisting of a set \( G \), a binary operation \( \circ:G\times G\rightarrow G \) and an identity element \( e\in G \) where we have the following three properties,<br><ol><li>\( \forall a,b,c\in G, (a\circ b) \circ c =a\circ(b\circ c) \)</li><li>\( \forall a\in G, a\circ e = e\circ a = a \)</li><li>\( \forall a\in G, \exists \inv a \in G, a \circ \inv a = \inv a \circ a = e \)</li></ol><br>We say that the <i>order</i> of the group \( (G,\circ, e) \) is the size of the set \( G \)	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Proposition</b> (Review of IA Groups > Definitions)<br><i>[Groups, Rings, and Modules]</i>	Inverses are unique.	Groups_Rings_and_Modules proposition Review_of_IA_Groups
<b>Definition</b> (Review of IA Groups > Definitions)<br><i>[Groups, Rings, and Modules]</i>	If \( G \) is a group, then a subset \( H\subseteq G \) is a <i>subgroup</i> if the following hold,<br><ol><li>\( e\in H \)</li><li>If \( a,b\in H \) then \( a\circ b\in H \)</li><li>\( (H,\circ, e) \) forms a group.</li></ol	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Lemma</b> (Review of IA Groups > Definitions)<br><i>[Groups, Rings, and Modules]</i>	A non-empty subset, \( H \), of a group \( G \) is a subgroup if and only if \( \forall h_1,h_2\in H \) we have that \( h_1 \inv h_2\in H \)	Groups_Rings_and_Modules lemma Review_of_IA_Groups
<b>Definition</b> (Review of IA Groups > Definitions)<br><i>[Groups, Rings, and Modules]</i>	A group \( G \) is abelian if \( \forall g_1,g_2\in G \) we have that \( g_1g_2=g_2g_1 \)	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Definition</b> (Review of IA Groups > Cosets)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a group and \( g\in G \). Let \( H \) be a subgroup of \( G \). The <i>left coset</i>, written as \( gH \) is the set \( \{gh : h\in H\} \)	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Theorem</b>: Lagrange's Theorem<br><i>[Groups, Rings, and Modules]</i>	If \( G \) is a finite group, then for a subgroup \( H \) of \( G \), \( |G|=|H||G:H| \), where \( |G:H| \) is the number of left cosets of \( H \) in \( G \)	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Definition</b> (Review of IA Groups > Cosets)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a group, and take some element \( g\in G \). We define the <i>order</i> of \( g \) as the smallest positive integer \( n \), such that \( g^n = e \). If no such \( n \) exists, we say the order of \( g \) is infinite. We denote the order by \( \mathrm {ord}(g) \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Proposition</b> (Review of IA Groups > Cosets)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a group and \( g\in G \). Then \( \mathrm {ord}(g) \) divides \( |G| \)	Groups_Rings_and_Modules proposition Review_of_IA_Groups
<b>Lemma</b> (Review of IA Groups > Normal subgroups)<br><i>[Groups, Rings, and Modules]</i>	For a group \( G \) with \( g, g'\in G \) and subgroup \( H \) we have that \( gH=g'H \) if and only if \( \inv {g'} g\in H \)	Groups_Rings_and_Modules lemma Review_of_IA_Groups
<b>Definition</b>: Normality<br><i>[Groups, Rings, and Modules]</i>	A subgroup \( H\le G \) is <i>normal</i> if \( \forall g \in G \), \( h\in H \), we have that \( gh\inv g\in H \)	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Definition</b>: Quotient<br><i>[Groups, Rings, and Modules]</i>	Let \( H\triangleleft G \). The <i>quotient group</i> is the set \( (G/H, \cdot, e=eH) \) where \( \cdot:G/H\times G/H \rightarrow G/H \) by \( (g_1H,g_2H)\rightarrow (g_1g_2)H \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Definition</b>: Homomorphism<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) and \( H \) be groups. A <i>homomorphism</i> is a function \( f: G\rightarrow H \) such that for all \( g_1,g_2\in G \) we have that \( f(g_1g_2)=f(g_1)f(g_2) \)	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Lemma</b> (Review of IA Groups > Normal subgroups)<br><i>[Groups, Rings, and Modules]</i>	If \( f:G\rightarrow H \) is a homomorphism. Then \( f(\inv g)={f(g)}^{-1} \)	Groups_Rings_and_Modules lemma Review_of_IA_Groups
<b>Definition</b> (Review of IA Groups > Normal subgroups)<br><i>[Groups, Rings, and Modules]</i>	Let \( f:G\rightarrow H \) be a homomorphism. The <i>kernel</i> of \( f \) is \( \ker f =\{g\in G: f(g)=e\} \). The <i>image</i> of \( f \) is \( \operatorname{im} f=\{ h\in H: h=f(g)\text{ for some } g\in G\} \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Proposition</b> (Review of IA Groups > Normal subgroups)<br><i>[Groups, Rings, and Modules]</i>	Let \( f:G\rightarrow H \) be a homomorphism. Then \( \ker f \triangleleft G \) and \( \operatorname{im} f \le H.\)	Groups_Rings_and_Modules proposition Review_of_IA_Groups
<b>Definition</b>: Isomorphism<br><i>[Groups, Rings, and Modules]</i>	A homomorphism \( f:G\rightarrow H \) is an <i>isomorphism</i> if it is a bijection. Two groups are called <i>isomorphic</i> if there exists an isomorphism between them.	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Theorem</b>: First isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( f:G\to H \) be a homomorphism. Then \( \ker f \) is normal, and the function \( \varphi:G/\ker f\rightarrow \operatorname{im} f \), by \( \varphi(g\ker f)=f(g) \), is a well-defined, isomorphism of groups.	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Theorem</b>: Second isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( H\le G \) and \( K\triangleleft G \). Then \( HK=\{hk : h\in H, k\in K\} \) is a subgroup of \( G \), the set \( H\cap K\) is normal in H, and \( \frac{HK}K\cong \frac H{H\cap K} \).	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Theorem</b>: Correspondence theorem<br><i>[Groups, Rings, and Modules]</i>	. Consider a group \( G \) with \( K\triangleleft G \), with the homomorphism \( p:G\to G/K \), by \( p(g)=gK \). Then there is a bijection between the subgroups of \( G \) which contain \( K \) and the subgroups of \( G/K \).	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Theorem</b>: Third isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( K,L \) be normal subgroups of \( G \) with \( K\le L\le G \). Then we have that \( \frac{G/K}{L/K}\cong \frac GL \).	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Definition</b>: Simple groups<br><i>[Groups, Rings, and Modules]</i>	A group \( G \) is called <i>simple</i> if the only normal subgroups are \( G \) itself and \( \{ e \} \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Proposition</b> (Review of IA Groups > Normal subgroups)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be an abelian group. Then \( G \) is simple if and only if  \( G\cong C_p \), for \( p \) prime.	Groups_Rings_and_Modules proposition Review_of_IA_Groups
<b>Theorem</b>: Composition series<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a finite group. Then there exists subgroups such that, \( G=H_1\triangleright H_2\triangleright H_3\triangleright\cdots \triangleright H_n=\{e\} \), such that \( \frac {H_i}{H_{i+1}} \) is simple.	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Definition</b> (Review of IA Groups > Groups actions and permutations)<br><i>[Groups, Rings, and Modules]</i>	Let \( X \) be a set. Let \( \operatorname{Sym}(x) \) denote the symmetric group of \( X \) and \( S_n=\operatorname{Sym}([n]) \) where we have that \( [n]=\{1,2,\dots, n\} \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Definition</b>: Alternating group<br><i>[Groups, Rings, and Modules]</i>	The <i>alternating group</i> \( A_n \) is the kernel of \( \mathrm{sgn} \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Definition</b>: Group action<br><i>[Groups, Rings, and Modules]</i>	An <i>action</i> of \( G \) on a set \( X \) is a function \( \tau:G\times X\to X \) sending \( (g,x) \to \tau(g,x)\in X \) such that \( \tau(e,x)=x, \forall x\in X \), and \( \tau(g_1,\tau(g_2,x))=\tau(g_1g_2,x), \forall g_1g_2\in G, \forall x\in X \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Proposition</b> (Review of IA Groups > Groups actions and permutations)<br><i>[Groups, Rings, and Modules]</i>	The funtion \( a \) above is a bijection from the set of homomorphism from \( G\to\operatorname{Sym}(X) \) to the set of actions from \( G \) on \( X \).	Groups_Rings_and_Modules proposition Review_of_IA_Groups
<b>Theorem</b> (Review of IA Groups > Groups actions and permutations)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be finite and \( H\le G \) of index \( n \). There exists a normal subgroup of \( G \), \( K\triangleleft G \), with \( K\le H \), such that \( G/K \) is isomorphic to a subgroup of \( S_n \). Thus, \( |G/K| \) divides \( n! \), and \( |G/K|\ge n\).	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Corollary</b> (Review of IA Groups > Groups actions and permutations)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be non-abelian and simple. Let \( H\le G \) be a proper subgroup of index \( n>1 \). Then \( G \) is isomorphism to a subgroup \( A_n \). Moreover, \( n\ge 5, \) i.e. no subgroup of index less than \( 5 \).	Groups_Rings_and_Modules corollary Review_of_IA_Groups
<b>Definition</b>: Orbits and stabiliser<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) act on some set \( X \). Then, the <i>orbit</i> of \( x\in X \) is \( G\cdot x=\operatorname{orb} x=\{gx : g\in G\}\subseteq X \). And the <i>stabiliser</i> of \( x\in X \) is \( G_x=\operatorname{stab}_G(x) = \{g\in G:gx=x\}\le G \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Theorem</b>: Orbit-stabiliser<br><i>[Groups, Rings, and Modules]</i>	For a group \( G \) acting on a set \( X \). For all \( x\in X \), there is a bijection \( G\cdot x \to G/G_x \) given by \( g\cdot x \to gG_x \). In particular, if \( G \) is finite, then \( |G|=|G\cdot x||G_x|, \forall x\in X \).	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Definition</b>: Automorphism<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a group. A permutation \( G\to G \) that is also a homomorphism is called an <i>automorphism</i> of \( G \). The set of all automorphisms of \( G \), \( \operatorname{Aut}(G) =\{f:G\to G: f \text{ is a automorphism}\}\subseteq \operatorname{Sym}(G) \), is a subgroup, called the automorphism group of \( G \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Definition</b>: Conjugacy classes and centralisers<br><i>[Groups, Rings, and Modules]</i>	Fix \( g\in G \). The <i>conjugacy class</i> of \( g \) is the set \( \operatorname{ccl}_G(g) = \{hg\inv h: h\in G\} \), i.e it is the orbit under the conjugation action. The <i>centraliser</i> of \( g\in G \) is \( C_G(g)=\{h\in G:hg\inv h=g\} \), i.e the stabiliser of \( g \) under the action.	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Definition</b>: Centre<br><i>[Groups, Rings, and Modules]</i>	The <i>centre</i> of \( G \) is \( Z(G)=\{z\in G:hz\inv h=z\forall h\in G\} \), i.e. it is the kernel of the conjugation action and the intersection of the centralisers.	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Corollary</b> (Review of IA Groups > Conjugacy, centralisers, and normalisers)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a finite group. Then \( |\operatorname{ccl}_G(x)|=|G:C_G(x)|=\frac{|G|}{|c_G(x)|} \).	Groups_Rings_and_Modules corollary Review_of_IA_Groups
<b>Definition</b>: Normaliser<br><i>[Groups, Rings, and Modules]</i>	Let \( H\le G \). The <i>normaliser</i> of \( H \) in \( G \) is \( N_G(H)=\{g\in G: gH\inv g = H\} \)	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Theorem</b> (Review of IA Groups > Simplicity of $ A_n $ for $ n\ge 5 $)<br><i>[Groups, Rings, and Modules]</i>	Let \( n\ge 5 \). Then \( A_n \) is simple.	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Definition</b>: Finite $ p $-groups<br><i>[Groups, Rings, and Modules]</i>	For \( p \) prime, a <i>finite \( p \)-group</i> is a group of order \( p^n \), \( n\in\mathbb{N} \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Theorem</b> (Review of IA Groups > Finite $p$-groups)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a finite \( p \)-group. Then \( Z(G) \) is non-trival.	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Theorem</b> (Review of IA Groups > Finite $p$-groups)<br><i>[Groups, Rings, and Modules]</i>	A group of size \( p^2 \) must be abelian.	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Lemma</b> (Review of IA Groups > Finite $p$-groups)<br><i>[Groups, Rings, and Modules]</i>	If \( G \) is any group and \( \frac G{Z(G)} \) is cyclic, then \( G \) is abelian.	Groups_Rings_and_Modules lemma Review_of_IA_Groups
<b>Theorem</b> (Review of IA Groups > Finite $p$-groups)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a group of size \( p^n \). Then for any \( 0\ge k \ge n\), \( G \) has a subgroup of size \( p^k \).	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Theorem</b>: Classification of finite abelian groups<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a finite abelian group. There exists positive integers \( d_1,\cdots, d_r \) such that:<br>\[<br>G\cong C_{d_1}\times C_{d_2}\times \cdots\times C_{d_r}<br>\]<br>Moreover, we can choose \( d_i \) such that \( d_{i+1}\mid d_i \) in which case this is unique.	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Lemma</b>: Chinese remainder theorem<br><i>[Groups, Rings, and Modules]</i>	If \( n \) and \( m \) are coprime, then \( C_n\times C_m\cong C_{nm} \)	Groups_Rings_and_Modules lemma Review_of_IA_Groups
<b>Definition</b>: Sylow $ p $-subgroup<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a finite group of order \( p^am\), where \( p\nmid m \), \( p \) is a prime. Then a <i>Sylow p-subgroup</i> of \( G \) is a subgroup of size \( p^a \).	Groups_Rings_and_Modules definition Review_of_IA_Groups
<b>Theorem</b>: Sylow theorems<br><i>[Groups, Rings, and Modules]</i>	For a finite group \( G \) of order \( p^am \), where \( p\nmid m \), \( p \) is prime:<br><ol><li>The set \( \operatorname{Syl}_p(G)=\{P\le G\) \( |\) \(P \text{ is a Sylow p-subgroup of } G \}\) is non-empty.</li><li>Any \( H,H'\in \operatorname{Syl}_p(G) \) are conjugate, namely \( H=gH'\inv g \), for some \( g\in G \).</li><li>If \( n_p=|\operatorname{Syl}_p(G)| \) then \( n_p\equiv 1 \mod p \) <i>and</i> \( n_p \) divides \( |G| \), so \( n_p\mid m \)</li></ol	Groups_Rings_and_Modules theorem Review_of_IA_Groups
<b>Lemma</b> (Review of IA Groups > Sylow Theorems)<br><i>[Groups, Rings, and Modules]</i>	If \( \operatorname{Syl}_p(G)=\{P\} \), then \( P \) is normal in \( G \).	Groups_Rings_and_Modules lemma Review_of_IA_Groups
<b>Corollary</b> (Review of IA Groups > Sylow Theorems)<br><i>[Groups, Rings, and Modules]</i>	Let \( G \) be a non-abelian simple group, and \( p\mid |G| \), \( p \) prime. Then \( |G| \) divides \( \frac{n_p!}2 \) and \( n_p\ge 5 \).	Groups_Rings_and_Modules corollary Review_of_IA_Groups
<b>Definition</b>: Rings<br><i>[Groups, Rings, and Modules]</i>	A <i>ring</i> is a quintuple \( (R,+,\circ,0_R,1_R) \), where \( R \) is a set with \( 0_R,1_R\in R \), and \( +:R\times R\to R \), and \( \circ:R\times R\to R \), called addition and multiplication are functions satisfying the following:<br><ol><li>\( (R,+,0_R) \) is an abelian group.</li><li>\( \circ \) is associative, so \( a\circ(b\circ c)=(a\circ b)\circ c \).</li><li>\( 1_R\circ a = a\circ 1_R=a \).</li><li>We have distributivity, so \( r_1\circ (r_2+r_3)=(r_1\circ r_2)+(r_1\circ r_3) \) and \( (r_1+r_2)\circ r_3=(r_1\circ r_3)+(r_2\circ r_3) \).</li></ol	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Subring<br><i>[Groups, Rings, and Modules]</i>	A <i>subring</i> of a ring \( R \), is a subset \( S\subseteq R \), such that \( 0_R,1_R\in S \), \( S \) is closed under both multiplication and addition of the ring, and \( (S,+,\circ, 0_R,1_R) \) is a ring.	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Units<br><i>[Groups, Rings, and Modules]</i>	An element \( u\in R \), is called a <i>unit</i> if there exists some \( v\in R \), such that \( uv=1_R\in R \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Polynomial<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a ring. Then a <i>polynomial</i> in \( x \) with coefficents in \( R \) in an expression:<br>\[<br>f(x)=a_0+a_1x+\cdots+a_nx^n<br>\]<br>and \( x^i \) are formal symbols. We will identify \( f(x) \) with \( f(x)+0\circ x^{n+1} \) as the same. The largest \( i \) such that \( a_i \ne 0\) is called the degree of the polynomial. A polynomial \( f(x) \) is monic of degree \( n \) if \( a_n=1 \) and it is of degree \( n \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Polynomial ring<br><i>[Groups, Rings, and Modules]</i>	The <i>polynomial ring</i> \( R[X] \) is given by:<br>\[<br>R[X]= \{f(X): \text{ f is a polynomial in } X \text { with coefficents in } R\}<br>\]<br>\(+, \circ  \) are the usual operations, \( 0_{R[X]}=0_R \) and \( 1_{R[X]}=1_R \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Ring of formal power series<br><i>[Groups, Rings, and Modules]</i>	The <i>ring of formal power series</i> is a ring in \( X \) with coefficents in \( R \) is:<br>\[<br>R[[X]]=\left\{\sum_{n=0}^\infty r_iX^i:a_i\in R,\forall i\ge 0, i\in\mathbb{Z}\right\}<br>\]<br>with the standard \( +,\circ \) of \( R \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Laurent polynomials<br><i>[Groups, Rings, and Modules]</i>	If \( R \) is a ring then a <i>Laurent polynomial</i> with coeffients in \( R \) is:<br>\[<br>R[X,\inv X] = \left\{\sum_{i\in\mathbb{Z}}a_iX^i: a_i\in R,\forall i\in\mathbb{Z}\right\}<br>\]<br>Where \( a_i \) is non-zero for at most finitely many \( i \) and with standard multiplication and addition.	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Ring homomorphism<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) and \( S \) be rings. A function \( f:R\to S \) is a <i>ring homomorphism</i> if for all \( r_1,r_2\in R \):<br><ol><li>\( f(r_1+r_2)=f(r_1)+f(f_2) \)</li><li>\( f(0_R)=0_S \)</li><li>\( f(r_1r_2)=f(r_1)f(r_2) \)</li><li>\( f(1_R)=1_S \).</li></ol	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Isomorphism<br><i>[Groups, Rings, and Modules]</i>	An <i>isomorphism</i> \( f:R\to S \) is a bijective ring homomorphism. The inverse function is also a ring homomorphism.	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Kernal<br><i>[Groups, Rings, and Modules]</i>	The <i>kernel</i> of a ring homomorphism \( f: R\to S \) is the set \( \ker f = \{r\in R: f(r)=0_S\} \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Image<br><i>[Groups, Rings, and Modules]</i>	The <i>image</i> of a ring homomorphism \( f: R\to S \) is \( \operatorname{im} f = \{s\in S:s=f(r) \text{ for some } r\in R \}\).	Groups_Rings_and_Modules definition Rings
<b>Lemma</b> (Rings > Homomorphisms, ideals, and quotients)<br><i>[Groups, Rings, and Modules]</i>	A homomorphism \( f:R\to S \) is injective if and only if \( \ker f = \{0\} \).	Groups_Rings_and_Modules lemma Rings
<b>Definition</b>: Ideal<br><i>[Groups, Rings, and Modules]</i>	A subset \( I\subseteq R \) is an <i>ideal</i>, written as \( I\triangleleft R \), if \( I \) is a subgroup and if \( a\in I \) and \( b\in R \), then \( ab\in I \).	Groups_Rings_and_Modules definition Rings
<b>Lemma</b> (Rings > Homomorphisms, ideals, and quotients)<br><i>[Groups, Rings, and Modules]</i>	If \( f:R\to S \) is a ring homomorphism then \( \ker f \triangleleft R\).	Groups_Rings_and_Modules lemma Rings
<b>Definition</b> (Rings > Homomorphisms, ideals, and quotients)<br><i>[Groups, Rings, and Modules]</i>	Let \( A\subseteq R \). The ideal generated by \( A \) is<br>\[<br>(A)=\left\{\sum_{a\in A}r_aa,\quad r_a \in R, \quad \text{all but finitely many } r_a \text{ are } 0\right\}<br>\]	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Principle<br><i>[Groups, Rings, and Modules]</i>	An ideal \( I\triangleleft R \) is <i>principle</i> if there exists \( r\in R \) such that \( (r)=I \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Quotient<br><i>[Groups, Rings, and Modules]</i>	Let \( I\triangleleft R \) be an ideal. Then the <i>quotient ring</i> \( R/I \) is the set of cosets \( r+I \) with \( 0_R/I=0_R+I \) and \( 1_R/I=1_R+I \), and operations \( (r_1+I)+(r_2+I)=(r_1+r_2)+I \) and \( (r_1+I)(r_2+I)=r_1r_2+I \).	Groups_Rings_and_Modules definition Rings
<b>Proposition</b> (Rings > Homomorphisms, ideals, and quotients)<br><i>[Groups, Rings, and Modules]</i>	The quotient ring is a ring. The function \( f:R\to R/I \) sending \( r \) to \( r+ I \) is a ring homomorphism.	Groups_Rings_and_Modules proposition Rings
<b>Proposition</b>: Euclidean algorithm for polynomials in $ X $<br><i>[Groups, Rings, and Modules]</i>	Let \( K \) be a field and \( f,g\in K[X] \). Then there exists polynomials \( r,q\in K[X] \) such that \( f=gq+r \) with \( \mathrm{deg}(r)<\mathrm{deg}(g) \).	Groups_Rings_and_Modules proposition Rings
<b>Corollary</b> (Rings > Homomorphisms, ideals, and quotients)<br><i>[Groups, Rings, and Modules]</i>	If \( K \) is a field then \( K[X] \) every ideal is principle.	Groups_Rings_and_Modules corollary Rings
<b>Theorem</b>: First isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( \varphi:R\to S \) be a ring homomorphism. Then the function \( f:R/\ker\varphi\to\operatorname{im}\varphi\le S \) sending \( r+\ker\varphi\to\varphi(r) \) is well-defined and an isomorphism of rings.	Groups_Rings_and_Modules theorem Rings
<b>Theorem</b>: Second isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( R\le S \) and \( J\triangleleft S \). Then \( J\cap R\triangleleft R \) and \( \frac{R+J}{J}=\{r+J:r\in R\}\le \frac SJ \). Furthermore,<br>\[<br>\frac{R}{R\cap J}\cong \frac{R+J}J.<br>\]	Groups_Rings_and_Modules theorem Rings
<b>Theorem</b>: Correspondence theorem<br><i>[Groups, Rings, and Modules]</i>	If \( I\triangleleft R \) is an ideal there is a bijection between subrings of \( R/I \) and subrings of \( R \) which contain \( I \). This is given by sending \( L\le R/I\to \{r\in R: r+I\in L\} \) and conversely \( I\triangleleft S\le R\to S/I\le R/I \)	Groups_Rings_and_Modules theorem Rings
<b>Theorem</b>: Third isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( I\triangleleft R \) and \( J\triangleleft R \) with \( I\subseteq J \). Then \( \frac JI\triangleleft \frac RI \) and we have that,<br>\[<br>\frac{R/I}{J/I}\cong R/J.<br>\]	Groups_Rings_and_Modules theorem Rings
<b>Definition</b>: Integral domain<br><i>[Groups, Rings, and Modules]</i>	A nonzero ring \( R \) is an integral domain if \( \forall a,b\in R \), if \( ab=0 \) then \( a=0 \) or \( b=0 \).	Groups_Rings_and_Modules definition Rings
<b>Lemma</b> (Rings > Integral domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a finite integral domain. Then \( R \) is a field.	Groups_Rings_and_Modules lemma Rings
<b>Definition</b> (Rings > Integral domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be an integral domain. A <i>text of fractions</i> for \( R \) is a field \( F \) such that:<br><ol><li>\( R\le F \) is a subring,</li><li>every \( x\in F \) can be written as \( a\inv b \), where \( a,b\in R, \) where \( \inv b \) is the multiplictive inverse to \( b \) in \( F \).</li></ol	Groups_Rings_and_Modules definition Rings
<b>Theorem</b> (Rings > Integral domains)<br><i>[Groups, Rings, and Modules]</i>	Every integral domain has a field of fractions.	Groups_Rings_and_Modules theorem Rings
<b>Proposition</b> (Rings > Integral domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a ring. Then \( R \) is a field if and only if the only ideals in \( R \) are \( (0) \) and \( R \).	Groups_Rings_and_Modules proposition Rings
<b>Definition</b>: Maximal ideal<br><i>[Groups, Rings, and Modules]</i>	An ideal \( I\triangleleft R \) is called <i>maximal</i> if it is not \( R \) itself and if for any \( J\triangleleft R \) with \( I\subseteq J\subseteq R \), either \( J=I \) or \( J=R \).	Groups_Rings_and_Modules definition Rings
<b>Proposition</b> (Rings > Integral domains)<br><i>[Groups, Rings, and Modules]</i>	An ideal \( I\triangleleft R \) is maximal if and only if \( R/I \) is a field.	Groups_Rings_and_Modules proposition Rings
<b>Definition</b>: Prime ideal<br><i>[Groups, Rings, and Modules]</i>	An ideal \( I\triangleleft R \) is <i>prime</i> if whenever \( ab\in I \) either \( a \) or \( b \) lies in \( I \).	Groups_Rings_and_Modules definition Rings
<b>Proposition</b> (Rings > Integral domains)<br><i>[Groups, Rings, and Modules]</i>	An ideal \( I\triangleleft R\) is prime if and only if \( R/I \) is an integral domain.	Groups_Rings_and_Modules proposition Rings
<b>Corollary</b> (Rings > Integral domains)<br><i>[Groups, Rings, and Modules]</i>	If \( R \) is a prime and \( I\triangleleft R \) is maximal, then \( I \) is prime.	Groups_Rings_and_Modules corollary Rings
<b>Definition</b>: Division<br><i>[Groups, Rings, and Modules]</i>	Let \( a,b\in R \) we say that a <i>divides</i> b, written as \( a\mid b \) if there exists some \( c \in R \) such that \( b=ac \). Equivalently we have that \( (b)\subseteq (a) \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Associates<br><i>[Groups, Rings, and Modules]</i>	We say that \( a \) and \( b \) in \( R \) are <i>associates</i> if \( a=bc \) for \( c\in R \) a unit. Equivalent to \( (a)=(b) \) and also equivalent to that \( a\mid b \) and \( b\mid a \).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Irreducible<br><i>[Groups, Rings, and Modules]</i>	An element \( a\in R \) is called <i>irreducible</i> if \( a\ne 0 \), \( a \) is not a unit, and if \( a=xy \) then either \( x \) or \( y \) is a unit.	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Prime element<br><i>[Groups, Rings, and Modules]</i>	We say that an element \( p\in R \) is <i>prime</i> if \( p\ne 0 \), not a unit and if \( p\mid xy \), then either \( p\mid x \) or \( p\mid y \).	Groups_Rings_and_Modules definition Rings
<b>Proposition</b> (Rings > Factorisation in integral domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( r\in R \). Then \( r\ne 0 \) is prime if and only if \( (r) \) is a prime ideal.	Groups_Rings_and_Modules proposition Rings
<b>Proposition</b> (Rings > Factorisation in integral domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( r\in R \) be prime. Then \( r \) is irreducible.	Groups_Rings_and_Modules proposition Rings
<b>Definition</b> (Rings > Factorisation in integral domains)<br><i>[Groups, Rings, and Modules]</i>	An integral domain \( R \) is called a <i>Euclidean domain</i> if there exists a Euclidean function \( \varphi:R\setminus \{0\}\to\mathbb{Z}_{\ge 0} \) such that:<br><ol><li>\( \varphi(ab)\ge \varphi(b) \) for all \( a,b\ne 0 \).</li><li>If \( a,b\in R \) with \( b\ne 0 \), then there exists \( q,r\in R \) such that \( a=bq+r \) and either \( r=0 \) or \( \varphi(r)<\varphi(b) \).</li></ol	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Principal ideal domain<br><i>[Groups, Rings, and Modules]</i>	A ring \( R \) is a <i>principle ideal domain</i> (PID) if it is an integral domain, and every ideal is a principal ideal, i.e for all \( I\triangleleft R \), there is some \( a \) such that \( I=(a) \).	Groups_Rings_and_Modules definition Rings
<b>Proposition</b> (Rings > Factorisation in integral domains)<br><i>[Groups, Rings, and Modules]</i>	Every Euclidean domain is a principal ideal domain.	Groups_Rings_and_Modules proposition Rings
<b>Definition</b>: Unique factorisation domain<br><i>[Groups, Rings, and Modules]</i>	An integral domain \( R \) is a <i>unique factorisation domain</i> (UFD) if:<br><ol><li>Every non-unit in \( R \) can be written as a product of irreducibles.</li><li>If \( p_1\dots p_n=q_1\cdots q_m \), where \( p_i, q_i \) are irreducible, then \( n=m \) and up to reordering \( p_i \) are \( q_i \) are associates.</li></ol	Groups_Rings_and_Modules definition Rings
<b>Lemma</b> (Rings > Factorisation in integral domains)<br><i>[Groups, Rings, and Modules]</i>	In a PID, any irreducible element is also prime.	Groups_Rings_and_Modules lemma Rings
<b>Lemma</b>: PIDs are Noetherian<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a PID. If \( I_1\subseteq I_2\subseteq\cdots \) ideals in \( R \) then for some \( N\in \mathbb{Z}_{> 0} \), we have for all \( n\ge N \), \( I_n=I_{n+1} \).	Groups_Rings_and_Modules lemma Rings
<b>Theorem</b> (Rings > Factorisation in integral domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a principal ideal domain. Then \( R \) is a unique factorisation domain.	Groups_Rings_and_Modules theorem Rings
<b>Definition</b>: Greatest common divisor<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be an integral domain and \( a_1,\dots, a_n\in R \). We say that \( d\in  R \) is a <i>greatest common divisor</i> (GCD) of \( a_1, \dots, a_n \) if:<br><ol><li>\( d\mid a_i \) for all \( i \).</li><li>If \( d'\mid a_i \) for all \( i \) then \( d'\mid d \).</li></ol	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Least common multiple<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be an integral domain and \( a_1,\dots, a_n\in R \). We say that \( m\in R \) is a <i>least common multiple</i> (LCM) of \( a_1,\dots, a_n \) if:<br><ol><li>\( a_i\mid m \) for all \( i \).</li><li>If \( a_i\mid m' \) for all \( i \) then \( m\mid m' \).</li></ol	Groups_Rings_and_Modules definition Rings
<b>Theorem</b> (Rings > Factorisation in integral domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a unique factorisation domain. Then gcd's and lcm's exist and are unique up to associates.	Groups_Rings_and_Modules theorem Rings
<b>Definition</b>: Content<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a unique factorisation domain and let \( f=a_0+a_1X+\cdots+a_nX^n\in R[X] \). We define the <i>content</i> as<br>\[<br>c(f)=\gcd(a_0,\dots,a_n)\in R.<br>\]	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Primitive polynomials<br><i>[Groups, Rings, and Modules]</i>	A polynomial is called <i>primitive</i> if \( c(g) \) is a unit.	Groups_Rings_and_Modules definition Rings
<b>Lemma</b> (Rings > Factorisation in polynomial rings)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a unique factorisation domain. If \( f,g\in R[X] \) are primitive, then so is \( fg \).	Groups_Rings_and_Modules lemma Rings
<b>Corollary</b> (Rings > Factorisation in polynomial rings)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a unique factorisation domain. Then for \( f,g\in R[X] \), \( c(fg) \) is an associate of \( c(f)c(g) \).	Groups_Rings_and_Modules corollary Rings
<b>Lemma</b>: Gauss' lemma<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a unique factorisation domain with \( F \) its field of fractions. Let \( f\in R[X] \) be primitive. Then \( f \) is reducible in \( R[X] \) if and only if \( f \) is reducible in \( F[X] \).	Groups_Rings_and_Modules lemma Rings
<b>Proposition</b> (Rings > Factorisation in polynomial rings)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a unique factorisation domain and \( F \) its field of fractions. Let \( g\in R[X] \) be primitive. Then a polynomial \( f\in R[X] \) is divisble by \( g \) in \( R[X] \) if and only if it is divisble by \( g \) in \( F[X] \). Or in other words if \( J=(g)\triangleleft R[X] \) and \( I=(g)\triangleleft F[X] \) then \( J=I\cap R[X] \).	Groups_Rings_and_Modules proposition Rings
<b>Theorem</b> (Rings > Factorisation in polynomial rings)<br><i>[Groups, Rings, and Modules]</i>	If \( R \) is a unique factorisation domain, then \( R[X] \) is also a unique factorisation domain.	Groups_Rings_and_Modules theorem Rings
<b>Theorem</b>: Eisenstein's criterion<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a unique factorisation domain and<br>\[<br>f=a_0+a_1X+a_2X^2+\cdots+a_nX^n\in R[X]<br>\]<br>is primitive, with \( a_n\ne 0 \). Let \( p\in R \) be irreducible such that<br><ol><li>\( p\nmid a_n \).</li><li>\( p\mid a_i \) for \( 0\le i\le n-1 \).</li><li>\( p^2 \nmid a_0 \).</li></ol><br>Then \( f \) is irreducible in \( R[X] \).	Groups_Rings_and_Modules theorem Rings
<b>Proposition</b> (Rings > Gaussian integers)<br><i>[Groups, Rings, and Modules]</i>	A prime number \( p\in \mathbb{Z} \) remains prime when viewed in \( \mathbb{Z}[i] \) if and only if \( p\ne a^2+b^2 \) for \( a,b\in \mathbb{Z}\setminus \{0\} \).	Groups_Rings_and_Modules proposition Rings
<b>Lemma</b> (Rings > Gaussian integers)<br><i>[Groups, Rings, and Modules]</i>	Let \( p \) be a prime number. Then the group \( \mathbb F_p^\times \) of non-zero elements \( \mod p \) under multiplication is a cyclic group. So \( \mathbb F_p^\times \cong C_{p-1}. \)	Groups_Rings_and_Modules lemma Rings
<b>Theorem</b>: Classification of primes in $ \mathbb{Z}[i] $<br><i>[Groups, Rings, and Modules]</i>	The primes in \( \mathbb{Z}[i] \) up to associates are exactly<br><ol><li>The primes \( p\in\mathbb{Z} \) such that \( p\equiv 3 \mod 4 \).</li><li>Gaussian integers \( z\in \mathbb{Z}[i] \) with \( N(z)=p \) where \( p \) is a prime that is either \( 2 \) or \( 1 \mod 4\).</li></ol	Groups_Rings_and_Modules theorem Rings
<b>Corollary</b> (Rings > Gaussian integers)<br><i>[Groups, Rings, and Modules]</i>	An non-negative integer \( n \) can be written as a sum of two squares if and only if when we write \( n \) as a product of distinct primes,<br>\[<br>n=p_1^{n_1}p_2^{n_2}\cdots p_k^{n_k}<br>\]<br>\( p_i\equiv 3\mod 4 \) implies that \( n_i \) is even.	Groups_Rings_and_Modules corollary Rings
<b>Definition</b>: Algebraic integer<br><i>[Groups, Rings, and Modules]</i>	A complex number \( \alpha\in \mathbb{C} \) is an <i>algebraic integer</i> if it is a root of a monic polynomial in \( \mathbb{Z}[X] \).	Groups_Rings_and_Modules definition Rings
<b>Proposition</b> (Rings > Algebraic integers)<br><i>[Groups, Rings, and Modules]</i>	Let \( \alpha\in \mathbb{C} \) be an algebraic integer. The ideal \( I=\ker (e_\alpha)\triangleleft \mathbb{Z}[X] \) is principal, and \( I=(f_\alpha) \) with \( f_\alpha \) monic and irreducible.	Groups_Rings_and_Modules proposition Rings
<b>Definition</b>: Minimal polynomial<br><i>[Groups, Rings, and Modules]</i>	The <i>minimal polynomial</i> of an algebraic integer \( \alpha \) is the irreducible monic \( f_\alpha \) such that \( (f_\alpha)=\ker (e_\alpha) \).	Groups_Rings_and_Modules definition Rings
<b>Theorem</b> (Rings > Algebraic integers)<br><i>[Groups, Rings, and Modules]</i>	The real root of \( X^5-X+d \) cannot be written using integers and the operations \( \times, +,-,\sqrt[n]{},\div \).	Groups_Rings_and_Modules theorem Rings
<b>Proposition</b> (Rings > Algebraic integers)<br><i>[Groups, Rings, and Modules]</i>	Let \( \alpha\in \mathbb{Q} \) be an algebraic integer. Then \( \alpha\in \mathbb{Z} \).	Groups_Rings_and_Modules proposition Rings
<b>Definition</b>: Noetherian ring<br><i>[Groups, Rings, and Modules]</i>	. A ring is <i>Noetherian</i> if for any chain of ideals<br>\[<br>I_1\subseteq I_2\subseteq I_3\subseteq \cdots<br>\]<br>then there is some \( N \) such that \( I_N=I_{N+1}=\cdots \). This is known as the <i>ascending chain condition</i> (ACC).	Groups_Rings_and_Modules definition Rings
<b>Definition</b>: Finitely generated ideal<br><i>[Groups, Rings, and Modules]</i>	An ideal \( I\triangleleft R \) is finitely generated if it can be written as \( I=(r_1,\dots, r_n) \) for some \( r_1,\dots, r_n\in R \).	Groups_Rings_and_Modules definition Rings
<b>Proposition</b> (Rings > Hilbert's basis theorem)<br><i>[Groups, Rings, and Modules]</i>	A ring \( R \) is Noetherian if and only if every ideal is finitely generated.	Groups_Rings_and_Modules proposition Rings
<b>Theorem</b>: Hilbert's basis theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a Noetherian ring. Then \( R[X] \) is also Noetherian.	Groups_Rings_and_Modules theorem Rings
<b>Corollary</b> (Rings > Hilbert's basis theorem)<br><i>[Groups, Rings, and Modules]</i>	\( \mathbb{Z}[X_1,X_2,\dots, X_n] \) is Noetherian, and for \( F \) a field \( F[X_1,X_2,\dots, X_n]  \) is Noetherian.	Groups_Rings_and_Modules corollary Rings
<b>Corollary</b> (Rings > Hilbert's basis theorem)<br><i>[Groups, Rings, and Modules]</i>	All finitely-generated rings are Noetherian.	Groups_Rings_and_Modules corollary Rings
<b>Definition</b>: R-module<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a communiative ring. Then a quadruple \( (M,+,0_M,\circ) \) is an <i>R-module</i> if<br><ol><li>\( (M,+,0_M) \) is an abelian group.</li><li>\( \circ:R\times M\to M \) satisfies<br>\begin{enumerate}</li><li>\( (r_1+r_2)\circ m = r_1m+r_2m \);</li><li>\( r\circ (m_1+m_2) = (r\circ m_1)+(r\circ m_2)\);</li><li>\( r_1\circ (r_2\circ m)=(r_1\circ r_2)\circ m \); and</li><li>\( 1_R\circ M = m \).</li></ol><br>\end{enumerate}<br>for all \( m_1,m_2,m\in M \) and \( r_1,r_2,r\in R \).	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Submodule<br><i>[Groups, Rings, and Modules]</i>	Let \( M \) be an \( R \)-module. A subgroup \( N\subseteq M \) is an \( R \)<i>-submodule</i> if for every \( n\in N \) and \( r\in R \), we have \( rn\in N \). We write \( N\le M \).	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Quotient module<br><i>[Groups, Rings, and Modules]</i>	Let \( N\le M \) be an \( R \)-module. The <i>quotient module</i> is the group \( M/N \) equipped with<br>\[\begin{aligned}<br>R\times M/N\to M/N \\<br>(r,m+N)\to (rm+N).<br>\end{aligned}\]	Groups_Rings_and_Modules definition Modules
<b>Definition</b> (Modules > Definitions and examples)<br><i>[Groups, Rings, and Modules]</i>	Let \( M,N \) be. \( R \)-modules. An \( R \)-module homomorphism is group homomorphism \( \varphi: M\to N \) such that \( \varphi(rm)=r\varphi(m) \) for all \( r\in R \) and \( m \in M\)	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Isomorphism<br><i>[Groups, Rings, and Modules]</i>	An <i>isomorphism</i> of \( R \)-modules is a bijective homomorphism. We say that the modules are <i>isomorphic</i>.	Groups_Rings_and_Modules definition Modules
<b>Theorem</b>: First isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( \varphi: M\to N\) be a homomorphism of \( R \)-modules. Then<br>\[<br>\ker\varphi=\{m\in M:\varphi(m)=0\}<br>\]<br>is a submodule of \( M \). The image<br>\[<br>\operatorname{im}\varphi= \{\varphi(m):m\in M\}<br>\]<br>is a submodule of \( N \). Furthermore there is an isomorphism<br>\[<br>M/\ker\varphi\cong\operatorname{im}\varphi<br>\]	Groups_Rings_and_Modules theorem Modules
<b>Theorem</b>: Second isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( L,K\le M \) be \( R \)-submodules. Then<br>\[<br>K+L=\{k+\ell :k\in K, \ell\in L\}<br>\]<br>is an \( R \)-submodule of \( M \). Moreover<br>\[<br>\frac{K+L}K\cong \frac L{L\cap K}<br>\]<br>is an isomorphism of \( R \)-modules.	Groups_Rings_and_Modules theorem Modules
<b>Theorem</b>: Third isomorphism theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( N\le L\le M \). Then<br>\[<br>M/L\cong\frac{M/N}{L/N}<br>\]<br>is an isomorphism of \( R \)-modules.	Groups_Rings_and_Modules theorem Modules
<b>Theorem</b>: Correspondence theorem<br><i>[Groups, Rings, and Modules]</i>	We have the correspondence<br>\[<br>\{\text{Submodules of } M/N\}\leftrightarrow{} \{\text{Submodules of } M \text{ which contain } N \}.<br>\]	Groups_Rings_and_Modules theorem Modules
<b>Definition</b>: Annihilator<br><i>[Groups, Rings, and Modules]</i>	Let \( M \) be an \( R \)-module. For \( m\in M \) its <i>annihilator</i> is<br>\[<br>\operatorname{Ann}(m)=\{r\in R:rm=0\}.<br>\]<br>For any set \( S\subseteq M \) we define<br>\[<br>\operatorname{Ann}(S)=\{r\in R:rm=0\text{ for all } m \in S\}=\bigcap_{s\in S}\operatorname{Ann}(s).<br>\]	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Submodule generated by an element<br><i>[Groups, Rings, and Modules]</i>	Let \( M \) be a \( R \)-module and \( m\in M \). The submodule generated by \( m \) is<br>\[<br>Rm=\{rm\in M:r\in R\}.<br>\]	Groups_Rings_and_Modules definition Modules
<b>Proposition</b> (Modules > Definitions and examples)<br><i>[Groups, Rings, and Modules]</i>	For \( m\in M \) there is an isomorphism \( R/\operatorname{Ann}(m)\cong Rm \).	Groups_Rings_and_Modules proposition Modules
<b>Definition</b>: Finite generation<br><i>[Groups, Rings, and Modules]</i>	An \( R \)-module \( M \) is finitely generated if there exists elements \( m_1,\dots,m_k \) such that<br>\[<br>M=Rm_1+Rm_2+\cdots Rm_k=\{r_1m_1+\cdots r_km_k:r_i\in R\}.<br>\]	Groups_Rings_and_Modules definition Modules
<b>Lemma</b> (Modules > Definitions and examples)<br><i>[Groups, Rings, and Modules]</i>	An \( R \)-module \( M \) is finitely generated if and only if there is a surjective \( R \)-module homomorphism from \( R^k\to M \).	Groups_Rings_and_Modules lemma Modules
<b>Corollary</b> (Modules > Definitions and examples)<br><i>[Groups, Rings, and Modules]</i>	If \( M \) is finitely generated \( R \)-module and \( N\le M \) then \( M/N \) is finitely generated.	Groups_Rings_and_Modules corollary Modules
<b>Definition</b>: Direct sum<br><i>[Groups, Rings, and Modules]</i>	Let \( M_1,\dots, M_k \) be \( R \)-modules. The <i>direct sum</i> is the abelian group \( M_1\times\cdots\times M_k \) with scaling<br>\[\begin{aligned}<br>R\times M_1\times\cdots\times M_k\to M_1\times \cdots \times M_k \\<br>(r,m_1,\dots, m_k)\to (rm_1\dots, rm_k)<br>\end{aligned}\]<br>We notate this as \( M_1\oplus \cdots \oplus M_k \).	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Linear independence<br><i>[Groups, Rings, and Modules]</i>	Let \( m_1,\dots, m_k\in M \). Then \( \{m_1,\dots, m_k\} \) is \( R \)<i>-linearly independent</i> if<br>\[<br>\sum r_im_i=0\implies r_i=0\quad\text{for all } i<br>\]	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Free generation<br><i>[Groups, Rings, and Modules]</i>	A subset \( S\subseteq M \) <i>freely generates</i> \( M \) if<br><ol><li>\( S \) generates \( M \)</li><li>Any set function \( f:S\to N \) with \( N \) an \( R \)-module extends to an \( R \)-module homomorphism \( \varphi_f:M\to N \) with the condition \( \varphi_f(s)=f(s)\quad\forall s\in S \).</li></ol	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Free module and basis<br><i>[Groups, Rings, and Modules]</i>	A module \( M \) is <i>free</i> if it is freely generated by some subset \( S\subseteq M \), and \( S \) is called a <i>basis</i>.	Groups_Rings_and_Modules definition Modules
<b>Proposition</b> (Modules > Direct sums and free modules)<br><i>[Groups, Rings, and Modules]</i>	Let \( S=\{m_1,\dots,m_k\}\subseteq M \). Then the following three statement are equivalent<br><ol><li>\( S \) generates \( M \) freely.</li><li>\( S \) generates \( M \) and \( S \) is linearly independent.</li><li>Every \( m\in M \) is uniquely expressible as \( m=r_1m_1+\cdots r_km_k \).</li></ol	Groups_Rings_and_Modules proposition Modules
<b>Definition</b>: Relations<br><i>[Groups, Rings, and Modules]</i>	Let \( M \) be finitely-generated with generators given by \(\theta: R^k\to M \). Then \( \ker \theta \) is called the <i>module of relations</i> of \( M \) with respect to \( \theta \).	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Finitely presented module<br><i>[Groups, Rings, and Modules]</i>	We say that a module is <i>finitely-presented</i> if \( \ker\theta \) is finitely generated.	Groups_Rings_and_Modules definition Modules
<b>Proposition</b>: Invariance of dimension/rank<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a non-zero ring. Then if \( R^n\cong R^m \) then \( n=m \).	Groups_Rings_and_Modules proposition Modules
<b>Definition</b>: Elementary row operations<br><i>[Groups, Rings, and Modules]</i>	Let \( A \) be an \( m\times n \) matrix with entries in \( R \). The <i>elementary row opertaions</i> are the following<br><ol><li>[(ER1)] Add \( c\in R \) times row \( i \) to row \( j \)</li><li>[(ER2)] Swap row \( i \) and row \( j \)</li><li>[(ER3)] Multiply the \( i \)th row by a <i>unit</i> \( c\in R \).</li></ol><br>A similarly we can do column operations in the same way.	Groups_Rings_and_Modules definition Modules
<b>Definition</b>: Equivalent matrices<br><i>[Groups, Rings, and Modules]</i>	Two matrices \( A,B \) over \( R \) are equivalent if \( A \) can be obtained from \( B \) by a sequence of row and column operations. In particular<br>\[<br>B=QA\inv T<br>\]<br>for \( Q,T \) invertible.	Groups_Rings_and_Modules definition Modules
<b>Theorem</b>: Smith normal form<br><i>[Groups, Rings, and Modules]</i>	Any \( m\times n \) matrix over \( R \) is equivalent to one of the form<br>\[<br>\begin{pmatrix}<br>d_1 & & & & \\<br>& d_2 & & & \\<br>& & \ddots & & \\<br>& & & \ddots & \\<br>& & & & 0<br>\end{pmatrix}<br>\]<br>with<br>\[<br>d_1\mid d_2\mid \cdots \mid d_r<br>\]<br>These \( d_i \) are the <i>invariant factors</i> of \( A \)	Groups_Rings_and_Modules theorem Modules
<b>Definition</b>: Fitting ideals<br><i>[Groups, Rings, and Modules]</i>	For \( A \) a matrix over \( R \), the \( k \)th <i>fitting ideal</i> is the ideal<br>\[<br>\operatorname{Fit}_k(A)\triangleleft R<br>\]<br>generated by the \( k\times k \) minors of \( A \).	Groups_Rings_and_Modules definition Modules
<b>Proposition</b> (Modules > Matrices over Euclidean domains)<br><i>[Groups, Rings, and Modules]</i>	If \( A \) and \( B \) are equivalent matrices then<br>\[<br>\operatorname{Fit}_k(A)=\operatorname{Fit}_k(B),\quad \forall k.<br>\]	Groups_Rings_and_Modules proposition Modules
<b>Corollary</b> (Modules > Matrices over Euclidean domains)<br><i>[Groups, Rings, and Modules]</i>	If \( A \) has Smith normal form then<br>\[<br>\operatorname{Fit}_k(A)=(d_1d_2\cdots d_k)<br>\]	Groups_Rings_and_Modules corollary Modules
<b>Proposition</b> (Modules > Matrices over Euclidean domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a principal ideal domain. Any submodule of \( R^m \) can be generated by \( m \) or fewer elements.	Groups_Rings_and_Modules proposition Modules
<b>Theorem</b> (Modules > Matrices over Euclidean domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a Euclidean domain. \( N\le R^m \). There exists a basis \( v_1,\dots, v_m \) for \( R^m \) such that \( N \) is generated by \( d_1v_1,\dots, d_rv_r \) for some \( 0\le r\le m \), \( d_i\in R \) such that \( d_i\mid d_{i+1} \).	Groups_Rings_and_Modules theorem Modules
<b>Theorem</b> (Modules > Matrices over Euclidean domains)<br><i>[Groups, Rings, and Modules]</i>	If \( R \) is a Euclidean domain, then any submodule of \( R^m \) is free.	Groups_Rings_and_Modules theorem Modules
<b>Theorem</b> (Modules > Matrices over Euclidean domains)<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a Euclidean domain. Let \( M \) be a finitely generated \( R \)-module. Then<br>\[<br>M\cong R\oplus \cdots \oplus R\oplus \frac R{(d_1)}\oplus \cdots \oplus\frac R{(d_r)}<br>\]<br>where \( d_i\ne 0 \) and \( d_i\mid d_{i+1} \).	Groups_Rings_and_Modules theorem Modules
<b>Proposition</b>: Chinese remainder theorem<br><i>[Groups, Rings, and Modules]</i>	For \( R \) a Euclidean domain with \( a,b\in R \) such that \( \gcd(a,b)=1 \). Then<br>\[<br>\frac R{(a)}\oplus \frac R{(b)}\cong \frac R{(ab)}.<br>\]	Groups_Rings_and_Modules proposition Modules
<b>Theorem</b>: Prime decomposition theorem<br><i>[Groups, Rings, and Modules]</i>	Let \( R \) be a Euclidean domain and \( M \) be a finitely generated \( R \)-module. Then<br>\[<br>M\cong N_1\oplus \cdots \oplus N_t<br>\]<br>where each \( N_i \) is either \( R \) or \( R/(p^n) \) for some prime \( p \).	Groups_Rings_and_Modules theorem Modules
<b>Lemma</b> (Modules > Modules over $ \F $ and forms of matrices)<br><i>[Groups, Rings, and Modules]</i>	If \( \dim V \) is finite then \( V_\alpha \) is a finitely generated \( \mathbb{F}[X] \)-module.	Groups_Rings_and_Modules lemma Modules
<b>Theorem</b>: Rational canonical form<br><i>[Groups, Rings, and Modules]</i>	Let \( V \) be a finite dimensional vector space over \( \mathbb{F} \) and let \( \alpha\in\mathrm{End}(V) \) giving an \( \mathbb{F}[X] \)-module \( V_\alpha \). Then<br>\[<br>V_\alpha\cong\frac{\mathbb{F}[X]}{(f_1)}\oplus \cdots \oplus \frac{\mathbb{F}[X]}{(f_s)}<br>\]<br>with \( f_1\mid f_2\mid \cdots\mid f_s \) and there exists a basis for \( V \) where \( \alpha \) has block diagonal matrix<br>\[<br>\begin{pmatrix}<br>c(f_1) & & \\<br>& \ddots & \\<br>& & c(f_s)<br>\end{pmatrix}<br>\]<br>where \( c(f_i) \) is the companion matrix for \( f_i \).	Groups_Rings_and_Modules theorem Modules
<b>Lemma</b> (Modules > Modules over $ \F $ and forms of matrices)<br><i>[Groups, Rings, and Modules]</i>	The primes in \( \mathbb{C}[X] \) are exactly \( (X-\alpha) \) for \( \alpha\in \mathbb{C} \).	Groups_Rings_and_Modules lemma Modules
<b>Theorem</b>: Jordan canonical form<br><i>[Groups, Rings, and Modules]</i>	Let \( V \) be a vector space over \( \mathbb{C} \) and let \( \alpha\in \mathrm{End}(V) \). Then<br>\[<br>V_\alpha\cong \frac{\mathbb{C}[X]}{(X-\lambda_1)^{a_1}}\oplus\cdots\oplus\frac{\mathbb{C}[X]}{(X-\lambda_t)^{a_t}}<br>\]<br>and there is a basis where \( \alpha \) is given by the matrix<br>\[<br>\begin{pmatrix}<br>J_{a_1}(\lambda_1) & & \\<br>& \ddots & \\<br>& & J_{a_t}(\lambda_t)<br>\end{pmatrix}<br>\]<br>where \( J_a(\lambda) \) is the \( a\times a \) matrix given by<br>\[<br>\begin{pmatrix}<br>\lambda & 0 & \cdots & 0 \\<br>1 & \lambda & \cdots & 0 \\<br>\vdots & \vdots & \ddots & \vdots \\<br>0 & \cdots & 1 & \lambda<br>\end{pmatrix}<br>\]<br>which is the Jordan canonical form.	Groups_Rings_and_Modules theorem Modules
<b>Definition</b>: Vector Space<br><i>[Linear Algebra]</i>	A \( \mathbb{F} \)<i>-vector space</i> (or a vector space over \( \mathbb{F} \)) is an abelian group \( (V,+,\boldsymbol 0) \) equipped with a function<br>\[\begin{aligned}<br>\mathbb{F}\times V\to V \\<br>(\lambda, v)\to \lambda v<br>\end{aligned}\]<br>which we call scalar multiplication such that \( \forall v,w\in V, \forall \lambda,\mu\in\mathbb{F} \)<br><ol><li>\( (\lambda + \mu)v=\lambda v + \mu v \)</li><li>\( \lambda(v + w)=\lambda v + \lambda w \)</li><li>\( \lambda(\mu v)=(\lambda \mu)v \)</li><li>\( 1\cdot v = v\cdot 1 = v \)</li></ol	Linear_Algebra definition Vector_Spaces
<b>Proposition</b> (Vector Spaces > Definitions)<br><i>[Linear Algebra]</i>	For all \( v\in V \) we have that \( 0\cdot v = \boldsymbol 0 \) and \( (-1)\cdot v=-v \) where \( -v \) denotes the additive inverse of \( v \).	Linear_Algebra proposition Vector_Spaces
<b>Definition</b>: Subspace<br><i>[Linear Algebra]</i>	A <i>subspace</i> of a \( \mathbb{F} \)-vector space \( V \) is a subset \( U\subseteq V \) which is a \( \mathbb{F} \)-vector space itself under the same operations as \( V \). Equivalently, \( (U,+) \) is a subgroup of \( (V,+) \) and \( \forall \lambda\in \mathbb{F} \), \(\forall u\in U \) we have that \( \lambda u \in U \).	Linear_Algebra definition Vector_Spaces
<b>Proposition</b>: Subspace test<br><i>[Linear Algebra]</i>	Let \( V \) be a \( \mathbb{F} \)-vector space and \( U\subseteq V \) then \( U \) is a subspace of \( V \) if and only if,<br><ol><li>\( U \) is nonempty.</li><li>\( \forall \lambda\in\mathbb{F} \) and \( \forall u,w\in U \) we have that \( u+\lambda w \in U \).</li></ol	Linear_Algebra proposition Vector_Spaces
<b>Lemma</b> (Vector Spaces > Definitions)<br><i>[Linear Algebra]</i>	For \( U,W\le V \) we have that \( U\cap W\le V \).	Linear_Algebra lemma Vector_Spaces
<b>Definition</b>: Subspace sum<br><i>[Linear Algebra]</i>	For \( U,W\le V \), the <i>subspace sum</i> of \( U, W \) is<br>\[<br>U+W=\{u+w:u\in U, w\in W\}.<br>\]	Linear_Algebra definition Vector_Spaces
<b>Lemma</b> (Vector Spaces > Definitions)<br><i>[Linear Algebra]</i>	If \( U, W\le V \) then \( U+W\le V \).	Linear_Algebra lemma Vector_Spaces
<b>Definition</b>: Linear map<br><i>[Linear Algebra]</i>	For \( V \), \( W \) \( \mathbb{F} \)-vector spaces. A <i>linear map</i> from \( V \) to \( W \) is a group homomorphism, \( \varphi \), from \( (V,+) \) to \( (W,+) \) such that \( \forall v\in V \)<br>\[<br>\varphi(\lambda v) = \lambda\varphi(v)<br>\]	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: Isomorphism<br><i>[Linear Algebra]</i>	A linear map \( \alpha:V\to W \) is an <i>isomorphism</i> if it is bijective.<br>We say that \( V \) and \( W \) are isomorphic, if there exists an isomorphism from \( V\to W \) and denote this by \( V\cong W \).	Linear_Algebra definition Vector_Spaces
<b>Proposition</b> (Vector Spaces > Linear maps, isomorphisms, and quotients)<br><i>[Linear Algebra]</i>	If \( \alpha: V\to W \) is an isomorphism then \( \inv\alpha:W\to V \) is also an isomorphism.	Linear_Algebra proposition Vector_Spaces
<b>Definition</b>: Kernal<br><i>[Linear Algebra]</i>	Let \( V,W \) be \( \mathbb{F} \)-vector spaces. Then the <i>kernel</i> of the linear map \( \alpha:V\to W \) is<br>\[<br>\ker(\alpha)=\{v\in V:\alpha(v)=\mathbf 0_W\}\subseteq V<br>\]	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: Image<br><i>[Linear Algebra]</i>	Let \( V,W \) be \( \mathbb{F} \)-vector spaces. Then the <i>image</i> of a linear map \( \alpha:V\to W \) is<br>\[<br>\operatorname{im}(\alpha)=\{\alpha(v):v\in V\}\subseteq W<br>\]	Linear_Algebra definition Vector_Spaces
<b>Lemma</b> (Vector Spaces > Linear maps, isomorphisms, and quotients)<br><i>[Linear Algebra]</i>	For a linear map \( \alpha:V\to W \) the following hold.<br><ol><li>\( \ker\alpha\le V \) and \( \operatorname{im} \alpha \le W \)</li><li>\( \alpha \) is surjective if and only if \( \operatorname{im} \alpha =W \)</li><li>\( \alpha \) is injective if and only if \( \ker\alpha=\{\mathbf 0_V\} \)</li></ol	Linear_Algebra lemma Vector_Spaces
<b>Proposition</b> (Vector Spaces > Linear maps, isomorphisms, and quotients)<br><i>[Linear Algebra]</i>	\( V/W \) is an \( \mathbb{F} \)-vector space under operations<br>\[\begin{aligned}<br>(u+W)+(v+W)&=(u+v)+W \\<br>\lambda (v+W)&=(\lambda v)+W<br>\end{aligned}\]<br>We call \( V/W \) the quotient space of \( V \) by \( W \).	Linear_Algebra proposition Vector_Spaces
<b>Proposition</b>: Quotient map<br><i>[Linear Algebra]</i>	The function \( \pi_W: V\to \frac VW \) called a <i>quotient map</i> is given by<br>\[<br>\pi_W(v)=v+W<br>\]<br>is a well-defined, surjective, linear map with \( \ker\pi_W=W \).	Linear_Algebra proposition Vector_Spaces
<b>Theorem</b>: First isomorphism theorem<br><i>[Linear Algebra]</i>	Let \( V,W \) be \( \mathbb{F} \)-vector spaces and \( \alpha:V\to W  \) linear. Then there is an isomorphism<br>\[<br>\overline\alpha:\frac{V}{\ker \alpha}\to\operatorname{im}\alpha<br>\]<br>given by \( \overline\alpha(v+\ker\alpha)=\alpha(v) \)	Linear_Algebra theorem Vector_Spaces
<b>Definition</b>: Span<br><i>[Linear Algebra]</i>	Let \( V \) be a \( \mathbb{F} \)-vector space. Then the <i>span</i> of some subset \( S\subseteq V \) is<br>\[<br>\langle S\rangle = \left\{\sum_{s\in S}\lambda_s\cdot s: \lambda_s\in \mathbb{F}\right\}<br>\]<br>where \( \sum \) denotes finite sums. An expression the form above is called a <i>linear combination</i> of \( S \).\\<br>We say that \( S \) <i>spans</i> \( V \) if \( \langle S\rangle =V \)	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: Finite-dimensional<br><i>[Linear Algebra]</i>	For a vector space \( V \) we say that it is <i>finite-dimensional</i> if there exists a finite spanning set.	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: Linear Independence<br><i>[Linear Algebra]</i>	A subset \( S\subseteq V \) is called <i>linearly independent</i> if, for all finite linear combinations<br>\[<br>\sum_{s\in S}\lambda_ss\quad \text{of S}<br>\]<br>if the sum is the zero vector in \( V \) the \( \lambda_s=0 \) for all \( s\in S \).	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: Basis<br><i>[Linear Algebra]</i>	A subset \( S\subseteq V \) is a <i>basis</i> for \( V \) if \( S \) is linearly independent and a spanning set.	Linear_Algebra definition Vector_Spaces
<b>Proposition</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	If \( S\subseteq V \) is a finite spanning set, then there exists a subset \( S'\subseteq S \) such that \( S' \) is a basis.	Linear_Algebra proposition Vector_Spaces
<b>Corollary</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	Every finite-dimensional vector space has a finite basis.	Linear_Algebra corollary Vector_Spaces
<b>Theorem</b>: Steinitz Exchange Lemma<br><i>[Linear Algebra]</i>	Let \( S,T\subseteq V \) finite with \( S \) linearly independent and \( T \) a spanning set of \( V \). Then<br><ol><li>\( |S|\le |T| \),</li><li>and there exists \( T'\subseteq T \) which has size \( |T'|=|T|-|S| \) and \( S\cup T' \) spans \( V \).</li></ol	Linear_Algebra theorem Vector_Spaces
<b>Corollary</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	For a finite-dimensional vector space \( V \),<br><ol><li>Every basis for \( V \) is finite.</li><li>All finite basis have the same size.</li></ol	Linear_Algebra corollary Vector_Spaces
<b>Definition</b>: Dimension<br><i>[Linear Algebra]</i>	For a vector space \( V \) the <i>dimension</i> of \( V \) is the size of any basis. We write this as \dim V.	Linear_Algebra definition Vector_Spaces
<b>Corollary</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	For a vector space \( V \) let \( S,T\subseteq V \) finite, with \( S \) linearly independent and \( T \) a spanning set, then<br>\[\begin{aligned}<br>|S|\le \dim V\le |T|<br>\end{aligned}\]<br>with equality if and only if \( S \) spans or \( V \) is linearly independent respectively.	Linear_Algebra corollary Vector_Spaces
<b>Proposition</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	If \( V \) is a finite-dimensional vector space, then if \( U\le V \) then \( U \) is finite-dimensional, namely, \( \dim U \le \dim V \) with equality if and only if \( U=V \).	Linear_Algebra proposition Vector_Spaces
<b>Proposition</b>: Extending a basis<br><i>[Linear Algebra]</i>	Let \( U\le V \). For any basis \( B_U \) of \( U \) there exists a basis \( B_V \) of \( V \) such that \( B_U\subseteq B_V \).	Linear_Algebra proposition Vector_Spaces
<b>Definition</b>: Nullity<br><i>[Linear Algebra]</i>	For a linear map \( \alpha:V\to W \) we define the <i>nullity</i> of \( \alpha \) as<br>\[<br>\mathrm{n}(\alpha)=\dim\ker\alpha.<br>\]	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: Rank<br><i>[Linear Algebra]</i>	For a linear map \( \alpha:V\to W \) we define the <i>rank</i> of \( \alpha \) as<br>\[<br>\mathrm{rk}(\alpha)=\dim\operatorname{im}\alpha.<br>\]	Linear_Algebra definition Vector_Spaces
<b>Theorem</b>: Rank-nullity theorem<br><i>[Linear Algebra]</i>	If \( V \) is a finite dimensional \( \mathbb{F} \)-vector space and \( W  \) is a \( \mathbb{F} \)-vector space. Then if \( \alpha:V\to W \) is linear then \( \operatorname{im} \alpha \) is finite dimensional and<br>\[<br>\dim V=\mathrm{n}(\alpha)+\mathrm{rk}(\alpha).<br>\]	Linear_Algebra theorem Vector_Spaces
<b>Lemma</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	For \( U\le V \),<br>\[<br>\dim(V/U)=\dim V-\dim U<br>\]	Linear_Algebra lemma Vector_Spaces
<b>Corollary</b>: Linear Pigeonhole principle<br><i>[Linear Algebra]</i>	If \( \dim V=\dim W=n \) and \( \alpha: V\to W \) then the following conditions are equivalent.<br><ol><li>\( \alpha \) is injective,</li><li>\( \alpha \) is surjective,</li><li>\( \alpha \) is an isomorphism.</li></ol	Linear_Algebra corollary Vector_Spaces
<b>Proposition</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	Suppose \( V \) is a vector space with a basis \( B \). For any vector space \( W  \) and any function \( f:B\to W \) there is a unique linear map \( F:V\to W \) such that \( F(B)=W \).	Linear_Algebra proposition Vector_Spaces
<b>Corollary</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	For a vector space, \( V \), with \( \dim V=n \) with a basis \( B=\{v_1,\dots, v_n\} \) for \( V \) then there is a unique isomorphism<br>\[\begin{aligned}<br>F_B:V&\to \mathbb{F}^n\\<br>\sum_{i=1}^n\lambda_iv_i &\to \begin{pmatrix}<br>\lambda_1\\<br>\vdots \\<br>\lambda_n<br>\end{pmatrix}<br>\end{aligned}\]	Linear_Algebra corollary Vector_Spaces
<b>Corollary</b> (Vector Spaces > Basis)<br><i>[Linear Algebra]</i>	If \( V,W \) are finite dimensional \( \mathbb{F} \)-vector spaces. Then<br>\[<br>V\cong W\iff \dim V=\dim W<br>\]	Linear_Algebra corollary Vector_Spaces
<b>Definition</b>: Coordinate vector<br><i>[Linear Algebra]</i>	\( F_B(v)=[v]_B \) is the <i>coordinate vector</i> of \( v \) with respect to the basis \( B \)	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: External direct sum<br><i>[Linear Algebra]</i>	For \( \mathbb{F} \)-vector spaces, \( V \) and \( W \), we dnote the <i>external direct sum</i> of \( V \) and \( W \) as \( V\oplus W \) with underlying set \( V\times W \) with addition and scalar multiplication given in the obvious sense.	Linear_Algebra definition Vector_Spaces
<b>Lemma</b> (Vector Spaces > Direct sums)<br><i>[Linear Algebra]</i>	For \( V,W \) finite dimensional vector spaces,<br>\[<br>\dim(V\oplus W)=\dim V+\dim W<br>\]	Linear_Algebra lemma Vector_Spaces
<b>Proposition</b> (Vector Spaces > Direct sums)<br><i>[Linear Algebra]</i>	Let \( V \) be a vector space with \( U,W\le V \). There is a surjective linear map<br>\[\begin{aligned}<br>\varphi: U\oplus W &\to U+W\\<br>(u,w) &\to u+w<br>\end{aligned}\]<br>with \( \ker\varphi\cong U\cap W \).	Linear_Algebra proposition Vector_Spaces
<b>Corollary</b>: Sum-Intersection Formula<br><i>[Linear Algebra]</i>	If \( V \) is finite dimensional and \( U,W\le V \) then<br>\[<br>\dim (U+W)=\dim U + \dim V-\dim(U\cup V)<br>\]	Linear_Algebra corollary Vector_Spaces
<b>Definition</b>: Internal direct sum<br><i>[Linear Algebra]</i>	Suppose \( U,W\le V \) satisify<br><ol><li>\( U+W=V \),</li><li>\( U\cap W=\{\mathbf 0_V\} \).</li></ol><br>Then<br>\[\begin{aligned}<br>\varphi: U\oplus W\to V<br>\end{aligned}\]<br>is an isomorphism, and we say that \( V \) is the <i>internal direct sum</i> of \( U \) and \( W \), and we write that \( V=U\oplus W \).	Linear_Algebra definition Vector_Spaces
<b>Definition</b>: Direct complement<br><i>[Linear Algebra]</i>	For \( U\le V \) a <i>direct complement</i> to \( U \) in \( V \) is a subspace \( W\le V \) satisfying \( V=U\oplus W \).	Linear_Algebra definition Vector_Spaces
<b>Proposition</b> (Vector Spaces > Direct sums)<br><i>[Linear Algebra]</i>	If \( V \) is finite dimensional then every subspace has a direct complement.	Linear_Algebra proposition Vector_Spaces
<b>Definition</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	For \( V,W \) \( \mathbb{F} \)-vector spaces we define<br>\[<br>\mathcal L(V,W)=\{\alpha:V\to W:\alpha\text{ is linear} \}<br>\]<br>which forms a \( \mathbb{F} \)-vector space under pointwise addition and obvious scalar multiplication.	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Definition</b>: Matrix<br><i>[Linear Algebra]</i>	The <i>matrix</i> of \( \alpha \) with respect to the ordered basis \( B,C \) is<br>\[<br>[\alpha]^B_C=(a_{ij})\in M_{m\times n}(\mathbb{F})<br>\]	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Theorem</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	For finite-dimensional vector spaces \( V,W \) with basis \( B,C \) respectively and \( \alpha:V\to W \) linear  then<br>\begin{enumerate}<br>\item For all \( v\in V \)<br>\[<br>[\alpha]^B_C[v]_B=[\alpha(v)]_C<br>\]<br>\item \( [\alpha]_C^B \) is the only matrix \( A\in M_{m\times n}(\mathbb{F}) \) satisfying \( A[v]_B =[\alpha(v)]_C \) for all \( v\in V \).<br>\item There is an isomorphism of \( \mathbb{F} \)-vector spaces<br>\[\begin{aligned}<br>\varepsilon_C^B:\mathcal L(V,W)&\to M_{m\times n}(\mathbb{F})\\<br>\alpha &\to [\alpha]^B_C<br>\end{aligned}\]	Linear_Algebra theorem Matrices_and_Linear_Maps
<b>Proposition</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	Let \( V,W,X \) be finite-dimensional \( \mathbb{F} \)-vector spaces with basis \( B,C,D \) and \( \alpha\in\mathcal L(V,W) \) and \( \beta\in\mathcal L(W,X) \). Then<br>\[<br>[\beta\circ \alpha]^B_D=[\beta]^C_D[\alpha]^B_C.<br>\]	Linear_Algebra proposition Matrices_and_Linear_Maps
<b>Definition</b>: Change of basis matrix<br><i>[Linear Algebra]</i>	Let \( B,B' \) be basis for \( V \) and \( \dim V=n \). The <i>change of basis matrix</i> from \( B \) to \( B' \) is given by<br>\[<br>P=[\mathrm{id}_V]^B_{B'}\in M_{m\times n}(\mathbb{F})<br>\]	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Proposition</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	For \( V,W \) finite-dimensional vector spaces,\smallskip<br><ol><li>\( [\mathrm{id}_V]^B_{B'}\in GL_n(\mathbb{F}) \) with inverse \( [\mathrm{id}_V]^{B'}_B \).</li><li>If \( \alpha\in\mathcal L(V,W) \) and \( B,B' \) basis for \( V \) and \( C,C' \) basis for \( W \), then<br>\[<br>[\alpha]^{B'}_{C'}=[\mathrm{id}_W]^C_{C'}[\alpha]^B_C[\mathrm{id}_V]^{B'}_B.<br>\]</li></ol	Linear_Algebra proposition Matrices_and_Linear_Maps
<b>Definition</b>: Equivalent matrices<br><i>[Linear Algebra]</i>	Let \( A,A'\in M_{m\times n}(\mathbb{F}) \). We say that \( A \) and \( A' \) are <i>equivalent</i> if \( \exists P\in GL_m(\mathbb{F}) \), \( Q\in GL_n(\mathbb{F}) \) such that \( A'=PAQ \).	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Theorem</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	Let \( V,W \) be finite-dimensional \( \mathbb{F} \)-vector spaces. Let \( \dim V=n \), \( \dim W=m \) and let \( \alpha\in\mathcal L(V,W) \). Let \( r=\mathrm{rk}(\alpha) \). Then,<br><ol><li>There exists basis \( B,C \) for \( V,W \) respectively such that<br>\[<br>[\alpha]^B_C=\begin{pmatrix}<br>I_r & 0 \\<br>0 & 0<br>\end{pmatrix}\in M_{m\times n}(\mathbb{F})<br>\]<br>where \( I_r \) is the identity matrix of size \( r \), and the zeros are block zero matrices.</li><li>If \[<br>[\alpha]^{B'}_{C'}=\begin{pmatrix}<br>I_{r'} & 0 \\<br>0 & 0<br>\end{pmatrix}\in M_{m\times n}(\mathbb{F})<br>\]<br>for some basis \( B',C'\) of \( V,W \) respectively, then \( r'=r \)</li></ol	Linear_Algebra theorem Matrices_and_Linear_Maps
<b>Definition</b>: Column-space<br><i>[Linear Algebra]</i>	For \( A\in M_{m\times n}(\mathbb{F}) \) the <i>column-space</i> \( \mathrm{Col}(A) \) is the subspace of \( \mathbb{F}^m \) spanned by the columns of \( A \). The dimension of the column-space is called the <i>column-rank</i> of \( A \).	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Definition</b>: Row-space<br><i>[Linear Algebra]</i>	For \( A\in M_{m\times n}(\mathbb{F}) \) the <i>row-space</i> \( \mathrm{Row}(A) \) is the subspace of \( \mathbb{F}^m \) spanned by the rows of \( A \) (when transposed as column vectors). The dimension of the row-space is called the <i>row-rank</i> of \( A \).	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Theorem</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	Let \( A, A' \in M_{m\times n}(\mathbb{F}) \), then<br><ol><li>\( A \) is equivalent to<br>\[<br>\begin{pmatrix}<br>I_r & 0 \\<br>0 & 0<br>\end{pmatrix}<br>\text{ where } r \text{ is the column-rank of } A<br>\]</li><li>\( A \) and \( A' \) are equivalent if and only if the have the same column-rank.</li></ol	Linear_Algebra theorem Matrices_and_Linear_Maps
<b>Lemma</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	For \( A\in M_{m\times n}(\mathbb{F}) \) and \( B\in M_{n\times p}(\mathbb{F}) \) then \( \mathrm{rk}(A\cdot B)\le \min(\mathrm{rk}(A),\mathrm{rk}(B)) \).	Linear_Algebra lemma Matrices_and_Linear_Maps
<b>Theorem</b> (Matrices and Linear Maps > Vector spaces of linear maps)<br><i>[Linear Algebra]</i>	For any \( A\in M_{m\times n}(\mathbb{F}) \), the row-rank of \( A \) is equal to the column-rank of \( A \).	Linear_Algebra theorem Matrices_and_Linear_Maps
<b>Definition</b>: Similarity<br><i>[Linear Algebra]</i>	For matrices \( A,A'\in M_{n\times m}(\mathbb{F}) \) are <i>similar</i> if there exists \( P\in GL_n(\mathbb{F}) \) such that \( A'=\inv P AP \).	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Definition</b>: Elementary row operations<br><i>[Linear Algebra]</i>	Let \( r_1,\dots, r_m \) be the rows of \( A \). We have three types of <i>elementary row operations</i> on \( A \)<br><ol><li>Swap \( r_i \) and \( r_j \) with \( i\ne j \).</li><li>Replace \( r_i \) with \( \lambda r_i \) with \( 0\ne\lambda\in\mathbb{F} \).</li><li>Replace \( r_i \) with \( r_i+\lambda r_j \) with \( \lambda\in \mathbb{F} \) and \( i\ne j \).</li></ol	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Lemma</b> (Matrices and Linear Maps > Elementary operations on matrices)<br><i>[Linear Algebra]</i>	If \( E \) is a matrix of type (i)-(iii) then \( EA \) is obtained from \( A \) by applying the corresponding ERO to \( A \).	Linear_Algebra lemma Matrices_and_Linear_Maps
<b>Definition</b>: Row reduced echelon form<br><i>[Linear Algebra]</i>	A matrix \( A\in M_{m\times n}(\mathbb{F}) \) is said to be in <i>row reduced echelon form</i> (RRE) if<br><ol><li>All non-zero rows of \( A \) appear above all zero rows.</li><li>The leftmost non-zero element of a non-zero row is \( 1 \) (called the <i>pivot entry</i>).</li><li>If row \( r_i,r_j \) are non-zero rows with \( i<j \) then the index of the pivot entry of \( i \) is less than the index of the pivot entry of \( j \).</li><li>In a column containing a pivot entry, every other entry is zero.</li></ol	Linear_Algebra definition Matrices_and_Linear_Maps
<b>Lemma</b> (Matrices and Linear Maps > Elementary operations on matrices)<br><i>[Linear Algebra]</i>	If \( A \) is in row reduced echelon form then the row rank of \( A \) is the number of non-zero rows of \( A \).	Linear_Algebra lemma Matrices_and_Linear_Maps
<b>Proposition</b> (Matrices and Linear Maps > Elementary operations on matrices)<br><i>[Linear Algebra]</i>	Every matrix \( A \in M_{m\times n}(\mathbb{F}) \) can be put into row reduced echelon form with elementary row operations.	Linear_Algebra proposition Matrices_and_Linear_Maps
<b>Theorem</b> (Matrices and Linear Maps > Elementary operations on matrices)<br><i>[Linear Algebra]</i>	For \( A\in M_{m\times n}(\mathbb{F}) \) the following are equivalent:<br><ol><li>\( \mathrm{rk} (A)=n \).</li><li>\( A \) is a product of elementary matrices.</li><li>\( A \) is invertible.</li></ol	Linear_Algebra theorem Matrices_and_Linear_Maps
<b>Theorem</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	There exists a unique function \( F:M_{m\times n}\to \mathbb{F} \) satisfying<br><ol><li>(Alternating) If \( c_i=c_j \) for some \( i\ne j \) then \( F(A)=0 \).</li><li>(Multilinear in columns) For all \( 1\le i\le n \) and \( v_j\in \mathbb{F}^n \) the function<br>\[\begin{aligned}<br>\mathbb{F}^n&\to \mathbb{F}\\<br>v&\to F(v_1\mid \cdots \mid v_{j-1} \mid v \mid v_{j+1} \mid \cdots \mid v_n )<br>\end{aligned}\]<br>is linear.</li><li>\( F(I_n)=1 \).</li></ol	Linear_Algebra theorem Determinant_and_Traces
<b>Definition</b>: Determinant<br><i>[Linear Algebra]</i>	We shall defined the \( F \) in the previous theorem as the \( n \)<i>-dimensional determinant</i>, written as \( F(A)=\det(A) \). A function satisfying conditions (i) and (ii) of the theorem is called an \( n \)-<i>-dimensional volumn form</i>.	Linear_Algebra definition Determinant_and_Traces
<b>Lemma</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	If \( F \) is an \( n \)-dimensional volumn form, \( A\in M_{m\times n}(\mathbb{F}) \),<br><ol><li>If \( A \) has a zero column then \( F(A)=0 \),</li><li>\( F(AT_{ij})=-F(A) \),</li><li>\( F(AM_{i,\lambda})=\lambda F(A) \),</li><li>\( F(AC_{i,j,\lambda})=F(A) \).</li></ol	Linear_Algebra lemma Determinant_and_Traces
<b>Corollary</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	\( \det A\ne 0 \) if and only if \( A \) is invertible. In this case, \( A=E_1\cdots E_\ell \) then \( \det A=\det(E_1)\cdots \det(E_\ell) \).	Linear_Algebra corollary Determinant_and_Traces
<b>Lemma</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	For \( A\in M_{n\times n}(\mathbb{F}) \), we have that \( \det(A^T)=\det(A) \).	Linear_Algebra lemma Determinant_and_Traces
<b>Proposition</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	For all \( A,B\in M_{n\times n}(\mathbb{F}) \) we have that \( \det(AB)=\det(A)\det(B) \).	Linear_Algebra proposition Determinant_and_Traces
<b>Definition</b>: Trace<br><i>[Linear Algebra]</i>	For a \( A\in M_{m\times n}(\mathbb{F}) \) the <i>trace</i> of \( A \) is given by<br>\[<br>\tr(A)=\sum_{i=1}^na_{i,i}<br>\]	Linear_Algebra definition Determinant_and_Traces
<b>Lemma</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	For all \( A,B\in M_{m\times n}(\mathbb{F}) \) we have that<br>\[<br>\tr(AB)=\tr(BA)<br>\]	Linear_Algebra lemma Determinant_and_Traces
<b>Corollary</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	Similar matrices have the same trace.	Linear_Algebra corollary Determinant_and_Traces
<b>Definition</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	For \( V \) a finite dimensional vector space and \( \alpha\in\mathcal L(V,V) \) define the <i>trace</i> of \( \alpha \) by<br>\[<br>\tr(\alpha)=\tr([\alpha]_B^B)<br>\]<br>for \( B \) a basis of \( V \).	Linear_Algebra definition Determinant_and_Traces
<b>Proposition</b> (Determinant and Traces > Determinant)<br><i>[Linear Algebra]</i>	This is independent of the basis \( B \).	Linear_Algebra proposition Determinant_and_Traces
<b>Definition</b>: Dual space<br><i>[Linear Algebra]</i>	If \( V \) is a \( \mathbb{F} \)-vector space, then the <i>dual space</i> of \( V \) is<br>\[<br>V^*=\mathcal L(V,\mathbb{F})=\{\theta:V\to\mathbb{F}: \theta\text{ is linear }\}<br>\]	Linear_Algebra definition Dual_Spaces
<b>Proposition</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	For \( B^* \) defined above,<br><ol><li>\( B^* \) is linearly independent;</li><li>If \( V \) is finite dimensional then \( B^* \) is a basis for \( V^* \).</li></ol	Linear_Algebra proposition Dual_Spaces
<b>Definition</b>: Dual basis<br><i>[Linear Algebra]</i>	If \( V \) is finite dimensional, call \( B^* \) the <i>dual basis</i> to \( B \).	Linear_Algebra definition Dual_Spaces
<b>Corollary</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	For \( V \) finite dimensional \( V\cong V^* \)	Linear_Algebra corollary Dual_Spaces
<b>Definition</b>: Annihilator<br><i>[Linear Algebra]</i>	For \( V \) a finite dimensional \( \mathbb{F} \)-vector space and \( S\subseteq V \), the <i>annihilator</i> of \( S \) is<br>\[<br>S^0=\{\theta\in V^*:\forall s\in S,\theta(s)=0\}\subseteq V^*<br>\]	Linear_Algebra definition Dual_Spaces
<b>Lemma</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	For and \( S,T\subseteq V \),<br><ol><li>\( S^0 \le V^* \);</li><li>If \( S\subseteq T \) then \( T^0\le S^0 \);</li><li>\( S^0=\langle S\rangle^0 \);</li><li>\( V^0=\{\mathbf 0_{V^*}\} \) and \( \{\mathbf 0_V\}^0=V^* \).</li></ol	Linear_Algebra lemma Dual_Spaces
<b>Proposition</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	For \( V \) finite dimensional with \( U\le V \), we have that<br>\[<br>\dim V=\dim U + \dim U^0<br>\]	Linear_Algebra proposition Dual_Spaces
<b>Proposition</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	If \( V \) is a \( \mathbb{F} \)-vector space  and \( U,W\le V \) then<br><ol><li>\( U^0\cap W^0=(U+W)^0 \);</li><li>\( U^0+W^0\le (U\cap W)^0 \);</li><li>If \( V \) is finite dimensional then we have equality in (ii).</li></ol	Linear_Algebra proposition Dual_Spaces
<b>Definition</b>: Dual map<br><i>[Linear Algebra]</i>	If \( \alpha\in\mathcal L(V,W) \) then the <i>dual map</i> of \( \alpha \) is \( \alpha^*:W^*\to V^* \) given by<br>\[<br>\alpha^*(\theta)=\theta\circ \alpha<br>\]	Linear_Algebra definition Dual_Spaces
<b>Lemma</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	If \( \alpha,\beta\in \mathcal L(V,W) \) and \( \gamma\in\mathcal L(U,V) \) and \( \lambda \in \mathbb{F} \) then:<br><ol><li>\( \alpha^* \) is linear;</li><li>\( (\alpha+\lambda\beta)^*=\alpha^*+\lambda\beta^* \);</li><li>\( (\alpha\circ \gamma)^*=\gamma^*\alpha^* \);</li><li>If \( \beta \) is an isomorphism then so is \( \beta^* \) and \({(\beta^*)}^{-1}=(\inv \beta)^* \).</li></ol	Linear_Algebra lemma Dual_Spaces
<b>Proposition</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	Let \( V,W \) be finite dimensional vector spaces and \( \alpha\in \mathcal L(V,W) \). Let \( B,C \) be basis for \( V,W \) Then<br>\[<br>[\alpha^*]_{B^*}^{C^*}=\left([\alpha]^B_C\right)^T.<br>\]	Linear_Algebra proposition Dual_Spaces
<b>Corollary</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	Let \( V,W \) and \( \alpha\) be as in the previous proposition. Then<br>\[<br>\mathrm{rk}(\alpha^*)=\mathrm{rk}(\alpha)<br>\]	Linear_Algebra corollary Dual_Spaces
<b>Proposition</b> (Dual Spaces)<br><i>[Linear Algebra]</i>	Let \( V,W \) be \( \mathbb{F} \)-vector spaces. Then if \( \alpha\in\mathcal L(V,W) \),<br><ol><li>\( \ker(\alpha^*)=\operatorname{im}(\alpha)^0 \);</li><li>\( \operatorname{im}(\alpha^*)\le (\ker(\alpha))^0 \);</li><li>If \( V,W \) are finite dimensional, then we have equality in (ii).</li></ol	Linear_Algebra proposition Dual_Spaces
<b>Theorem</b> (Dual Spaces > The double dual)<br><i>[Linear Algebra]</i>	If \( V \) is a \( \mathbb{F} \)-vector space then there is a linear map \( \mathcal E:V\to V^{**} \) given by<br>\[<br>\mathcal E(v)(\theta)=\theta(v)\quad\text{for }v\in V, \theta\in V^*<br>\]<br>where if \( V \) is finite dimensional then \( \varepsilon \) is an isomorphism.	Linear_Algebra theorem Dual_Spaces
<b>Definition</b> (Dual Spaces > The double dual)<br><i>[Linear Algebra]</i>	We call \( \mathcal E:V\to V^{**} \) the <i>evaluation map</i> or the <i>natural isomorphism</i>.	Linear_Algebra definition Dual_Spaces
<b>Proposition</b> (Dual Spaces > The double dual)<br><i>[Linear Algebra]</i>	Every basis \( C \) for \( V^* \) is the dual basis to some basis of \( V \).	Linear_Algebra proposition Dual_Spaces
<b>Proposition</b> (Dual Spaces > The double dual)<br><i>[Linear Algebra]</i>	For \( U\le V \),<br>\[<br>\mathcal E(U)=(U^0)^0\le V^{**}<br>\]	Linear_Algebra proposition Dual_Spaces
<b>Definition</b>: Polynomial<br><i>[Linear Algebra]</i>	A <i>polynomial</i> \( f \) over \( \mathbb{F} \) is a formal expression:<br>\[<br>f(t)=\sum_{i=0}^na_it^i\quad n\in \mathbb{Z}_{\ge 0},\ a_i\in \mathbb{F}<br>\]	Linear_Algebra definition Dual_Spaces
<b>Definition</b>: Degree<br><i>[Linear Algebra]</i>	The <i>degree</i> of \( f \), written, \( \deg f \) is the largest \( i \) such that \( a_i\ne 0 \). We also say that \( \deg 0 = -\infty \).	Linear_Algebra definition Dual_Spaces
<b>Proposition</b>: Euclidean algorithm for polynomials in $ X $<br><i>[Linear Algebra]</i>	Let \( K \) be a field and \( f,g\in K[X] \). Then there exists polynomials \( r,q\in K[X] \) such that \( f=gq+r \) with \( \mathrm{deg}(r)<\mathrm{deg}(g) \).	Linear_Algebra proposition Dual_Spaces
<b>Corollary</b>: Bezout's Lemma<br><i>[Linear Algebra]</i>	If \( f_1,\dots, f_n\in \mathbb{F}[t] \) have no common divisor of degree \( \ge \) 1 (i.e the \( \gcd \) is a unit) then \( \exists g_1,\dots, g_n\in \mathbb{F}[t] \) such that<br>\[<br>\sum_{i=1}^nf_ig_i=1\quad\in \mathbb{F}[t].<br>\]	Linear_Algebra corollary Dual_Spaces
<b>Lemma</b> (Dual Spaces > Polynomials)<br><i>[Linear Algebra]</i>	For \( \lambda\in \mathbb{F} \),<br>\[<br>f(\lambda)=0\iff (t-\lambda)\mid f(t).<br>\]	Linear_Algebra lemma Dual_Spaces
<b>Definition</b>: Root<br><i>[Linear Algebra]</i>	\( \lambda\in \mathbb{F} \) is a <i>root</i> of \( f\in \mathbb{F}[t] \) of <i>multiplicity</i> greater than \( e \) if<br>\[<br>(t-\lambda)^e\mid f(t).<br>\]	Linear_Algebra definition Dual_Spaces
<b>Corollary</b> (Dual Spaces > Polynomials)<br><i>[Linear Algebra]</i>	If \( \deg f = n\ge 0 \), then \( f \) has at most \( n \) roots counted with multiplicity.	Linear_Algebra corollary Dual_Spaces
<b>Corollary</b> (Dual Spaces > Polynomials)<br><i>[Linear Algebra]</i>	If \( \deg f,\deg g < n \), and there exists \( \lambda_1,\dots, \lambda_n\in \mathbb{F} \) distinct such that \( f(\lambda_i)=g(\lambda_i) \) for \( 1\le i\le n \), then \( f=g \).	Linear_Algebra corollary Dual_Spaces
<b>Theorem</b>: Fundamental Theorem of Algebra<br><i>[Linear Algebra]</i>	Every \( f\in \mathbb{C}[t] \) of \( \deg f\ge 1 \) has exactly \( n \) roots counting multiplicity. i.e. \( f \) is a product of polynomials of degree \( 1 \).	Linear_Algebra theorem Dual_Spaces
<b>Definition</b>: Diagonalisable<br><i>[Linear Algebra]</i>	Let \( V \) be a finite dimensional vector space, and \( \alpha\in\mathcal L(V,V) \). Then \( \alpha \) is <i>diagonalisable</i> if there exists a basis \( B \) of \( V \) such that \( [\alpha]^B_B \) is a diagonal matrix.	Linear_Algebra definition Eigenspaces
<b>Definition</b>: Triangularisable<br><i>[Linear Algebra]</i>	Let \( V \) be a finite dimensional vector space, and \( \alpha\in\mathcal L(V,V) \). Then \( \alpha \) is <i>triangularisable</i> if there exists a basis \( B \) of \( V \) such that \( [\alpha]^B_B \) is an upper-triangular matrix.	Linear_Algebra definition Eigenspaces
<b>Definition</b>: Eigenvalues, Eigenvectors, and Eigensapces<br><i>[Linear Algebra]</i>	Let \( V \) be a \( \mathbb{F} \)-vector space and \( \alpha\in\mathcal L(v,v) \). An element \( \lambda\in \mathbb{F} \) is an <i>eigenvalue</i> of \( \alpha \) if there exists some \( v\in\V \) non-zero such that \( \alpha(v)=\lambda v \). Such a vector is a \( \lambda \)-<i>eigenvector</i> of \( \alpha \).<br>\[<br>V_\lambda=\{v\in V:\alpha(v)=\lambda (v)\}<br>\]<br>is the \( \lambda \)-<i>eigenspace</i> of \( \alpha \).	Linear_Algebra definition Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	If \( \lambda_1,\dots, \lambda_k\in\mathbb{F} \) are distinct and \( \mathbf 0 \ne v_i\in V_{\lambda_i} \) then \( \{v_1,\dots, v_k\} \) is linearly independent.	Linear_Algebra lemma Eigenspaces
<b>Corollary</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	If \( V \) is a finite dimensional vector space, then every \( \alpha\in\mathcal L(V,V) \) has only finitely many eigenvalues.	Linear_Algebra corollary Eigenspaces
<b>Proposition</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Let \( V \) be a finite dimensional \( \mathbb{F} \)-vector space, and let \( \alpha\in\mathcal L(V,V) \). Let \( \lambda_1,\dots, \lambda_k\in\mathbb{F} \) be all the eigenvalues of \( \alpha \). Then,<br><ol><li>\( \langle V_{\lambda_1}\cup \cdots \cup V_{\lambda_k}\rangle= V_{\lambda_1}\oplus \cdots \oplus V_{\lambda_k} \);</li><li>\( \alpha \) is diagonalisable if and only if \( V=V_{\lambda_1}\oplus \cdots \oplus V_{\lambda_k} \).</li></ol	Linear_Algebra proposition Eigenspaces
<b>Definition</b>: Characteristic polynomial<br><i>[Linear Algebra]</i>	For \( A\in M_{n\times n}(\mathbb{F}) \), the <i>characteristic polynomial</i> of \( A \) is<br>\[<br>\chi_A(t)=\det(tI_n-A)\in \mathbb{F}[t].<br>\]	Linear_Algebra definition Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	For \( V \) a finite dimensional vector space, and \( \alpha\in\mathcal L(,V) \), we have that the set of roots of \( \chi_A(t) \) are exactly the set eigenvalues of \( \alpha \).	Linear_Algebra lemma Eigenspaces
<b>Proposition</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	If \( \alpha \) is triangularisable then \( \chi_\alpha(t) \) can be written as aproduct of linear factors.	Linear_Algebra proposition Eigenspaces
<b>Theorem</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Every \( A\in M_{n\times n}(\mathbb{C}) \) is triangularisable.`	Linear_Algebra theorem Eigenspaces
<b>Corollary</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Let \( V \) be a finite dimensional \( \mathbb{C} \)-vector space. Then every \( \alpha\in \mathcal L(V,V) \) is triangularisable.	Linear_Algebra corollary Eigenspaces
<b>Definition</b>: Minimal polynomial<br><i>[Linear Algebra]</i>	We call \( m_\alpha \) the <i>minimial polynomial</i>.	Linear_Algebra definition Eigenspaces
<b>Proposition</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	The minimial polynomial is unique.	Linear_Algebra proposition Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	For any \( f\in I_\alpha \), we have that \( m\alpha\mid f \).	Linear_Algebra lemma Eigenspaces
<b>Theorem</b>: Cayley-Hamilton Theorem<br><i>[Linear Algebra]</i>	For \( \alpha\in \mathcal L(V,V) \) we have that<br>\[<br>\chi_\alpha(\alpha)=0.<br>\]	Linear_Algebra theorem Eigenspaces
<b>Corollary</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	\( m_\alpha\mid \chi_\alpha \).	Linear_Algebra corollary Eigenspaces
<b>Definition</b>: Algebraic multiplicity<br><i>[Linear Algebra]</i>	Let \( \lambda\in \mathbb{F} \) be an eigenvalue of \( \alpha \). The <i>algebraic multiplicity</i> \( a_\lambda \) of \( \alpha \) is the multiplicity of \( \lambda \) as a root of \( \chi_\alpha(t) \).	Linear_Algebra definition Eigenspaces
<b>Definition</b>: Geometric multiplicity<br><i>[Linear Algebra]</i>	Let \( \lambda\in \mathbb{F} \) be an eigenvalue of \( \alpha \). The <i>geometric multiplicity</i> \( g_\lambda \) of \( \lambda \) is \( \dim(V_\lambda) \).	Linear_Algebra definition Eigenspaces
<b>Proposition</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Let \( \lambda\in\mathbb{F} \) be an eigenvalue of \( \alpha \) then we have that<br>\[<br>g_\lambda\le a_\lambda.<br>\]	Linear_Algebra proposition Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Let the eigenvalues of \( \alpha \) be \( \lambda_1,\dots, \lambda_k\in \mathbb{F} \).<br><ol><li>\[<br>\sum_{i=1}^k g_{\lambda_i}\le \dim V<br>\]<br>with equality if and only if \( \alpha \) is diagonalisable.</li><li>\[<br>\sum_{i=1}^ka_{\lambda_i}\le \dim V<br>\]<br>with equality if and only if \( \alpha \) is triangularisable.</li></ol	Linear_Algebra lemma Eigenspaces
<b>Proposition</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	For \( \mathbb{F}=\mathbb{C} \), \( \alpha \) is diagonalisable if and only if \( a_\lambda=g_\lambda \) for every eigenvalue \( \lambda \) of \( \alpha \).	Linear_Algebra proposition Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	For any \( \lambda \in \mathbb{F} \), \( \lambda \) is a root of \( m_\alpha \) is and only if it is a root of \( \chi_\alpha \).	Linear_Algebra lemma Eigenspaces
<b>Theorem</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	If there exists a \( p(t)\in \mathbb{F}[t] \) non-zero such that \( p \) is a product of <i>distinct</i> linear factors, such that \( p(\alpha)=0 \) then \( \alpha \) is diagonalisable.	Linear_Algebra theorem Eigenspaces
<b>Theorem</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	The following statements are equivalent.<br><ol><li>\( \alpha \) is diagonalisable;</li><li>\( V \) has a basis consisting of the eigenvectors of \( \alpha \);</li><li>There exists a \( p(t)\in\mathbb{F}[t] \) non-zero which is a product of distinct linear factors such that \( p(\alpha)=0 \);</li><li>\( m_\alpha(t) \) is a product of distinct linear factors.</li></ol><br>Moreover if \( \mathbb{F}=\mathbb{C} \) these are also equivalent to<br>\[<br>a_\lambda=g_\lambda<br>\]<br>for all \( \lambda\in \mathbb{C} \).	Linear_Algebra theorem Eigenspaces
<b>Definition</b>: Simultaneously diagonalisable<br><i>[Linear Algebra]</i>	Let \( \alpha,\beta\in\mathcal L(V,V) \). We say that \( \alpha \) and \( \beta \) are <i>simultaneously diagonalisable</i> if there exists a basis \( B \) for \( V \) such that \( [\alpha]^B_B \) and \( [\beta]^B_B \) are both diagonal.	Linear_Algebra definition Eigenspaces
<b>Theorem</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Suppose that \( \alpha \) and \( \beta \) are diagonal. Then they are simultaneously diagonalisable if and only if they commute.	Linear_Algebra theorem Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	If \( \alpha \) and \( \beta \) commute and \( V_\lambda \) is the \( \lambda \)-eigenspace of \( \alpha \), then \( \beta(V_\lambda)\le V_\lambda \).	Linear_Algebra lemma Eigenspaces
<b>Definition</b>: Jordan matrix<br><i>[Linear Algebra]</i>	For \( \lambda\in \mathbb{C} \), the \( (n\times n) \)-<i>Jordan matrix</i> is<br>\[<br>J_n(\lambda) = \begin{pmatrix}<br>\lambda & 1 & 0 & \cdots & 0\\<br>0 & \lambda & 1 & \cdots & 0\\<br>0 & 0 & \lambda & \ddots & \vdots\\<br>\vdots &\vdots & \vdots & \ddots & 1 \\<br>0 & \cdots & \cdots & 0 & \lambda<br>\end{pmatrix}\in M_{n\times n}(\mathbb{C}).<br>\]	Linear_Algebra definition Eigenspaces
<b>Definition</b>: Jordan normal form<br><i>[Linear Algebra]</i>	A matrix \( A \in M_{n\times n}(\mathbb{C}) \) is in <i>Jordan normal form</i> if<br>\[<br>A=\begin{pmatrix}<br>J_{n_1}(\lambda_1) & \cdots & 0 \\<br>\vdots & \ddots & \vdots\\<br>0 & \cdots & J_{n_k}(\lambda_k)<br>\end{pmatrix},<br><br>\]<br>for some \( n_i\in \mathbb{N} \) such that \( \sum_{i=1}^k n_i=n \) and some \( \lambda_i\in \mathbb{C} \) not necessarily distinct.	Linear_Algebra definition Eigenspaces
<b>Theorem</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Every \( A \in M_{n\times n}(\mathbb{C})\) can be written in Jordan normal form uniquely up to a reordering of the Jordan blocks.	Linear_Algebra theorem Eigenspaces
<b>Proposition</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	For \( A\in M_{n\times n}(\mathbb{C}) \) in Jordan normal form,<br><ol><li>\( a_\lambda(A) \) is the sum of the sizes of \( \lambda \)-Jordan blocks in \( A \);</li><li>\( g_\lambda(A) \) is the number of \( \lambda \)-Jordan blocks;</li><li>\( C_\lambda(A) \) is the size of the largest \( \lambda \)-Jordan block.</li></ol	Linear_Algebra proposition Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	\[<br>R_{\lambda,r}(\overline A)=\mathrm{rk}((A_\lambda -I_n)^{r-1})-\mathrm{rk}((A-\lambda I_n)^r)<br>\]	Linear_Algebra lemma Eigenspaces
<b>Definition</b>: Generalised eigenspace<br><i>[Linear Algebra]</i>	Let \( V \) be a finite dimensional \( \mathbb{C} \)-vector space and \( \alpha\in \mathcal L(V,V) \). Write<br>\[<br>m_\alpha(t)=(t-\lambda_1)^{C_1}\cdots (t-\lambda_k)^{C_k}<br>\]<br>with \( \lambda_i\in \mathbb{C} \) all distinct and \( C_i\ge 1 \). The <i>generalised</i> \( \lambda_i \)-<i>eigenspace</i> of \( \alpha \) is<br>\[<br>V_i=\ker((\alpha-\lambda_i\mathrm{id}_V)^{C_i})\le V.<br>\]	Linear_Algebra definition Eigenspaces
<b>Theorem</b>: Generalised eigenspace decomposition<br><i>[Linear Algebra]</i>	Let \( V \) be as in the above definition, then<br>\[<br>V=V_1\oplus \cdots \oplus V_k.<br>\]	Linear_Algebra theorem Eigenspaces
<b>Lemma</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	If \( \mathbf 0\ne v_i\in V_i \), then \( \{v_1,\dots, v_k\} \) are linearly independent.	Linear_Algebra lemma Eigenspaces
<b>Theorem</b> (Eigenspaces)<br><i>[Linear Algebra]</i>	Let \( V \) be a \( \mathbb{C} \)-vector space with \( \dim V=n \), and \( \alpha\in\mathcal L(V,V) \) nilpotent. Then there exists a basis \( B = \{v_1,\dots, v_n\} \) for \( V \) such that for all \( 1\le i\le n \), \( \alpha(v_i)\in \{v_{i-1},\mathbf 0\} \).	Linear_Algebra theorem Eigenspaces
<b>Definition</b>: Bilinear form<br><i>[Linear Algebra]</i>	A function \( \varphi:U\times V\to \mathbb{F} \) is a <i>bilinear form</i> if for each fixed \( u_0\in U, v_0\in V \), we have that<br>\[<br>v\to \varphi(u_0,v)\quad u\to \varphi(u,v_0)<br>\]<br>are linear.	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Matrix representation<br><i>[Linear Algebra]</i>	If \( U,V \) are finite dimensional and \( B=\{b_1,\dots, b_m\} \), \( C=\{c_1,\dots, c_n\} \) are basis for \( U,V \) respectively and \( \varphi:U\times V\to \mathbb{F} \) is bilinear, then the <i>matrix</i> of \( \varphi \) with respect to \( B \) and \( C \) is<br>\[<br>[\varphi]_{B,C}=(\varphi(b_i,c_j))_{i,j}\in M_{m\times n}(\mathbb{F}).<br>\]	Linear_Algebra definition Bilinear_forms
<b>Proposition</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	\( [\varphi]_{B,C} \) satisfies<br>\[<br>([u])^T_B[\varphi]_{B,C}[v]_c=\varphi(u,v)\tag{\star}<br>\]<br>for all \( u\in U \), \( v\in V \) and \( [\varphi]_{B,C} \) is the <i>unique</i> matrix satisfying \( (\star) \) for all \( u,v \).	Linear_Algebra proposition Bilinear_forms
<b>Corollary</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	If \( B,B' \) are basis for \( U \) and \( C,C' \) are basis for \( V \), then<br>\[<br>[\varphi]_{B',C'}=([\mathrm{id}_U]^{B'}_B)^T[\varphi]_{B,C}[\mathrm{id}_V]^{C'}_C<br>\]	Linear_Algebra corollary Bilinear_forms
<b>Definition</b>: Rank<br><i>[Linear Algebra]</i>	The <i>rank</i> of \( \varphi \) is the rank of \( [\varphi]_{B,C} \) for any basis \( B,C \) for \( U,V \).	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Congurency<br><i>[Linear Algebra]</i>	\( A,A'\in M_{m\times n}(\mathbb{F}) \) are <i>congruent</i> if there exists some \( P\in GL_n(\mathbb{F}) \) such that \( A'=P^TAP \).	Linear_Algebra definition Bilinear_forms
<b>Proposition</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	Congruence is an equivalence relation.	Linear_Algebra proposition Bilinear_forms
<b>Definition</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	Let \( \varphi:U\times V\to \mathbb{F} \) be a bilinear form. For \( u\in U, v\in V \) let<br>\[<br>\varphi_L(u)\in V^*, \quad \varphi_R(v)\in U^*<br>\]<br>be given by<br>\[<br>\varphi_L(u)[v]=\varphi(u,v)=\varphi_R(v)[u].<br>\]	Linear_Algebra definition Bilinear_forms
<b>Lemma</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	\( \varphi_L:U\to V^* \), \( \varphi_R:V\to U^* \) are linear.	Linear_Algebra lemma Bilinear_forms
<b>Definition</b>: Left/Right-Kernel<br><i>[Linear Algebra]</i>	Let \( \varphi_L,\varphi_R \) be as above. Then we define \( \ker(\varphi_L)\le U \) to be the <i>left-kernel</i> of \( \varphi \) and \( \ker(\varphi_R)\le V \) to be the <i>right-kernel</i> of \( \varphi \).	Linear_Algebra definition Bilinear_forms
<b>Proposition</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	Let \( U,V \) be finite dimensional and \( B,C \) be basis for \( U,V \) and \( B^*,C^* \) be dual to the basis \( B,C \) respectively. Then<br><ol><li>\( [\varphi_L]^B_{C^*}=[\varphi]_{B,C} \).</li><li>\( [\varphi_R]^C_{B^*}=([\varphi]_{B,C})^T \).</li></ol	Linear_Algebra proposition Bilinear_forms
<b>Corollary</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	\( \mathrm{rk}(\varphi_L)=\mathrm{rk}(\varphi_R)=\mathrm{rk}(\varphi) \).	Linear_Algebra corollary Bilinear_forms
<b>Definition</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	For \( S\subseteq U \) and \( T\subseteq V \), we define<br>\[\begin{aligned}<br>S^{\perp}&=\{v\in V: \forall s\in S, \varphi(s,v)=0\}\\<br>{\ }^{\perp}T&=\{u\in U: \forall t\in T, \varphi(u,t)=0\}.<br>\end{aligned}\]	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Degeneracy<br><i>[Linear Algebra]</i>	We say that \( \varphi \) is <i>degenerate</i> if \( U^\perp \) or \( \ ^\perp V \) is nontrivial.	Linear_Algebra definition Bilinear_forms
<b>Proposition</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	For \( U,V \) finite dimensional and \( B,C \) basis for \( U,V \) then \( \varphi \) is non-degenerate if and only if \( \dim U=\dim V \) and \( [\varphi]_{B,C} \) is invertible.	Linear_Algebra proposition Bilinear_forms
<b>Definition</b>: Symmetric bilinear form<br><i>[Linear Algebra]</i>	A bilinear form \( \varphi:V\times V\to \mathbb{F} \) is <i>symmetric</i> if \( \forall u,v\in V \),<br>\[<br>\varphi(u,v)=\varphi(v,u).<br>\]	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Quadratic form<br><i>[Linear Algebra]</i>	A <i>quadratic form</i> on \( V \) is a function \( Q:V\to \mathbb{F} \) such that there exists a bilinear form \( \varphi: V\times V\to \mathbb{F} \) such that for all \( v\in V \), \( Q(v)=\varphi(v,v) \).	Linear_Algebra definition Bilinear_forms
<b>Proposition</b>: Polarisation Identity<br><i>[Linear Algebra]</i>	. Suppose that \( \mathbb{F} \) is a field of characteristic greater than 2. Let \( Q:V\to \mathbb{F} \) be quadratic form. Then there is unique symmetric bilinear form \( \psi:V\times V\to \mathbb{F} \) such that,<br>\[<br>Q(v)=\psi(v,v)\quad \forall v\in V.\tag{\star}<br>\]<br>And \( \psi \) is given by<br>\[<br>\psi(u,v)=\frac 12(Q(u+v)-Q(u)-Q(v)).\tag{\dagger}<br>\]	Linear_Algebra proposition Bilinear_forms
<b>Theorem</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	Suppose \( \mathbb{F} \) is a field of characteristic greater than 2 and \( V \) is a finite dimensional \( \mathbb{F} \)-vector space. Let \( \varphi:V\times V\to \mathbb{F} \) be a symmetric bilinear form. Then there is a basis \( B \) for \( V \) such that \( [\varphi]_B \) is diagonal.	Linear_Algebra theorem Bilinear_forms
<b>Corollary</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	Suppose \( \mathbb{F} \) is a field of characteristic greater than 2. Then every symmetric matrix is congruent to a diagonal matrix.	Linear_Algebra corollary Bilinear_forms
<b>Corollary</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	Suppose<br><ol><li>\( V \) is a finite dimensional \( \mathbb{C} \)-vector space, and \( \varphi \) is as in the theorem. Let \( Q(v)=\varphi(v,v) \). Then there is a basis \( B=\{v_1,\dots, v_n\} \) for \( V \) such that<br>\[<br>[\varphi]_B=\begin{pmatrix}<br>I_r & 0 \\<br>0 & 0<br>\end{pmatrix}, \quad r=r\mathrm{rk} (\varphi).<br>\]</li><li>If instead \( V \) is a \( \mathbb{R} \)-vector space,<br>\[<br>[\varphi]_B=\begin{pmatrix}<br>I_p & 0 & 0 \\<br>0 & I_q & 0 \\<br>0 & 0 & 0<br>\end{pmatrix}, \quad p+q=\mathrm{rk}(\varphi).<br>\]</li></ol	Linear_Algebra corollary Bilinear_forms
<b>Definition</b>: Positive definite<br><i>[Linear Algebra]</i>	Let \( \varphi:V\times V\to \mathbb{R} \) be a symmetrical bilinear form. \( \varphi \) is said to be <i>positive definite</i> if \( \varphi(v,v)>0 \) for all \( \mathbf 0 \ne v\in V \). If we replace the \( > \) with a \( \ge \) and \( \varphi \) satisfies the inequality for all \( v \) we say that \( \varphi \) is <i>positive semi-definite</i>.	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Negative definite<br><i>[Linear Algebra]</i>	Let \( \varphi:V\times V\to \mathbb{R} \) be a symmetrical bilinear form. \( \varphi \) is said to be <i>negative definite</i> if \( \varphi(v,v)<0 \) for all \( \mathbf 0 \ne v\in V \). If we replace the \( < \) with a \( \le \), and \( \varphi \) satisfies the inequality for all \( v \) we say that \( \varphi \) is <i>negative semi-definite</i>.	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Indefinite<br><i>[Linear Algebra]</i>	If \( \varphi:V\times V\to \mathbb{R} \) symmetrical is not positive semi-definite or negative semi-definite, we say that \( \varphi \) is <i>indefinite</i>.	Linear_Algebra definition Bilinear_forms
<b>Theorem</b>: Sylvester's Law of Inertia<br><i>[Linear Algebra]</i>	Let \( V \) be finite dimensional and \( \varphi \) be a symmetric bilinear form on \( V \). If \( B,B' \) are basis for \( V \) such that<br>\[<br>[\varphi]_B=\begin{pmatrix}<br>I_p & 0 & 0 \\<br>0 & I_q & 0 \\<br>0 & 0 & 0<br>\end{pmatrix}\quad \text{and}\quad [\varphi]_{B'}=\begin{pmatrix}<br>I_{p'} & 0 & 0 \\<br>0 & I_{q'} & 0 \\<br>0 & 0 & 0<br>\end{pmatrix},<br>\]<br>then \( p=p' \) and \( q=q' \).	Linear_Algebra theorem Bilinear_forms
<b>Definition</b>: Signature<br><i>[Linear Algebra]</i>	We say that \( \sigma(\varphi)=p-q \) is the <i>signature</i> of \( \varphi \).	Linear_Algebra definition Bilinear_forms
<b>Corollary</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	\( \sigma(\varphi) \) is well-defined.	Linear_Algebra corollary Bilinear_forms
<b>Lemma</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	If \( V \) is finite dimensional and \( U,W\le V \) then if \( \varphi\mid_U \) is positive definite and \( \varphi\mid_W \) is negative semi-definite then \( U\cap W=\{\mathbf 0\} \).	Linear_Algebra lemma Bilinear_forms
<b>Definition</b>: Totally isotropic<br><i>[Linear Algebra]</i>	A subspace \( T\le V \) is called <i>totally isotropic</i> for \( \varphi \) if for all \( t,u\in T \) we have that \( \varphi(t,u)=0 \).	Linear_Algebra definition Bilinear_forms
<b>Proposition</b> (Bilinear forms)<br><i>[Linear Algebra]</i>	Let \( V \) be finite dimensional. The maximial dimension of a totally isotropic subspace of \( V \) for \( \varphi \) is \( \dim V-\max(p,q) \).	Linear_Algebra proposition Bilinear_forms
<b>Definition</b>: Sesquilinear form<br><i>[Linear Algebra]</i>	Let \( V,W \) be \( \mathbb{C} \)-vector spaces. A <i>sesquilinear form</i> is a function \( \varphi:V\times W\to \mathbb{C} \) such that<br><ol><li>\( \varphi(\lambda v_1+v_2,w_1)=\lambda\varphi(v_1,w_1)+\varphi(v_2,w_1) \)</li><li>\( \varphi(v_1,\mu w_1+w_2)=\overline \mu \varphi(v_1,w_1)+\varphi(v_1,w_2) \)</li></ol><br>for all \( \lambda,\mu \in \mathbb{C} \), \( v_1,v_2\in V \), \( w_1,w_2\in W \).	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Matrix<br><i>[Linear Algebra]</i>	Let \( V,W \) be a finite dimensional and let \( \varphi:V\times W\to \mathbb{C} \) be a sesquilinear form. Let \( B=\{b_1,\dots, b_m\} \) and \( C=\{c_1,\dots, c_n\} \) be basis for \( V,W \) respectively. Then<br>\[<br>[\varphi]_{B,C}=(\varphi(b_i,c_j))_{i,j}\in M_{m\times n}(\mathbb{C})<br>\]<br>is the <i>matrix</i> of \( \varphi \) with respect to \( B,C \).	Linear_Algebra definition Bilinear_forms
<b>Proposition</b> (Bilinear forms > Sesquilinear Forms)<br><i>[Linear Algebra]</i>	\( [\varphi]_{B,C} \) is the unique matrix satisfying<br>\[<br>\varphi(v,w)= ([v]_B)^T[\varphi]_{B,C}\overline{[w]}_C<br>\]<br>for all \( v\in V \) and \( w\in W \).	Linear_Algebra proposition Bilinear_forms
<b>Corollary</b> (Bilinear forms > Sesquilinear Forms)<br><i>[Linear Algebra]</i>	Let \( B,B' \) be basis for \( V \) and \( C,C' \) be basis for \( W \). Then<br>\[<br>[\varphi]_{B',C'}=P^T[\varphi]_{B,C}\overline Q<br>\]<br>where \( P=[\mathrm{id}_V]^{B'}_B \), \( Q=[\mathrm{id}_W]^{C'}_C \).	Linear_Algebra corollary Bilinear_forms
<b>Definition</b>: Hermitian<br><i>[Linear Algebra]</i>	A sesquilinear form \( \varphi:V\times V\to \mathbb{C} \) is <i>Hermitian</i> if \( \forall u,v\in V \),<br>\[<br>\varphi(u,v)=\overline{\varphi(v,u)}.<br>\]	Linear_Algebra definition Bilinear_forms
<b>Definition</b>: Hermitian matrix<br><i>[Linear Algebra]</i>	A square matrix \( A\in M_{n\times n}(\mathbb{C}) \) is <i>Hermitian</i> if<br>\[<br>A=\overline A^T.<br>\]	Linear_Algebra definition Bilinear_forms
<b>Lemma</b> (Bilinear forms > Sesquilinear Forms)<br><i>[Linear Algebra]</i>	Let \( V \) be finite dimensional. Then a sesquilinear form \( \varphi:V\times V\to \mathbb{C} \) is Hermitian if and only if for some (equivalently any) basis \( B \) for \( V \) , \( [\varphi]_B \) is a Hermitian matrix.	Linear_Algebra lemma Bilinear_forms
<b>Proposition</b>: Polarisation Identity<br><i>[Linear Algebra]</i>	Let \( V \) be any \( \mathbb{C} \)-vector space. A Hermitian form \( \varphi \) on \( V \) is uniquely determined by<br>\[\begin{aligned}<br>Q &: V\to \mathbb{R}\\<br>&v\to \varphi(v,v)<br>\end{aligned}\]<br>where \( \varphi(u,v)=\frac 14(Q(u+v)-Q(u-v)+iQ(u+iv)-iQ(u-iv)) \).	Linear_Algebra proposition Bilinear_forms
<b>Theorem</b> (Bilinear forms > Sesquilinear Forms)<br><i>[Linear Algebra]</i>	Let \( V \) be a finite dimensional \( \mathbb{C} \)-vector space and \( \varphi \) a Hermitian form on \( V \). Then we have the following,<br><ol><li>There is a basis \( B \) for \( V \) such that<br>\[<br>[\varphi]_B=\begin{pmatrix}<br>I_p & 0 & 0 \\<br>0 & -I_q & 0 \\<br>0 & 0 & 0<br>\end{pmatrix}.<br>\]</li><li>(Hermitian Sylvester's law) \( p,q \) are uniquely determined by<br>\( \varphi \).</li></ol	Linear_Algebra theorem Bilinear_forms
<b>Definition</b>: Inner product<br><i>[Linear Algebra]</i>	Let \( V \) be a real or complex vector space. An <i>inner product</i> on \( V \) is a positive definite symmetric bilinear (respectively Hermitian) form \( \varphi \) on \( V \).	Linear_Algebra definition Inner_Product_Spaces
<b>Definition</b>: Inner product space<br><i>[Linear Algebra]</i>	The pair \( (V,\varphi) \) where \( V \) is a real or complex vector space and \( \varphi \) is an inner product is called an <i>inner product space</i>. We write \( \langle v,w\rangle \) for \( \varphi(v,w) \).	Linear_Algebra definition Inner_Product_Spaces
<b>Definition</b>: Length<br><i>[Linear Algebra]</i>	Let \( (V,\langle\cdot,\cdot\rangle \) be an inner product space. The <i>length</i> of \( v\in V \) is<br>\[<br>||v||=\sqrt{\langle v,v\rangle}.<br>\]<br>The <i>distance</i> between two vectors \( v,w\in V \) is just \( ||v-w|| \).	Linear_Algebra definition Inner_Product_Spaces
<b>Lemma</b>: Cauchy-Schwarz Inequality<br><i>[Linear Algebra]</i>	For all \( v,w\in V \), we have that<br>\[<br>|\langle v,w\rangle |\le ||v||||w||.\tag{\star}<br>\]	Linear_Algebra lemma Inner_Product_Spaces
<b>Corollary</b>: Triangle Inequality<br><i>[Linear Algebra]</i>	For all \( v,w\in V \), we have that<br>\[<br>||v+w||\le ||v||+||w||.<br>\]	Linear_Algebra corollary Inner_Product_Spaces
<b>Definition</b>: Orthogonal<br><i>[Linear Algebra]</i>	A set \( E\subseteq V \) is <i>orthogonal</i> if for all \( d,e\in E \) with \( d\ne e \) we have that \( \langle d,e\rangle=0 \).	Linear_Algebra definition Inner_Product_Spaces
<b>Definition</b>: Orthonormal<br><i>[Linear Algebra]</i>	A set \( E\subseteq V \) is <i>orthonormal</i> if it is orthogonal and all elements have length \( 1 \).	Linear_Algebra definition Inner_Product_Spaces
<b>Lemma</b> (Inner Product Spaces)<br><i>[Linear Algebra]</i>	If \( E\subseteq V \) is an orthonormal set and \( \mathbf 0\notin E \), then<br><ol><li>\( E \) is linearly independent.</li><li>For \( v\in \langle E\rangle \),<br>\[<br>v=\sum_{e\in E}\frac{\langle v,e\rangle}{\langle e,e\rangle}e<br>\]<br>with a finite sum.</li></ol	Linear_Algebra lemma Inner_Product_Spaces
<b>Corollary</b>: Parseval's Identity<br><i>[Linear Algebra]</i>	If \( E \) is an orthonormal basis for \( V \), then for all \( v,w\in V \)<br>\[<br>\langle v,w\rangle=\sum_{e\in E}\langle v,e\rangle\overline{\langle w,e\rangle}.<br>\]	Linear_Algebra corollary Inner_Product_Spaces
<b>Theorem</b>: Gram-Schmidt Process<br><i>[Linear Algebra]</i>	Let \( V \) be an inner product space with \( v_1,\dots, v_n\in V \) linearly independent. Then there is an orthonormal set \( \{e_1,\dots, e_n\} \subseteq V \) such that<br>\[<br>\langle e_1,\dots, e_k\rangle=\langle v_1,\dots ,v_k\rangle<br>\]<br>for all \( 1\le k\le n \).	Linear_Algebra theorem Inner_Product_Spaces
<b>Corollary</b> (Inner Product Spaces)<br><i>[Linear Algebra]</i>	Let \( V \) be a finite dimensional inner product space. For any orthonormal set \( E \) in \( V \), there is a orthonormal basis, containing \( E \).	Linear_Algebra corollary Inner_Product_Spaces
<b>Definition</b>: Orthogonal direct sum<br><i>[Linear Algebra]</i>	Let \( V \) be an inner product space and \( U,W\le V \). Then \( V \) is the <i>orthogonal direct sum</i> of \( U \) and \( W \) if<br><ol><li>\( V=U+W \),</li><li>\( \forall u\in U,\ w\in W \), \( \langle u,w\rangle=0 \).</li></ol><br>We write that \( V=U\obot W \).	Linear_Algebra definition Inner_Product_Spaces
<b>Lemma</b> (Inner Product Spaces > Orthogonal Complements)<br><i>[Linear Algebra]</i>	Let \( V \) be finite dimensional with \( W\le V \). Then \( V=W\obot W^\perp \).	Linear_Algebra lemma Inner_Product_Spaces
<b>Corollary</b> (Inner Product Spaces > Orthogonal Complements)<br><i>[Linear Algebra]</i>	\[<br>\dim W^\perp = \dim V-\dim W.<br>\]	Linear_Algebra corollary Inner_Product_Spaces
<b>Definition</b>: Orthogonal projection<br><i>[Linear Algebra]</i>	The <i>orthogonal projection</i> \( \pi_W:V\to V \) of \( V \) onto \( W \) is given by \( \pi_W(v)=w \), where \( v=w+u \) where \( w\in W \) and \( u\in W^\perp \) unique.	Linear_Algebra definition Inner_Product_Spaces
<b>Proposition</b> (Inner Product Spaces > Orthogonal Complements)<br><i>[Linear Algebra]</i>	For all \( v\in V \), \( v\in W \),<br>\[<br>||v-\pi_W(v)||\le ||v-w||<br>\]<br>with equality if and only if \( w=\pi_W(v) \).	Linear_Algebra proposition Inner_Product_Spaces
<b>Definition</b>: External Orthogonal Direct Set<br><i>[Linear Algebra]</i>	Let \( (V_1,\langle \cdot,\cdot\rangle)_1 \) and \( (V_2,\langle\cdot,\cdot\rangl_2) \) be inner product spaces. We can define an inner product \( \langle\cdot,\cdot\rangle \) on \( V_1\times V_2 \) by,<br>\[<br>\langle(v_1,v_2,(v_1',v_2')\rangle=\langle v_1,v_1'\rangle_1+\langle v_2,v_2'\rangle_2.<br>\]<br>Then \( \langle \cdot,\cdot\rangle \) is an inner product on \( V_1\oplus V_2 \).	Linear_Algebra definition Inner_Product_Spaces
<b>Theorem</b> (Inner Product Spaces > Adjoint Maps)<br><i>[Linear Algebra]</i>	For \( \alpha\in\mathcal L(V,W) \),<br><ol><li>There exists a unique linear map \( \alpha^*:W\to V \) satisfying<br>\[<br>\langle \alpha(v),w\rangle_W=\langle v,\alpha^*(w)\rangle_V\tag{\star}<br>\]<br>for all \( v\in V \) and \( w\in W \).</li><li>For any orthonormal basis \( B,C \) for \( V,W \), we have that<br>\[<br>[\alpha^*]^C_B=\overline{([\alpha]_C^B)}^T<br>\]</li></ol	Linear_Algebra theorem Inner_Product_Spaces
<b>Definition</b>: Adjoint map<br><i>[Linear Algebra]</i>	\( \alpha^* \) is the <i>adjoint map</i> of \( \alpha \).	Linear_Algebra definition Inner_Product_Spaces
<b>Theorem</b>: Riesz Representation<br><i>[Linear Algebra]</i>	For \( V \) a finite dimensional real inner product space, \( \varphi_R:V\to V^* \) is a linear isomorphism.	Linear_Algebra theorem Inner_Product_Spaces
<b>Definition</b>: Self-adjoint<br><i>[Linear Algebra]</i>	Let \( \alpha\in \mathcal L(V,V)\). We say that \( \alpha \) is <i>self-adjoint</i> if \( \alpha^*=\alpha \).	Linear_Algebra definition Inner_Product_Spaces
<b>Lemma</b> (Inner Product Spaces > Self-adjoint and isometry maps)<br><i>[Linear Algebra]</i>	If \( \mathbb{F}=\mathbb{R} \) or \( \mathbb{C} \), the map \( \alpha \) is self-adjoint if for some (or equivalently any) orthonormal basis \( B \) for \( V \) if \( [\alpha]^B_B \) is symmetric in the real case, and Hermitian in the complex case.	Linear_Algebra lemma Inner_Product_Spaces
<b>Definition</b>: Isometry<br><i>[Linear Algebra]</i>	Let \( \alpha\in\mathcal (V,W) \). We say that \( \alpha \) is an <i>isometry</i> if \( \forall u,v\in V \),<br>\[<br>\langle \alpha(u),\alpha(v)\rangle_W=\langle u,v\rangle_V.<br>\]	Linear_Algebra definition Inner_Product_Spaces
<b>Proposition</b> (Inner Product Spaces > Self-adjoint and isometry maps)<br><i>[Linear Algebra]</i>	Let \( \alpha\in \mathcal(V,W) \) be invertible. Then \( \alpha \) is an isometry if and only if \( \inv\alpha=\alpha^* \).	Linear_Algebra proposition Inner_Product_Spaces
<b>Definition</b>: Markov chain<br><i>[Markov Chains]</i>	A discrete-time Markov chain is a sequence \( \doubleline X=(X_n)_{n\ge 0} \) of random variables taking values in the same discrete countable state space \( I \), such that:<br>\[<br>\mathbb{P}\left({X_{n+1}\right)=x_{n+1}|X_0=x_0,\dots, X_n=x_n}=\mathbb{P}\left({X_{n+1}\right)=x_{n+1}|X_n=x_n}\quad \forall n\ge 0.<br>\]	Markov_Chains definition Markov_Chains
<b>Definition</b>: Transition matrix<br><i>[Markov Chains]</i>	We define the transition matrix \( P \) as the matrix<br>\[<br>P(x,y)=P_{xy}=\mathbb{P}\left({X_{n+1}\right)=y|X_n=x}.<br>\]	Markov_Chains definition Markov_Chains
<b>Theorem</b> (Markov Chains > The Markov property)<br><i>[Markov Chains]</i>	\( \doubleline X = (X_n)\) is \( \text{Markov}(\lambda, P) \) on \( I \) if and only if<br>\[<br>\mathbb{P}\left({X_0=x_0,X_1=x_1,\dots, X_n=x_n}\right)=\lambda_{x_0}p_{x_0x_1},\dots p_{x_{n-1}x_n}<br>\]<br>for all \( n\ge 0 \) and all \( x_0,x_1,\dots, x_n\in I \).	Markov_Chains theorem Markov_Chains
<b>Definition</b> (Markov Chains > The Markov property)<br><i>[Markov Chains]</i>	For \( i\in I \) the \( \delta_i \)-mass at \( i \) denotes the probability mass function at \( i \)<br>\[<br>\delta_{ij}=\begin{cases}<br>1 & j=i \\<br>0 & j\ne 1<br>\end{cases}<br>\]	Markov_Chains definition Markov_Chains
<b>Theorem</b>: Markov property<br><i>[Markov Chains]</i>	If \( \overline X \sim \text{Markov}(\lambda, P) \). Then for any \( m\ge 1 \) and \( i\in I \) conditional on \( X_m=i \) the process \( (X_{m+n}) \) is \( \text{Markov}(\delta_i,P) \) and it is indepdent of \( X_0,\dots, X_m \).	Markov_Chains theorem Markov_Chains
<b>Theorem</b> (Powers of the transition matrix)<br><i>[Markov Chains]</i>	Suppose that \( \doubleline X\sim\text{Markov}(\lambda, P) \). Then<br><ol><li>\( \mathbb{P}\left({X_n=x}\right)=(\lambda P^n)_x \) for all \( x\in I, n \ge1 \).</li><li>\( \mathbb{P}\left({X_{n+m}\right)=y | X_m=x}=(\delta_xP^n)_y=(P^n)_{xy} \).</li></ol	Markov_Chains theorem Powers_of_the_transition_matrix
<b>Definition</b> (Powers of the transition matrix)<br><i>[Markov Chains]</i>	We say that state \( i \) <i>leads to</i> \( j \), denoted as \( i\to j \) if<br>\[<br>\mathbb{P}\left({X_n=j\text{ for some \( n\ge 0 \)}\right)\mid X_0=i}<br>\]<br>and we say that \( i \) and \( j \) <i>communicate</i> if \( i\to j \) and \( j\to i \) we denote this as \( i\longleftrightarrow j \).	Markov_Chains definition Powers_of_the_transition_matrix
<b>Theorem</b> (Powers of the transition matrix)<br><i>[Markov Chains]</i>	The following statements are equivalent.<br><ol><li>\( i\to j \).</li><li>There is a path \( x_0=i,x_1,\dots, x_n=j \) such that \( p_{x_0x_1},\dots,p_{x_{n-1}x_n} \) are all positive.</li><li>\( P_{ij}(n)\ge 0 \) for some \( n \).</li></ol	Markov_Chains theorem Powers_of_the_transition_matrix
<b>Corollary</b> (Powers of the transition matrix)<br><i>[Markov Chains]</i>	Communication defines a equvalence relation on the state space.	Markov_Chains corollary Powers_of_the_transition_matrix
<b>Definition</b>: Communicating class<br><i>[Markov Chains]</i>	The induced equivalences classes are called <i>communicating classes</i>. A communicating class \( C\subseteq I \) is <i>closed</i> if \( x\to y \) for some \( x\in C \) and \( y\in I \) then we have that \( y\in C \).	Markov_Chains definition Powers_of_the_transition_matrix
<b>Definition</b>: Absorbing<br><i>[Markov Chains]</i>	A state \( x \) is absorbing if \( \{x\} \) is closed.	Markov_Chains definition Powers_of_the_transition_matrix
<b>Definition</b>: Irreducible<br><i>[Markov Chains]</i>	A transition matrix \( P \) is called <i>irreducible</i> if \( I \) is a communicating class. i.e. \( x\longleftrightarrow y \) for all \( x,y\in I \).	Markov_Chains definition Powers_of_the_transition_matrix
<b>Definition</b>: First hitting time<br><i>[Markov Chains]</i>	Let \( A\subseteq I \). Then the <i>first hitting time</i> \( T_A \) for \( A \) is<br>\[<br>T_A=\inf\{x\ge 0: X_n\in A\}<br>\]<br>which can be infinite if the set empty. The <i>hitting probability</i> of \( A \) is the function<br>\[<br>h^A:I\to [0,1]<br>\]<br>defined by<br>\[<br>h_i^A=\mathbb P_i(T_A\le \infty)<br>\]<br>and the \texit{mean hitting time} is the function<br>\[<br>k^A:I\to(0,\infty]<br>\]<br>is<br>\[<br>k^A_i=\mathbb E_i(T_A)=\sum_{n=0}^\infty n\mathbb P_i(T_A=n)+\infty\cdot\mathbb{P}\left({T_A=\infty}\right).<br>\]	Markov_Chains definition Powers_of_the_transition_matrix
<b>Definition</b>: Complex Fourier series<br><i>[Methods]</i>	For an \( L \)-periodic \( f:\mathbb{R}\to \mathbb{C} \) define its <i>complex Fourier series</i> by<br>\[<br>\sum_n\hat f_n e^{2\pi in \theta /L}<br>\]<br>where<br>\[<br>\hat f_n = \frac 1L \int_0^1 f(\theta) e^{-2\pi in\theta/L}\mathrm d \theta<br>\]<br>are called the complex Fourier coefficients. We will write for \( f\in V \)<br>\[<br>f(\theta)\sim \sum_n\hat f_n e^{2\pi in\theta/L}<br>\]<br>to mean the series on the right corresponds to complex Fourier series for the function on the left.	Methods definition Fourier_Series
<b>Definition</b>: Fourier series<br><i>[Methods]</i>	For \( f: \mathbb{R}\to \mathbb{C} \) an \( L \)-periodic function define its <i>Fourier series</i> by<br>\[<br>\frac 1L a_0+\sum_{n=1}^\infty\left[a_n\cos\left(\frac{2\pi n\theta}L\right)+b_n\sin\left(\frac{2\pi n\theta}L\right)\right]<br>\]<br>where<br>\[<br>a_n=\frac 2L\int^L_0f(\theta)\cos\left(\frac{2\pi n\theta}L\right)\mathrm d\theta<br>\]<br>and<br>\[<br>b_n=\frac 2L\int^L_0f(\theta)\sin\left(\frac{2\pi n\theta}L\right)\mathrm d\theta<br>\]<br>are called the Fourier cofficients for \( f \).	Methods definition Fourier_Series
<b>Definition</b> (Fourier Series > Convergence of Fourier series)<br><i>[Methods]</i>	For \( f:\mathbb{R}\to \mathbb{C} \) an \( L \)-periodic function we defined the <i>partial Fourier series</i> as<br>\[\begin{aligned}<br>(S_Nf)(\theta)&=\sum_{|n|<N}\hat f_ne^{2\pi in\theta /L} \\<br>&= \frac 12a_0+\sum_{n=1}^N\left[a_n\cos\left(\frac {2\pi n\theta}L\right)+b_n\sin\left(\frac{2\pi n\theta}L\right)\right]<br>\end{aligned}\]	Methods definition Fourier_Series
<b>Proposition</b> (Fourier Series > Convergence of Fourier series)<br><i>[Methods]</i>	Let \( f:\mathbb{R}\to\mathbb{C} \) be an \( L \)-periodic function for which on \( [0,L) \) we have the following,<br><ol><li>\( f \) has finitely many discontinuities.</li><li>\( f \) has finitely many local maxima and minima.</li></ol><br>Then for each \( \theta\in[0,1) \) we have<br>\[\begin{aligned}<br>\frac{\theta_++\theta_-}2 &= \lim_{n\to \infty}(S_Nf)(\theta)\\<br>&= \sum_n\hat f_n e^{2\pi in\theta/L}<br>\end{aligned}\]<br>where \( f(\theta_\pm) = \lim_{\varepsilon\to 0^+}f(\theta \pm \varepsilon) \). So at the points of continuity the Fourier series gives back the original function, and at points of discontunity the Fourier series gives back the average of the function at the disconunity neighbourhood.	Methods proposition Fourier_Series
<b>Definition</b> (Fourier Series > Peridoic extensions: Cosine and sine series)<br><i>[Methods]</i>	For \( f: [0,L)\to \mathbb{C} \) define its <i>cosine</i> and <i>sine</i> series by<br>\[\begin{aligned}<br>\frac{1}2 A_0+\sum_{n=1}^\infty A_n\cos\left(\frac{n\pi\theta}L\right),\quad \sum_{n=1}^\infty B_n\sin\left(\frac{n\pi\theta}L\right)<br>\end{aligned}\]<br>where \( A_n \) and \( B_n \) defined as before.	Methods definition Fourier_Series
<b>Definition</b>: Self-adjoint<br><i>[Methods]</i>	A linear differential operator, \( L \), is said to be <i>self-adjoint</i> on \( (V,\langle \cdot,\cdot\rangle_w) \) if<br>\[<br>\langle Ly_1,y_2\rangle_w=\langle y_1,Ly_2\rangle_w\quad\forall y_1,y_2\in V.<br>\]	Methods definition Sturm-Liouville_Theory
<b>Definition</b>: Eigenfunction/value<br><i>[Methods]</i>	For \( (y,\lambda) \in (V\setminus\{0\}\times \mathbb{C} \) is an <i>eigenfunction, eigenvalue</i> pair for \( L \) if \( Ly=\lambda y \).	Methods definition Sturm-Liouville_Theory
<b>Proposition</b> (Sturm-Liouville Theory > Abstract eigenvalues problem)<br><i>[Methods]</i>	If \( L \) is self-adjoint on \( (V,\langle \cdot,\cdot,\rangle_w) \) then:<br><ol><li>Eigenvalues are real,</li><li>eigenfunctions with distinct eigenvalues are orthogonal,</li><li>there exists a complete orthogonal set of eigenfunctions \( \{y_n\}_{n=1}^\infty \) i.e. for each \( f \in V \) we can write,<br>\[<br>f=\sum_{n=1}^\infty \hat f_ny_n<br>\]<br>where<br>\[<br>\hat f_n=\frac{\langle f, y_n\rangle_w}{||y_n||_w^2}<br>\]</li></ol	Methods proposition Sturm-Liouville_Theory
<b>Definition</b>: Sturm-Liouville operator<br><i>[Methods]</i>	We say that \( L \) is a <i>Sturm-Liouville operator</i> on \( (a,b) \) if it has the form<br>\[\begin{aligned}<br>L&=\frac 1w\left[-\frac{\mathrm d}{\mathrm d x}\left(p\frac{\mathrm d \mathhuge\cdot}{\mathrm dx}\right)+q\mathhuge\cdot\right]\\<br>&= \frac 1w\left[-p\frac{\mathrm d^2\mathhuge \cdot}{\mathrm dx^2}-p^2\frac{\mathrm d \mathhuge \cdot}{\mathrm dx}+q\mathhuge\cdot\right]<br>\end{aligned}\]<br>where \( p,q,w \) are real valued and \( p,w>0 \) on \( (a,b) \). We call \( w \) the <i>weight function</i>.	Methods definition Sturm-Liouville_Theory
<b>Definition</b>: Singular<br><i>[Methods]</i>	For a Sturm-Liiouville operator on \( (a,b) \) say an endpoint \( c\in \{a,b\} \) is <i>singular</i> if \( p(c)=0 \) and <i>non-singular</i> otherwise.	Methods definition Sturm-Liouville_Theory
<b>Proposition</b> (Sturm-Liouville Theory > Abstract eigenvalues problem)<br><i>[Methods]</i>	If \( L \) is a Sturm-Lionville operator on \( (a,b)  \) with weight function \( w \) then if \( y_1,y_0\in C^2[a,b] \) we have that<br>\[<br>\langle Ly_1,y_2\rangle_w-\langle y_1,Ly_2\rangle_w=p(x)W(y_1,\overline{y_2})(x)\mathlarger{\mathlarger{\mathlarger{|}}}^b_a<br>\]<br>where \( W \) is the Wronskian.	Methods proposition Sturm-Liouville_Theory
<b>Proposition</b> (Sturm-Liouville Theory > Reduction to Sturn-Lionville form)<br><i>[Methods]</i>	The equation<br>\[<br>\alpha(x)\frac{\mathrm d^2y}{\mathrm dx^2}+\beta(x)\frac{\mathrm dy}{\mathrm dx}+\gamma(x)y+\lambda y=0<br>\]<br>is equivalent to<br>\[<br>-\frac{\mathrm d}{\mathrm dx}\left[p\frac{\mathrm dy}{\mathrm dx}\right] + qy=\lambda wy<br>\]<br>where<br><ol><li>\( p(x)=I(x) \),</li><li>\( q(x)=-\frac{I(x)\gamma(x)}{\alpha(x)} \),</li><li>\( w(x)=\frac{I(x)}{\alpha(x)} \).</li></ol	Methods proposition Sturm-Liouville_Theory
<b>Proposition</b> (Linear PDEs and Seperation of Variables > The Heat Equation > Heat loss and uniqueness)<br><i>[Methods]</i>	The solution to the problem in \( (\dagger\dagger) \) is unique.	Methods proposition Linear_PDEs_and_Seperation_of_Variables
<b>Proposition</b> (Inhomogeneous Problems and Green's Functions > A General Result)<br><i>[Methods]</i>	Let \( y_1,y_2 \) be solutions to \( Ly=0 \) with \( y_1(a)=0 \) and \( y_2(b)=0 \) linearly independent. Then,<br>\[<br>G(x,\xi)=\frac1{\alpha(xi)W(y_1,y_2)(\xi)}\times \begin{cases}<br>y_1(x)y_2(\xi) & a <x <\xi\\<br>y_1(\xi)y_2(x) & \xi< x < b<br>\end{cases}<br>\]<br>satisfies<br>\[<br>L_x[G(x,\xi)]=\delta(x-\xi),\quad G(a,\xi)=G(b,\xi)=0.<br>\]	Methods proposition Inhomogeneous_Problems_and_Green's_Functions
<b>Proposition</b> (Inhomogeneous Problems and Green's Functions > Green's functions for Sturm-Liouville operators)<br><i>[Methods]</i>	If \( L \) is a Sturm-Lioville operator and \( y_1,y_2 \) satisfy \( Ly_1=Ly_2=0 \), then<br>\[<br>p(x)W(y_1,y_2)(x)<br>\]<br>is constant.	Methods proposition Inhomogeneous_Problems_and_Green's_Functions
<b>Proposition</b> (Inhomogeneous Problems and Green's Functions > Eigenfunction Expansions Revisited)<br><i>[Methods]</i>	If \( \{Y_k\} \) are as above then the Dirichlet Green's function for the Sturm Liouville operator \( L \) satisfies,<br>\[<br>G(x,\xi)=\sum_{k=1}^\infty \frac{Y_k(x)Y_K(\xi)}{\lambda_k}<br>\]<br>where \( LY_k=\lambda_k Y_k \).	Methods proposition Inhomogeneous_Problems_and_Green's_Functions
<b>Proposition</b> (Inhomogeneous Problems and Green's Functions > Initial Value Problems)<br><i>[Methods]</i>	The Green's function for \( (\dagger) \) is characterised by<br><ol><li>\( G(t,\tau)=0 \) on \( t< \tau \);</li><li>\( L_t[G(t,\tau)]=0 \) on \( t>\tau \) with \( G(t^+,\tau)=0 \) and \( \frac{\mathrm dG}{\mathrm dt}(\tau^+,\tau)=\frac1{\alpha(\tau)} \).</li></ol	Methods proposition Inhomogeneous_Problems_and_Green's_Functions
<b>Definition</b>: Fourier Transform<br><i>[Methods]</i>	For \( f:\to \mathbb{R}\to \mathbb{C} \) define its <i>Fourier Transform</i> by<br>\[<br>\hat f(\lambda)=\int_{-\infty}^\infty e^{-i\lambda x}f(x)\mathrm dx,\quad \lambda\in \mathbb{R}.<br>\]	Methods definition The_Fourier_Transform
<b>Proposition</b> (The Fourier Transform > Definitions and simple properties)<br><i>[Methods]</i>	We'll make some statements about the arthimetic of Fourier transformations.<br><ol><li>\[<br>\mathcal F_{x\to \lambda}\left[\left(\frac{\mathrm d}{\mathrm dx}\right)^kf(x)\right]=(i\lambda)^k\hat f(\lambda)<br>\]<br>\[<br>\mathcal F_{x\to \lambda}\left[x^kf(x)\right]=\left(i\frac{\mathrm d}{\mathrm d\lambda}\right)^k\hat f(\lambda)<br>\]</li><li>\[<br>\mathcal F_{x\to \infty}[f(x-a)]=e^{-i\lambda a}\hat f(\lambda)<br>\]<br>\[<br>\mathcal F_{x\to\infty}[e^{-iax}f(x)]=\hat f(\lambda +a)<br>\]</li></ol	Methods proposition The_Fourier_Transform
<b>Proposition</b> (The Fourier Transform > Definitions and simple properties)<br><i>[Methods]</i>	We can reconstruct \( f \) from \( \hat f \), using the inversion formula for the Fourier transformation,<br>\[<br>f(x)=\frac1{2\pi}\int_{-\infty}^\infty e^{i\lambda x}\hat f(\lambda)\mathrm d\lambda.<br>\]	Methods proposition The_Fourier_Transform
<b>Proposition</b> (The Fourier Transform > Definitions and simple properties)<br><i>[Methods]</i>	For \( f,g:\mathbb{R}\to \mathbb{C} \),<br>\[<br>\int_{-\infty}^\infty f(x)\overline{g(x)}\mathrm dx=\frac1{2\pi}\int_{-\infty}^\infty \hat f(\lambda)\overline{\hat g(\lambda)}\mathrm d\lambda<br>\]<br>hence<br>\[<br>\int_{-\infty}^\infty|f(x)|^2\mathrm dx=\frac1{2\pi}\int_{-\infty}^\infty|\hat f(\lambda)|^2\mathrm d\lambda.<br>\]	Methods proposition The_Fourier_Transform
<b>Definition</b>: Convolution<br><i>[Methods]</i>	For \( f,g:\mathbb{R}\to\mathbb{C} \) define the <i>convolution</i> by,<br>\[<br>f*g(x)=\int_{-\infty}^\infty f(x-y)g(y)\mathrm dy.<br>\]	Methods definition The_Fourier_Transform
<b>Proposition</b> (The Fourier Transform > Definitions and simple properties)<br><i>[Methods]</i>	\[<br>\mathcal F_{x\to \lambda}[f*g(x)]=\hat f(\lambda)\hat g(\lambda).<br>\]	Methods proposition The_Fourier_Transform
<b>Proposition</b>: Poisson summation formula<br><i>[Methods]</i>	For a "nice" function \( f \) we have that<br>\[<br>\sum_nf(x+n)=\sum_n\hat f(2\pi n)e^{2\pi in x}<br>\]	Methods proposition The_Fourier_Transform
<b>Proposition</b> (The Fourier Transform > Discrete Fourier Transform)<br><i>[Methods]</i>	Given \( \{\hat X_k\}_{k=0}^{N-1} \) we can recover \( \{X_n\}_{n=0}^{N-1} \) via<br>\[<br>X_n=\frac 1N\sum_{k=0}^{N-1}\hat X_ke^{i(2\pi k/N)n}.<br>\]	Methods proposition The_Fourier_Transform
<b>Proposition</b>: Parseval's theorem<br><i>[Methods]</i>	We have that,<br>\[<br>\sum_{n=0}^{N-1}X_n\overline Y_n=\frac 1N\sum_{k=0}^{N-1} \hat X_k\overline{\hat Y}_k.<br>\]<br>This also means that<br>\[<br>\sum_{n=0}^{N-1}|X_n|^2=\frac 1N\sum_{k=0}^{N-1}|\hat X_k|^2.<br>\]	Methods proposition The_Fourier_Transform
<b>Proposition</b> (The Fourier Transform > Discrete Fourier Transform)<br><i>[Methods]</i>	\[<br>[\mathcal F(X*Y)]=\hat X_k\hat Y_k.<br>\]	Methods proposition The_Fourier_Transform
<b>Proposition</b> (PDEs on unbounded domains > Classification of second order linear PDEs in 2 variables)<br><i>[Methods]</i>	If \( (x,y)\to (\xi,\eta) \) and \( U(\xi,\eta)=u(x,y) \) then \( Lu \) becomes<br>\[<br>\tilde LU=\sum_{p,q=1}^2 A_{pq}\frac{tial^2 U}{tial \xi_ptial \xi_q}+[\text{lower order terms}]<br>\]<br>where<br>\[<br>A_{pq}=\sum_{i,j=1}^2a_{ij}\frac{tial \xi_p}{tial x_i}\frac{tial \xi_q}{tial x_j}.<br>\]	Methods proposition PDEs_on_unbounded_domains
<b>Proposition</b> (PDEs on unbounded domains > Green's Function for the Heat equation)<br><i>[Methods]</i>	We have that for all \( t >0 \),<br>\[<br>\hat K_t(\boldsymbol \lambda)=\mathcal F_{\mathbf x\to\boldsymbol \lambda}[K_t(\mathbf x)]=e^{-\kappa t|\boldsymbol \lambda|^2}.<br>\]	Methods proposition PDEs_on_unbounded_domains
<b>Proposition</b> (PDEs on unbounded domains > Green's Function for the Heat equation)<br><i>[Methods]</i>	The solution to (i) is<br>\[<br>u(\mathbf x,t)=K_t*f(\mathbf x).<br>\]	Methods proposition PDEs_on_unbounded_domains
<b>Proposition</b> (PDEs on unbounded domains > Green's Function for the Heat equation)<br><i>[Methods]</i>	The solution to (ii) is<br>\[<br>u(\mathbf x,t)=\int_0^t\left[\int K_{t-s}(\mathbf x-\mathbf y)F(\mathbf y,s)\mathrm d^n \mathbf y\right]\mathrm ds.<br>\]	Methods proposition PDEs_on_unbounded_domains
<b>Proposition</b> (PDEs on unbounded domains > Green's Function for Laplace's Equation)<br><i>[Methods]</i>	For \( \alpha>0 \), \( \mathbf x\in \mathbb{R}^n \),<br>\[<br>\mathcal F_{\mathbf x\to\boldsymbol\lambda}[|\mathbf x|^{-\alpha}]=C_{n,\alpha}|\boldsymbol\lambda|^{\alpha-n}<br>\]	Methods proposition PDEs_on_unbounded_domains
<b>Proposition</b> (PDEs on unbounded domains > Green's Function for Laplace's Equation)<br><i>[Methods]</i>	For \( n>2 \) we have that<br>\[<br>G(\mathbf x,\mathbf y)=-\frac 1{(n-2)|S^{n-1}|}\cdot\frac 1{|\mathbf x-\mathbf y|^{n-2}}<br>\]<br>where \( |S^{n-1}| \) is the area of \( S^{n-1} \). If \( n=3 \) we get that<br>\[<br>G(\mathbf x,\mathbf y)=-\frac 1{4\pi}\frac 1{|\mathbf x-\mathbf y|}.<br>\]	Methods proposition PDEs_on_unbounded_domains
<b>Proposition</b> (PDEs on unbounded domains > Green's Function for Laplace's Equation)<br><i>[Methods]</i>	If \( n=2 \), a Free Space Green's function for Laplace's equation is<br>\[<br>G(\mathbf x,\mathbf y)=\frac{1}{2\pi}\log|\mathbf x-\mathbf y|.<br>\]	Methods proposition PDEs_on_unbounded_domains
<b>Definition</b>: State of a particle<br><i>[Quantum Mechanics]</i>	We say that \( \psi \) is the <i>state</i> of a particle, where \( \psi(\mathbf{x},t) \) is the complex coefficient of \( \psi \) in the continuous basis of \( \mathbf{x} \) at a given time \( t \). i.e. \( \psi(\mathbf{x},t) \) is \( \psi \) in the \( \mathbf{x} \) representation and is called a wave function.<br>\[<br>\psi(\mathbf{x},t):R^3\to \mathbb{C}<br>\]<br>that satisfies mathematical properties dictated by its physical interpretation.	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Theorem</b> (Foundation of Quantum Mechanics > The Hilbert space)<br><i>[Quantum Mechanics]</i>	If \( \psi_1,\psi_2\in\mathcal H \) then for \( a_1,a_2\in \mathbb{C} \) we have that<br>\[<br>a_1\psi_1+a_2\psi_2\in\mathcal H<br>\]	Quantum_Mechanics theorem Foundation_of_Quantum_Mechanics
<b>Definition</b> (Foundation of Quantum Mechanics > Inner product in $ \mathcal H $)<br><i>[Quantum Mechanics]</i>	Inner product in \( \mathcal H \) is defined as<br>\[<br>(\psi,\phi)=\int_{\mathbb{R}^3}\psi(\mathbf x,t)\psi(\mathbf x,t)\mathrm d^3x.<br>\]	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Theorem</b> (Foundation of Quantum Mechanics > Inner product in $ \mathcal H $)<br><i>[Quantum Mechanics]</i>	If \( \psi,\pgi\in\mathcal H \) then their inner product exists.	Quantum_Mechanics theorem Foundation_of_Quantum_Mechanics
<b>Definition</b>: Norm<br><i>[Quantum Mechanics]</i>	The <i>Norm</i> of a wavefunction \( \psi \) is the real function<br>\[<br>||\psi||=\sqrt{(\psi,\psi)}.<br>\]	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Definition</b>: Normalised<br><i>[Quantum Mechanics]</i>	For a wavefunction \( \psi \) we say that \( \psi \) is normalised if<br>\[<br>||\psi||=1<br>\]	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Definition</b>: Orthogonal<br><i>[Quantum Mechanics]</i>	We say that two wavefunctions \( \psi,\phi\in\H \) are <i>orthogonal</i> if<br>\[<br>(\psi,\phi)=0<br>\]	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Definition</b>: Orthonormal<br><i>[Quantum Mechanics]</i>	A set of wavefunctions \( \{\psi_n\} \) is called <i>orthonormal</i> if<br>\[\begin{aligned}<br>(\psi_m,\psi_n)=\delta_{mn}=\begin{cases}<br>0& m\ne n\\<br>1 & m =n<br>\end{cases}<br>\end{aligned}\]	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Definition</b>: Complete<br><i>[Quantum Mechanics]</i>	A set of wavefunctions \( \{\psi_n\} \) is <i>complete</i> if \( \forall\phi\in \mathcal H \) we can write \( \phi \) as a linear combination of \( \{\psi_n\} \).	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Lemma</b> (Foundation of Quantum Mechanics > Inner product in $ \mathcal H $)<br><i>[Quantum Mechanics]</i>	If \( \{\psi_n\} \) forms a complete and orthonormal basis of \( \mathcal H \) then<br>\[<br>c_n=(\psi_n,\phi)<br>\]	Quantum_Mechanics lemma Foundation_of_Quantum_Mechanics
<b>Definition</b>: Observable<br><i>[Quantum Mechanics]</i>	A property is <i>observable</i> if is described by a particle's state \( \psi \) and can be measured.	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Definition</b> (Foundation of Quantum Mechanics > Hermitian operators)<br><i>[Quantum Mechanics]</i>	An operator \( \hat O \) is any linear map \( \H\to\H \) such that<br>\[<br>\hat O(a_1\psi_1+a_2\psi_2)=a_1\hat O\psi_1+a_2\hat O\psi_2<br>\]<br>with \( a_1,a_2\in \mathbb{C} \) and \( \psi_1,\psi_2\in\H \).	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Definition</b>: Hermitian conjugate<br><i>[Quantum Mechanics]</i>	For an operator \( \hat O \), its <i>Hermitian conjugate</i> \( \hat O^\dagger \) is the operator such that<br>\[<br>(\hat O^\dagger \psi_1,\psi_2)=(\psi_1,\hat O\psi_2)<br>\]<br>for all \( \psi_1,\psi_2\in \H \).	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Definition</b>: Hermitian<br><i>[Quantum Mechanics]</i>	An operator \( \hat O \) is <i>Hermitian</i> if<br>\[<br>\hat O =\hat O^\dagger.<br>\]	Quantum_Mechanics definition Foundation_of_Quantum_Mechanics
<b>Theorem</b> (Foundation of Quantum Mechanics > Hermitian operators)<br><i>[Quantum Mechanics]</i>	The eigenvalues of Hermitian operators are real.	Quantum_Mechanics theorem Foundation_of_Quantum_Mechanics
<b>Theorem</b>: Law of total variance<br><i>[Statistics]</i>	\[<br>\operatorname{Var}\left({X}\right)=\mathbb E[\operatorname{Var}\left({X\mid Y}\right)] +\operatorname{Var}\left({\mathbb E[X\mid Y]}\right).<br>\]	Statistics theorem Parametric_Estimation
<b>Theorem</b>: Weak Law of Large Numbers<br><i>[Statistics]</i>	\[<br>\bar X_n\to \mu<br>\]<br>where \( \to \) means that \( \mathbb{P}\left({|\bar X_n-\mu|>\varepsilon}\right)\to 0 \) as \( n\to \infty \) for all \( \varepsilon>0 \).	Statistics theorem Parametric_Estimation
<b>Theorem</b>: Strong Law of Large Numbers<br><i>[Statistics]</i>	\[ \bar X_n\to \mu \]<br>almost surely. So \( \mathbb{P}\left({\lim_{n\to\infty}\right)\bar X_n=\mu}=1 \).	Statistics theorem Parametric_Estimation
<b>Theorem</b>: Central Limit Theorem<br><i>[Statistics]</i>	The random variables<br>\[<br>Z_n = \frac{S_n-n\mu}{\sigma\sqrt n}<br>\]<br>is approximately \( \mathcal N(0,1) \) for large \( n \). Or we can write this as<br>\[<br>S_n\approx \mathcal N(n\mu, n\sigma^2).<br>\]<br>Formally this means that \( \mathbb{P}\left({Z_n\le z}\right)\to \Phi(z) \) for all \( z\in \mathbb{R} \) where \( \Phi(z) \) is the cdf of \( \mathcal N(0,1) \).	Statistics theorem Parametric_Estimation
<b>Definition</b>: Estimator<br><i>[Statistics]</i>	A function of the data \( T(X)\to\hat\theta \) which is used to approximate the true parameter \( \theta \) is called an <i>estimator</i> (or sometimes a <i>statistic</i>). The distribution of \( T(X) \) is the <i>sampling distribution</i	Statistics definition Parametric_Estimation
<b>Definition</b>: Bias<br><i>[Statistics]</i>	The <i>bias</i> of a random variable \( \hat\theta=T(X) \) is<br>\[<br>\mathrm{bias}(\hat\theta) = \mathbb E_\theta(\hat\theta)-\theta,<br>\]<br>where the expectation is taken over the model \( X_1\sim f_X(\cdot \mid \theta) \).	Statistics definition Parametric_Estimation
<b>Definition</b>: Unbiased estimator<br><i>[Statistics]</i>	We say that an estimator is <i>unbiased</i> if \( \mathrm{bias}(\hat\theta)=0 \) for all \( \theta\in\Theta \).	Statistics definition Parametric_Estimation
<b>Definition</b>: Mean squared error<br><i>[Statistics]</i>	The <i>mean squared error</i> of an estimator \( \hat\theta \) is<br>\[<br>\mathrm{mse}(\hat\theta) = \mathbb E_\theta[(\hat\theta-\theta)^2].<br>\]	Statistics definition Parametric_Estimation
<b>Proposition</b>: Bias-variance decomposition<br><i>[Statistics]</i>	For an estimator \( \hat\theta \) of a parameter \( \theta \), we have that<br>\[<br>\mathrm{mse}(\hat\theta)=\left(\mathrm{bias}(\hat\theta)\right)^2 + \mathrm{Var}_\theta(\hat\theta).<br>\]	Statistics proposition Parametric_Estimation
<b>Definition</b>: Sufficient statistics<br><i>[Statistics]</i>	A statistics \( T \) is <i>sufficient</i> for \( \theta \) if the conditional distribution of \( X\) given \( T(X) \) does not depend on \( \theta \).	Statistics definition Parametric_Estimation
<b>Theorem</b>: Factorisation criterion<br><i>[Statistics]</i>	The statistics \( T \) is sufficient for \( \theta \) if and only if \( f_X(x\mid \theta)= g(T(x),\theta)h(x) \) for some suitable \( g \) and \( h \).	Statistics theorem Parametric_Estimation
<b>Definition</b>: Minimal sufficient<br><i>[Statistics]</i>	A sufficient statistics \( T(X) \) is <i>minimal sufficient</i> if it is a function of every other sufficient statistic. So if \( T'(X) \) is also sufficient, then \( T'(x)=T'(y)\implies T(x)=T(y) \) for all \( x,y\in \chi \).	Statistics definition Parametric_Estimation
<b>Theorem</b> (Parametric Estimation > Minimal sufficiency)<br><i>[Statistics]</i>	Suppose \( T(X) \) is a statistics such that \( \frac{f_X(x\mid \theta)}{f_X(y\mid \theta)} \) is constant a function of \( \theta \) if and only if \( T(x)=T(y) \). Then \( T \) is minimal sufficient.	Statistics theorem Parametric_Estimation
<b>Theorem</b>: Rao-Blackwell Theorem<br><i>[Statistics]</i>	Let \( T \) be a sufficient statistic for \( \theta \) and let \( \tilde\theta \) be an estimator for \( \theta \) with \( \mathbb E(\tilde\theta^2)<\infty,\ \forall\theta \). Define a new estimator \( \hat\theta = \mathbb E[\tilde\theta\mid T(X)] \). Then for all \(\theta \),<br>\[<br>\mathbb E[(\hat\theta-\theta)^2] \le \mathbb E[(\tilde\theta-\theta)^2].<br>\]<br>This inequality is strict unless \( \tilde\theta \) is a function of \( T \).	Statistics theorem Parametric_Estimation
<b>Definition</b>: Likelihood<br><i>[Statistics]</i>	Let \( X=(X_1,\dots X_n) \) have a joint pdf \( f_X(x\mid \theta) \). The <i>likelihood</i> of \( \theta \) is the function<br>\[<br>L:\theta \to f_X(x\mid\theta).<br>\]<br>The max likelihood estimator (MLE) is the value of \( \theta \) maximizing \( L \).	Statistics definition Parametric_Estimation
<b>Definition</b>: Confidence intervals<br><i>[Statistics]</i>	A \( (100\gamma)\%\) confidience interval for a paramter \( \theta \) is a random interval \( (A(X),B(X)) \) such that \( \mathbb{P}\left({A(X)\le \theta\le B(X)}\right)= \gamma \) for some \( \gamma\in (0,1)  \) and all values of the true parameter \( \theta \).	Statistics definition Parametric_Estimation
<b>Definition</b>: Bayes estimator<br><i>[Statistics]</i>	The <i>Bayes estimator</i> \( \hat\theta^{(b)} \) is defined by<br>\[<br>h(\delta) = \int_\Theta L(\theta,\delta)\pi(\theta\mid X)\mathrm d\theta<br>\]<br>and<br>\[<br>\hat \theta^{(b)}= \mathrm{arg}\ \mathrm{min} h(\delta)<br>\]	Statistics definition Parametric_Estimation
<b>Definition</b>: Credible interval<br><i>[Statistics]</i>	A \( 100\gamma\% \) <i>credible interval</i> satifies that<br>\[<br>\pi(A(X)\le \theta\le B(X)\mid X=x) = \gamma.<br>\]	Statistics definition Parametric_Estimation
<b>Definition</b>: Hypothesis<br><i>[Statistics]</i>	A <i>hypothesis</i> is an assumption about a distribution of data \( X \) taking values in \( \chi \).	Statistics definition Hypothesis_Testing
<b>Definition</b>: Null/Alternative hypothesis<br><i>[Statistics]</i>	The <i>null hypothesis</i> \( H_0 \) is the base case. The <i>alternative hypothesis</i> is the positive or negative effect the interesting case, denoted by \( H_1 \).	Statistics definition Hypothesis_Testing
<b>Definition</b>: Simple/composite hypothesis<br><i>[Statistics]</i>	A <i>simple hypothesis</i> fully specifies the distribution of \( X \). Otherwise we say the hypothesis is <i>composite</i>.	Statistics definition Hypothesis_Testing
<b>Definition</b>: Test and critical regions<br><i>[Statistics]</i>	A <i>test</i> of \( H_0 \) is defined by a <i>critical region</i>, C. When \( X\in C \), we reject \( H_0 \), otherwise we do not reject \( H_1 \).	Statistics definition Hypothesis_Testing
<b>Definition</b>: Type I Error<br><i>[Statistics]</i>	A <i>Type I Error</i> occurs when we reject \( H_0 \) when \( H_0 \) is true.	Statistics definition Hypothesis_Testing
<b>Definition</b>: Type II Error<br><i>[Statistics]</i>	A <i>Type II Error</i> occurs when we fail to reject \( H_0 \) when \( H_1 \) is true.	Statistics definition Hypothesis_Testing
<b>Definition</b>: Size<br><i>[Statistics]</i>	We define \( \alpha \) as the <i>size</i> of the test, defined as<br>\[<br>\alpha = \mathbb P_{H_0}(H_0\ \text{rejected}) = \mathbb P_{H_0}(X\in C).<br>\]	Statistics definition Hypothesis_Testing
<b>Definition</b>: Power<br><i>[Statistics]</i>	We define the <i>power</i> of the test as \( 1-\beta \) where<br>\[<br>\beta = \mathbb P_{H_1}(H_0\text{ not rejected}) = \mathbb P_{H_1}(X\notin C).<br>\]	Statistics definition Hypothesis_Testing
<b>Definition</b>: Likelihood ratio statistic<br><i>[Statistics]</i>	Let \( H_0 \) and \( H_1 \) be simple hypotheses with \( X \) having pdf \( f_i \) under \( H_i \). The <i>likelihood ratio statistic</i> is<br>\[<br>\Lambda_X(H_0,H_1) = \frac{f_1(X)}{f_0(X)}.<br>\]<br>\ll	Statistics definition Hypothesis_Testing
<b>Definition</b>: Likelihood ratio test<br><i>[Statistics]</i>	A <i>Likelihood ratio test</i> (LRT) rejects \( H_0 \) when \( X\in C=\{x\in \Lambda_X(H_0,H_1)>k\} \) for some \( k>0\) .	Statistics definition Hypothesis_Testing
<b>Theorem</b>: Neyman-Pearson Lemma<br><i>[Statistics]</i>	Suppose that \( f_0 \) and \( f_1 \) are nonzero on the same sets and \( \exists k\) such that the LRT with critical region \( C=\{x: \frac{f_1(x)}{f_0(x)}>k\} \) has size \( \alpha \). Out of all tests with size \( \le\alpha \) the LRT is the test with smallest \( \beta \).	Statistics theorem Hypothesis_Testing
<b>Definition</b>: $ p $-value<br><i>[Statistics]</i>	For any test with critical region of the form \( \{x: T(x) > k\} \) where \( T \) is some statistic, we usually report the \( p \)-<i>value</i><br>\[<br>p = \mathbb P_{H_0}(T(X)>T(X^*))<br>\]<br>where \( x^* \) is the observed data.	Statistics definition Hypothesis_Testing
<b>Proposition</b> (Hypothesis Testing > Simple hypotheses)<br><i>[Statistics]</i>	Uner \( H_0 \) the \( p \)-value is \( \mathrm{Uniform}[0,1]\).	Statistics proposition Hypothesis_Testing
<b>Definition</b>: Acceptance region<br><i>[Statistics]</i>	The <i>acceptance region</i> of a test is the complement of the critical region.	Statistics definition Hypothesis_Testing
<b>Theorem</b> (Hypothesis Testing > Simple hypotheses)<br><i>[Statistics]</i>	ol><li>Suppose that for each \( \theta_0\in \Theta \) there exists a test of \( H_0:\theta = \theta_0 \) of size \( \alpha \) with acceptance region \( A(\theta_0) \). Then the set \( I(X) = \{ \theta: X\in A(\theta)\} \) is a \( 100(1-\alpha)\% \) confidence set.</li><li>Suppose that \( I(X) \) is a \( 100(1-\alpha)\% \) confidence set for \( \theta \). Then<br>\[<br>A(\theta_0) = \{x:\theta_0\in I(X)\}<br>\]<br>is the acceptance region of a size \( \alpha \) test for<br>\( H_0:\theta = \theta_0 \) for each \( \theta \in \Theta \).</li></ol	Statistics theorem Hypothesis_Testing
<b>Definition</b>: Power function<br><i>[Statistics]</i>	The <i>power function</i> is \( W(\theta)= \mathbb P_\theta(X\in C) \).	Statistics definition Hypothesis_Testing
<b>Definition</b>: Size<br><i>[Statistics]</i>	The <i>size</i> of a test with composite null \( H_0 \) is the worst-case Type I error probability, so<br>\[<br>\alpha = \sup_{\theta\in \Theta_0} W(\theta).<br>\]	Statistics definition Hypothesis_Testing
<b>Definition</b>: Uniformly most powerful<br><i>[Statistics]</i>	We say that a test of \( H_0 \) against \( H_1 \) is <i>uniformly most powerful</i> (UMP) of size \( \alpha \) if<br><ol><li>\( \sup_{\theta\in\Theta_0} W(\theta)\le \alpha \);</li><li>For any other test of size \( \alpha \), with power function \( W^* \) we have that<br>\[<br>W(\theta) \ge W^*(\theta)\quad \forall\theta\in \Theta_1.<br>\]</li></ol	Statistics definition Hypothesis_Testing
<b>Definition</b>: Topology<br><i>[Topological Spaces]</i>	Let \( X \) be a set. A <i>topology</i> on \( X \) is a collection of sets \( T\subseteq \mathcal P(X) \) such that<br><ol><li>\(\emptyset, X\in T \),</li><li>\( T \) is closed under (possibly uncountable) unions.</li><li>\( T \) is closed under finite intersections.</li></ol	Topological_Spaces definition Topologies
<b>Definition</b>: Continuity<br><i>[Topological Spaces]</i>	If \( (X,T_X) \) and \( (Y,T_Y) \) are topological spaces then a function \( f:X\to Y \) is called <i>continuous</i> if for \( U\in T_Y \), \( \inv f(U)\in T_X \).	Topological_Spaces definition Topologies
<b>Definition</b>: Homeomorphism<br><i>[Topological Spaces]</i>	A function \( f:(X,T_X)\to (Y,T_Y) \) is a <i>homeomorphism</i> if it is continuous and has a continuous inverse.	Topological_Spaces definition Topologies
<b>Definition</b> (Topologies > Definitions)<br><i>[Topological Spaces]</i>	If \( T\subseteq T' \) are topologies on \( X \) then we say that \( T \) is <i>coarser</i> and \( T' \) is <i>finer</i>. The identity function \( d: (X,T)\to (X,T') \) is continuous.	Topological_Spaces definition Topologies
<b>Proposition</b> (Topologies > Topologies from metrics)<br><i>[Topological Spaces]</i>	If \( T_d \) is the subset of \( X \) which are open under the metric \( d \), then \( (X,T_d) \) is a topological space. We will call this the topology on \( X \) induced by the metric \( d \).	Topological_Spaces proposition Topologies
<b>Proposition</b> (Topologies > Topologies from metrics)<br><i>[Topological Spaces]</i>	If we have two metric spaces \( (X,d_X), (Y,d_Y) \) and we have \( f:X\to Y \), the \( f \) is continuous in the metric space sense if and only if it is continuous in the topological space sense (with the topologies induced by the metric \( d_X \) and \( d_Y \) respectively).	Topological_Spaces proposition Topologies
<b>Definition</b> (Topologies > Topologies from metrics)<br><i>[Topological Spaces]</i>	Let \( (X,T) \) be a topological space and \( x_1,x_2,\dots \in X \) say. We say that \( x_n \) convergences to \( x \) if for every open neighbourhood \( U \) of \( x \) there exists a \( N \) such that \( x_n\in U \) for all \( n\ge N \).	Topological_Spaces definition Topologies
<b>Proposition</b> (Topologies > Topologies from metrics)<br><i>[Topological Spaces]</i>	If \( (X,d) \) is a metric space with topology \( T_d \) then a sequence \( (x_n) \) converges in the metric sense if and only if it converges in the topological sense.	Topological_Spaces proposition Topologies
<b>Definition</b>: Discrete topology<br><i>[Topological Spaces]</i>	Let \( X \) be a set. The <i>discrete</i> topology is the topology \( T_{\text{discrete}} = \mathcal P(X) \) (so every set is open).	Topological_Spaces definition Topologies
<b>Definition</b>: Indiscrete topology<br><i>[Topological Spaces]</i>	Let \( X \) be a set. The <i>indiscrete</i> topology \( T_{\text{indiscrete}} = \{\emptyset, X\} \) (as little as possible sets are open).	Topological_Spaces definition Topologies
<b>Definition</b>: Basis<br><i>[Topological Spaces]</i>	Let \( T \) be a topology of \( X \). A <i>basis</i>, \( B\subseteq T \) for \( T \) is a subcollection such that every element of \( T \) is a union of elements in \( B \).	Topological_Spaces definition Topologies
<b>Definition</b>: Subbasis<br><i>[Topological Spaces]</i>	Let \( T \) be a topology of \( X \). A <i>subbasis</i>, \( S\subseteq T \) for \( T \) is a subcollection such that every element of \( T \) is a union of sets which are finite intersections of elements of \( S \).	Topological_Spaces definition Topologies
<b>Lemma</b> (Topologies > Bases and subbases)<br><i>[Topological Spaces]</i>	Let \( f:(X,T_X)\to (Y,T_Y) \) and \( S\subseteq T_Y \) is a subbasis. If \( \inv f(U) \) is open for all \( U\in S \) then \( f \) is continuous.	Topological_Spaces lemma Topologies
<b>Definition</b>: Closed set<br><i>[Topological Spaces]</i>	Let \( (X,T) \) be a topological space. A subset \( C\subseteq X \) is <i>closed</i> if \( X\setminus C\in T \).	Topological_Spaces definition Topologies
<b>Proposition</b> (Topologies > Bases and subbases)<br><i>[Topological Spaces]</i>	Let \( (X,T) \) be a topological space and \( \mathcal F = \{ C\subseteq X \mid C \ \text{closed} \} \). Then<br><ol><li>\( \emptyset, X\in \mathcal F \);</li><li>\( \mathcal F \) is closed under (possibly uncountable) intersections;</li><li>\( \mathcal F \) is closed under finite unions.</li></ol	Topological_Spaces proposition Topologies
<b>Proposition</b> (Topologies > Bases and subbases)<br><i>[Topological Spaces]</i>	A function \( f:X\to Y \) between topological spaces is continuous if and only if the preimage of every closed set is closed.	Topological_Spaces proposition Topologies
<b>Definition</b> (Topologies > Bases and subbases)<br><i>[Topological Spaces]</i>	Let \( (X,T) \) be a topological space. Let \( A\subseteq X \) be a subset of \( X \). Then<br><ol><li>The closure \( \bar A \) is the smallest (by inclusion) closed set containing \( A \) so<br>\[<br>\bar A = \bigcap_{S\ \text{closed}, A\subseteq S} S.<br>\]</li><li>We say that \( A \) is dense in \( X \) if \( A=\bar A \).</li><li>The interior \( \mathring{A} \) is the largest open set contained in \( A \) so<br>\[<br>\mathring{A} = \bigcup_{S\ \text{open}, S\subseteq A} S.<br>\]</li></ol	Topological_Spaces definition Topologies
<b>Definition</b>: Limit point<br><i>[Topological Spaces]</i>	Let \( X \) be a topological space and \( A\subseteq X \). A <i>limit point</i> of \( A \) is a point in \( X \) which is a limit of a sequence in \( A \).	Topological_Spaces definition Topologies
<b>Proposition</b> (Topologies > Bases and subbases)<br><i>[Topological Spaces]</i>	If \( C \) is a closed subset of \( (X,T) \), then the limit points of \( C \) lie in \( C \).	Topological_Spaces proposition Topologies
<b>Corollary</b> (Topologies > Bases and subbases)<br><i>[Topological Spaces]</i>	A limit point of a \( A \) lies in \( \bar A \).	Topological_Spaces corollary Topologies
<b>Definition</b>: Hausdorff<br><i>[Topological Spaces]</i>	A space \( (X,T) \) is <i>Hausdorff</i> if for \( x\ne y \in X \) there are open neighbourhoods \( x\in U \), \( y\in V \) with \( U\cap V=\emptyset \).	Topological_Spaces definition Topologies
<b>Lemma</b> (Topologies > Hausdorff spaces)<br><i>[Topological Spaces]</i>	If the topology \( T \) is induced by a metric then it is Hausdorff.	Topological_Spaces lemma Topologies
<b>Proposition</b> (Topologies > Hausdorff spaces)<br><i>[Topological Spaces]</i>	If a space is Hausdorff then a sequence in \( X \) has at most \( 1 \) limit.	Topological_Spaces proposition Topologies
<b>Proposition</b> (Topologies > Hausdorff spaces)<br><i>[Topological Spaces]</i>	If \( (X,T) \) is Hausorff then points are closed.	Topological_Spaces proposition Topologies
<b>Definition</b>: Subset topology<br><i>[Topological Spaces]</i>	Let \( (X,T_X) \) be a topological space. Let \( Y\subseteq X \) a subset. The <i>subset topology</i> on \( Y \) is<br>\[<br>T\mid_Y = \{Y\cap U \mid U\in T\}.<br>\]	Topological_Spaces definition Topologies
<b>Definition</b>: Subspace<br><i>[Topological Spaces]</i>	A subspace of \( (X,T) \) is a subset equipped with the subspace topology.	Topological_Spaces definition Topologies
<b>Proposition</b> (Topologies > Defining new topologies on existing ones > The subspace topology)<br><i>[Topological Spaces]</i>	The subset topology is a topology.	Topological_Spaces proposition Topologies
<b>Proposition</b> (Topologies > Defining new topologies on existing ones > The subspace topology)<br><i>[Topological Spaces]</i>	The inclusion map \( \iota: (Y,T\mid_Y)\to (X,T) \) is continuous. In fact \( T\mid_Y \) is the constant topology on \( Y \) such that the inclusion map is continuous.	Topological_Spaces proposition Topologies
<b>Lemma</b>: Gluing Lemma<br><i>[Topological Spaces]</i>	Let \( f:X\to Y \) be a function between topological spaces.<br><ol><li>If \( \{U_\alpha\}_{\alpha\in I} \) are open subsets which cover \( X \) and each \( f\mid_{U_\alpha}:U_\alpha\to Y \) are continuous (where \( U_\alpha \) is given the subspace topology) then \( f \) is continuous.</li><li>If \( \{C_\alpha\}_{\alpha\in I} \) is a finite collection of closed sets containing \( X \) and \( f\mid_{C_\alpha}:C_\alpha\to Y \) is continuous for each \( a\in I \) then \( f \) is continuous.</li></ol	Topological_Spaces lemma Topologies
<b>Definition</b>: Quotient topology<br><i>[Topological Spaces]</i>	Let \( (X,T_X) \) be a topological space, \( \sim \) an equivalence relation on \( X \) and \( X/\sim \) is the set of equivalence classes, and \( \pi:X\to X/\sim \) the equivalence map. The <i>quotient toplogy</i> on \( X/\sim \) is<br>\[<br>T_{X/\sim} = \{U\subset X/\sim \mid \inv\pi (U)\in T_X\}.<br>\]	Topological_Spaces definition Topologies
<b>Proposition</b> (Topologies > Defining new topologies on existing ones > The quotient topology)<br><i>[Topological Spaces]</i>	\( T_{X/\sim} \) is indeed a topology.	Topological_Spaces proposition Topologies
<b>Proposition</b> (Topologies > Defining new topologies on existing ones > The quotient topology)<br><i>[Topological Spaces]</i>	The quotient map \( \pi:(X,T_X)\to (X/\sim, T_{X/\sim}) \) is continuous and \( T_{X/\sim} \) is the finest topology for which this is true.	Topological_Spaces proposition Topologies
<b>Definition</b> (Topologies > Defining new topologies on existing ones > The quotient topology)<br><i>[Topological Spaces]</i>	For a continuous function \( g:(X,T_X)\to (Y,T_Y) \) is a <i>quotient map</i> if it surjective and \( U\in T_Y \iff \inv g(Y)\in T_X\).<br>Given, this construct \( \sim \) on \( X \) by \( x\sim x' \iff g(x)=g(x')\). There is an induced function \( G:X/\sim \to Y \) sending \( G([x]) = g(x) \).	Topological_Spaces definition Topologies
<b>Definition</b>: Product topology<br><i>[Topological Spaces]</i>	Let \( (X,T_X) \) and \( (Y,T_Y) \) be topological spaces. Then <i>product topology</i> on \( X\times Y \) consists of open sets \( U\subseteq X\times Y \) such that for \( (x,y)\in U \) there is a \( V\in T_X \) and \( W\in T_Y \) such that \( (x,y)\in V\times W\in U \).	Topological_Spaces definition Topologies
<b>Proposition</b> (Topologies > Defining new topologies on existing ones > The product topology)<br><i>[Topological Spaces]</i>	This indeed is a topology and the sets \( V\times W \) are a basis for \( T_{X\times Y} \).	Topological_Spaces proposition Topologies
<b>Proposition</b> (Topologies > Defining new topologies on existing ones > The product topology)<br><i>[Topological Spaces]</i>	The projection maps<br>\[<br>\pi_X:(X\times Y, T_{X\times Y})\to (X,T_{X})\qquad \pi_Y:(X\times Y,T_{X\times Y})\to (Y,T_Y)<br>\]<br>are continuous and \( T_{X\times Y} \) is the coarsest topology for which this is true.	Topological_Spaces proposition Topologies
<b>Definition</b>: Disconnected<br><i>[Topological Spaces]</i>	A topological space \( X \) is <i>disconnected</i> if \( X = U \cup V \) for \( U,V \) disjoint nonempty open sets.	Topological_Spaces definition Connectivity
<b>Definition</b>: Connected<br><i>[Topological Spaces]</i>	A topological space is <i>connected</i> if it is not disconnected.	Topological_Spaces definition Connectivity
<b>Proposition</b> (Connectivity > Connected and disconnected)<br><i>[Topological Spaces]</i>	A space \( X \) is disconnected if and only if, there is a continuous surjection \( f:X\to \{0,1\} \) where \( \{0,1\} \) is equipped with the discrete topology.	Topological_Spaces proposition Connectivity
<b>Theorem</b> (Connectivity > Connected and disconnected)<br><i>[Topological Spaces]</i>	The spaces \( [0,1] \), \( [0,1) \), \( (0,1) \) are all connected.	Topological_Spaces theorem Connectivity
<b>Theorem</b>: Generalised intermediate value theorem<br><i>[Topological Spaces]</i>	Let \( X \) be a connected topological space and \( f:X\to \mathbb{R} \) continuous. If there exists \( x_0,x_1\in X \) such that \( f(x_0)< 0 < f(x_1) \) then there exists a \( x_2\in X \) such that \( f(x_2) = 0 \).	Topological_Spaces theorem Connectivity
<b>Proposition</b> (Connectivity > Connected and disconnected)<br><i>[Topological Spaces]</i>	Let \( f:X\to Y \) be a continuous surjection. Then \( X \) connected implies that \( Y \) is connected.	Topological_Spaces proposition Connectivity
<b>Corollary</b> (Connectivity > Connected and disconnected)<br><i>[Topological Spaces]</i>	If \( X \) is connected and \( f: X\to Y \) is continuous then \( \operatorname{im}(f) \) is connected.	Topological_Spaces corollary Connectivity
<b>Lemma</b> (Connectivity > Connected and disconnected)<br><i>[Topological Spaces]</i>	If \( f:X\to Y \) is a homeomorphism and \( Z\subseteq X \), then \( f\mid_Z:Z\to \operatorname{im}(f\mid_Z) \) is a homeomorphism.	Topological_Spaces lemma Connectivity
<b>Proposition</b> (Connectivity > Connected and disconnected)<br><i>[Topological Spaces]</i>	Let \( \{ X_\alpha\}_{\alpha \in I} \) be a collection of subspaces of \( X \). Suppose that each \( X_\alpha \) is connected and \( \bigcap_{\alpha\in I} X_\alpha\ne\emptyset \). Then \( \bigcup_{\alpha \in I} X_\alpha \) is connected.	Topological_Spaces proposition Connectivity
<b>Corollary</b> (Connectivity > Connected and disconnected)<br><i>[Topological Spaces]</i>	If \( X \) and \( Y \) are connected then so is \( X\times Y \).	Topological_Spaces corollary Connectivity
<b>Definition</b>: Path<br><i>[Topological Spaces]</i>	If \( X \) is a topological space and \( x_0,x_1\in X \) a <i>path</i> between them is a continuous \( \gamma:[0,1]\to X \) such that \( \gamma(0)=x_0 \) and \( \gamma(1)= x_1 \).	Topological_Spaces definition Connectivity
<b>Definition</b>: Path connected<br><i>[Topological Spaces]</i>	A topological space is <i>path connected</i> if for any two points in the space, there is a path between them.	Topological_Spaces definition Connectivity
<b>Proposition</b> (Connectivity > Path-connectedness)<br><i>[Topological Spaces]</i>	A path-connected space is connected.	Topological_Spaces proposition Connectivity
<b>Proposition</b> (Connectivity > Path-connectedness)<br><i>[Topological Spaces]</i>	If \( X \) and \( Y \) are path-connected then \( X\times Y \) is path-connected.	Topological_Spaces proposition Connectivity
<b>Lemma</b> (Connectivity > Path-connectedness > Path components)<br><i>[Topological Spaces]</i>	\( \sim \) is indeed an equivalence relation.	Topological_Spaces lemma Connectivity
<b>Definition</b>: Path components<br><i>[Topological Spaces]</i>	The <i>path components</i> of \( X \) are the equivalence classes of \( \sim \).	Topological_Spaces definition Connectivity
<b>Lemma</b> (Connectivity > Path-connectedness > Connected components)<br><i>[Topological Spaces]</i>	\( \approx \) is an equivalence relation.	Topological_Spaces lemma Connectivity
<b>Definition</b>: Connected components<br><i>[Topological Spaces]</i>	Let the <i>connected components</i> of \( X \) are the equivalence classes of \( \approx \).	Topological_Spaces definition Connectivity
<b>Proposition</b> (Connectivity > Path-connectedness > Connected components)<br><i>[Topological Spaces]</i>	The connected components are connected.	Topological_Spaces proposition Connectivity
<b>Lemma</b> (Connectivity > Path-connectedness > Connected components)<br><i>[Topological Spaces]</i>	The closure of a connected subspace is connected.	Topological_Spaces lemma Connectivity
<b>Definition</b>: Cover<br><i>[Topological Spaces]</i>	A collection \( \mathcal X\subset P(X) \) is a <i>cover of</i> \( X \) if for each \( x\in X \) there is a \( S\in \mathcal X \) with \( x\in S \).	Topological_Spaces definition Connectivity
<b>Definition</b>: Open cover<br><i>[Topological Spaces]</i>	An <i>open cover</i> of \( X \) is a cover consisting of open sets.	Topological_Spaces definition Connectivity
<b>Definition</b>: Subcover<br><i>[Topological Spaces]</i>	A <i>subcover</i> of \( \mathcal X \) is a \( \mathcal X'\subseteq \mathcal X \) which is also a cover.	Topological_Spaces definition Connectivity
<b>Definition</b>: Compact<br><i>[Topological Spaces]</i>	A topological space \( X \) is <i>compact</i> if every open cover has a finite subcover.	Topological_Spaces definition Connectivity
<b>Theorem</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	\( [0,1] \) is compact.	Topological_Spaces theorem Connectivity
<b>Proposition</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	If \( X \) is compact and \( C\subseteq X \) is closed, then \( C \) is compact.	Topological_Spaces proposition Connectivity
<b>Proposition</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	If \( X \) is Hausdorff and \( C \subseteq X \) is compact, then \( C \) is closed.	Topological_Spaces proposition Connectivity
<b>Proposition</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	If \( X \) is compact and \( f:X\to Y \) is continuous, then \( f(X) \) is a compact subspace of \( Y \).	Topological_Spaces proposition Connectivity
<b>Corollary</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	If \( f:X\to Y \) is a continuous bijection from a compact space \( X \) to a Hausdorff space \( Y \), then it is a homeomorphism.	Topological_Spaces corollary Connectivity
<b>Definition</b>: Sequentially compact<br><i>[Topological Spaces]</i>	A metric space \( (X,d) \) is <i>sequientially compact</i> if every sequence in \( X \) has a convergent subsequence.	Topological_Spaces definition Connectivity
<b>Lemma</b>: Lebesgue's number lemma<br><i>[Topological Spaces]</i>	Let \( (X,d) \) be sequentially compact and \( \mathcal U \subset T_d \) be an open cover.  Then there is a \( \delta>0 \) such that each \( B_\delta (X) \) lies inside some element of \( \mathcal U \).	Topological_Spaces lemma Connectivity
<b>Theorem</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	The metric space \( (X,d) \) is sequentially comapct if and only if \( (X,T_d) \) is compact.	Topological_Spaces theorem Connectivity
<b>Corollary</b>: Heine-Borel Theorem<br><i>[Topological Spaces]</i>	A subspcae \( X\subseteq \mathbb{R}^n \) is compact if and only if it is closed and bounded.	Topological_Spaces corollary Connectivity
<b>Corollary</b>: Extreme value theorem<br><i>[Topological Spaces]</i>	If \( X \) is a compact topological space and \( f:X\to\mathbb{R} \) is continuous then there are \( a,b\in x \) such that<br>\[<br>f(a)\le f(x) \le f(b)\qquad \forall x\in X.<br>\]	Topological_Spaces corollary Connectivity
<b>Theorem</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	If \( X \) and \( Y \) are compact, then the product space \( X\times Y \) is compact.	Topological_Spaces theorem Connectivity
<b>Lemma</b>: Tube lemma<br><i>[Topological Spaces]</i>	If \( Y \) is compact, \( x_0\in X \) and \( \{x_0\}\times Y\subseteq W \) is an open neighbourhood then there is an open neighbourhood \( U_{x_0}\ni x_0 \) such that \( U_{x_0}\times Y\subseteq W \).	Topological_Spaces lemma Connectivity
<b>Corollary</b> (Connectivity > Compactness)<br><i>[Topological Spaces]</i>	\( [0,1]^n \) is compact.	Topological_Spaces corollary Connectivity
<b>Corollary</b>: Heine-Borel<br><i>[Topological Spaces]</i>	A subspace \( X\subseteq R^n \) is compact if and only if it is closed and bounded.	Topological_Spaces corollary Connectivity
<b>Theorem</b> (Connectivity > Compactness > The finite intersection property)<br><i>[Topological Spaces]</i>	A space \( X \) is compact if every collection of closed subsets \( \{C_\alpha\mid \alpha \in I\} \) having the finite intersection property has<br>\[<br>\bigcap_{\alpha \in I} C_\alpha \ne \emptyset.<br>\]	Topological_Spaces theorem Connectivity
<b>Definition</b>: Stationary point<br><i>[Variational Principles]</i>	A point \(\mathbf a\in \mathbb{R}^n  \) is a <i>stationary point</i> of \( f \) if and only if \( (\nabla f)(\mathbf a)=0 \)	Variational_Principles definition Calculus_on_$_\R^n_$
<b>Definition</b>: Convex set<br><i>[Variational Principles]</i>	A set \( S \) is <i>convex</i> if and only if \( \forall x,y\in S \) and \( \forall t\in (0,1) \) we have that \( (1-t)x+ty\in S \).	Variational_Principles definition Calculus_on_$_\R^n_$
<b>Definition</b>: Convex function<br><i>[Variational Principles]</i>	A function \( f:S\to \mathbb{R} \) is convex if<br><ol><li>\( S \) is a convex set</li><li>The graph of \( f \) lies below on or below all of its chords i.e we have that<br>\[<br>f((1-t)\mathbf x + t\mathbf y)\le (1-t)f(\mathbf x)+tf(\mathbf y)<br>\]<br>for all \( t\in (0,1) \) and for all \( \mathbf x, \mathbf y \in S \).\\<br>We say that \( f \) is <i>strictly convex</i> if the condition in (ii) is strict when \( \mathbf x\ne \mathbf y \).</li></ol	Variational_Principles definition Calculus_on_$_\R^n_$
<b>Lemma</b> (Calculus on $ \R^n $ > Convex functions)<br><i>[Variational Principles]</i>	\( f \) is strictly concave if and only if \( f \) is strictly convex.	Variational_Principles lemma Calculus_on_$_\R^n_$
<b>Theorem</b> (Calculus on $ \R^n $ > First order conditions)<br><i>[Variational Principles]</i>	If \( f \) is differentiable \( f \) on a convex domain \( D(f) \), then \( f \) is convex if and only if<br>\[<br>f(\mathbf y) \ge  f(\mathbf x) + (\mathbf y -\mathbf x) \cdot\nabla f(\mathbf x).<br>\]	Variational_Principles theorem Calculus_on_$_\R^n_$
<b>Definition</b>: Legendre transform<br><i>[Variational Principles]</i>	The <i>Legendre transform</i> of a function \( f:D(f)\to \mathbb{R} \) is defined as<br>\[<br>f^*(\mathbf p)=\sup_{\mathbf x}\left[\mathbf p\cdot \mathbf x-f(\mathbf x)\right]<br>\]<br>with the domain of \( f^* \) being the subset of \( \mathbb{R}^n \) where the suprenum exists.	Variational_Principles definition Legendre_Transform
<b>Corollary</b> (Legendre Transform)<br><i>[Variational Principles]</i>	If \( f \) convex and differentiable then any stationary point of \( \mathbf p\cdot\mathbf x - f(\mathbf x) \) is a global maximium occuring at \( \mathbf x(\mathbf p)  \) found by solving \( \nabla f(\mathbf x)=\mathbf p \).	Variational_Principles corollary Legendre_Transform

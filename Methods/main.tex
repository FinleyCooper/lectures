\documentclass{article}
\usepackage{../header}
\title{Methods}
\author{Notes made by Finley Cooper}
\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
\section{Fourier Series}
\subsection{Motivation}
In 1807 J. Fourier was studying head conduction along a metal rod. This lead him to study $ 2\pi $-periodic functions i.e. functions $ f:\R\to \R $ was such that $ f(\theta+2\pi)=f(\theta) $ for all $ \theta\in \R $ then he found that if \[
	f(\theta)=\sum_{n\in\Z}\hat{f_n}e^{in\theta}
\]
then you can write down the coefficients $ \{\hat{f_n}\} $ via the formula
\[
	\hat{f_n}=\frac 1{2\pi}\int_{0}^{2\pi}f(\theta)e^{-in\theta}\mathrm d\theta,\quad n\in \Z.
\]
And Fourier believed that this worked for any $ 2\pi $-periodic function $ f $. So computing each $ \{\hat{f}_n\} $ and construcuted the sum as above, then it would return the original function. He was wrong.
\subsection{Modern Treatment}
Introduce a vector space $ V $ of $ L $-periodic functions. Hence
\[
	V=\{f:\R\to\C:\text{ with } f \text{ a "nice" function},\text { } f(\theta+L)=f(\theta), \forall \theta\in\R\}.
\]
Note for $ f\in V $ need only to consider values of $ f $ taken in an interval of length $ L $, i.e. $ [0,L) $ or $ (-\frac L2,\frac L2] $ since periodicity covers elsewhere.\par
We can introduce an inner product on $ V $ with
\[
	\langle f,g\rangle=\int_0^1f(\theta)\overline{g(\theta)}\mathrm d\theta.
\]
This gives the associated norm,
\[
	||f||=\sqrt{\langle f,f\rangle}.
\]
For $ n\in \Z $ consider $ e_n\in V $ defined by $ e_n(\theta)=e^{2\pi i n\theta / L }$.
\[
\langle e_n,e_m\rangle = \int_0^L e^{2\pi i (n-m)\theta / L}\,\mathrm d\theta = L\,\delta_{nm}.
\]
So $ \{e_n\} $ are orthogonal and $ ||e_n||^2=L $ for each $ n\in \Z $. This looks like IA Vectors and Matrices.\par
Recall that if $ v_N $ is $ N $-dim vector space equipped with usual inner product and $ \{ e_n\}^N_{n=1} $ are orthogonal with $ | e_n|=L $, then for each $  x\in V $ we can write $  x = \sum_{n=1}^N \hat{x}_n{e_n} $ for some $ \{\hat {x}_n\} $. To find $ \{\hat{x}_n\} $ take the inner product of both sides with $  e_m $. So
\[
	( x,  e_m)=\sum_{n=1}^N \hat{x}_n( e_n\cdot  e_m)=L\hat{x}_m
\]
i.e
\[
\hat x_n = \frac 1L( x\cdot  e_n).
\]
Now could this work on $ V $? $ V $ is not finite dimensional so it's not obvious. Every subset of $ \{e_n\} $ is linearly indepedent. Ignoring this for now we assume that for all $ f\in V $ we can write $ f $ in our basis $ \{e_n\} $. Then
\[
  f(\theta)=\sum_n\hat f_ne_n(\theta),
\]
So taking the inner product as before
\[
  \langle f,e_m\rangle = \sum_n\hat f_n\langle e_n,e_m\rangle
\]
so using the delta as before
\[
  =L\hat f_m
\]
i.e.
\[
	\hat f_n=\frac{1}{L}\langle f, e_n\rangle = \frac{1}{L} \int_0^1 f(\theta)e^{-2\pi in\theta/L}\mathrm d\theta
\]
\begin{definition}
	(Complex Fourier series) For an $ L $-periodic $ f:\R\to \C $ define its \textit{complex Fourier series} by
	\[
		\sum_n\hat f_n e^{2\pi in \theta /L}
	\]
	where
	\[
		\hat f_n = \frac 1L \int_0^1 f(\theta) e^{-2\pi in\theta/L}\mathrm d \theta
	\]
	are called the complex Fourier coefficients. We will write for $ f\in V $
	\[
		f(\theta)\sim \sum_n\hat f_n e^{2\pi in\theta/L}
	\]
	to mean the series on the right corresponds to complex Fourier series for the function on the left.
\end{definition}
We'd like to replace the $ \sim $ symbol with equality, but we require a bit more than that.\par
If we split the complex Fourier series into the parts $\{n=0\}\cup\{n>0\}\cup\{n<0\}$ we get
\[
\sum_n\hat f_n e^{2\pi i n\theta / L} = \hat f_0 + \sum_{n=1}^\infty \hat f_n\left[\cos\left(\frac{2\pi n\theta}{L}\right)+i\sin\left(\frac{2\pi n\theta}{L}\right)\right]
+
\sum_{n=1}^\infty \hat f_{-n}\left[\cos\left(\frac{2\pi n\theta}{L}\right)-i\sin\left(\frac{2\pi n\theta}{L}\right)\right].
\]

\begin{definition}
	(Fourier series) For $ f: \R\to \C $ an $ L $-periodic function define its \textit{Fourier series} by
	\[
		\frac 1L a_0+\sum_{n=1}^\infty\left[a_n\cos\left(\frac{2\pi n\theta}L\right)+b_n\sin\left(\frac{2\pi n\theta}L\right)\right]
	\]
	where
	\[
		a_n=\frac 2L\int^L_0f(\theta)\cos\left(\frac{2\pi n\theta}L\right)\mathrm d\theta
	\]
	and
	\[
		b_n=\frac 2L\int^L_0f(\theta)\sin\left(\frac{2\pi n\theta}L\right)\mathrm d\theta
	\]
	are called the Fourier cofficients for $ f $.
\end{definition}
If we set
\begin{align*}
c_n(\theta) &= \cos\left(\frac{2\pi n\theta}{L}\right),\\
s_n(\theta) &= \sin\left(\frac{2\pi n\theta}{L}\right),
\end{align*}
then we can show, for $ m,n\ge 1 $ that $ \langle c_n,c_m\rangle=\langle s_n, s_m\rangle =\frac L2 \delta_{mn} $ and
\[
  \langle c_n,1\rangle = \langle s_m,1\rangle = \langle c_n, s_m \rangle = 0.
\]
So we have that $ \{1,c_n,c_n\} $ is orthogonal set in $ V $.\par
For an example take $ f:\R\to \R $, $1$-periodic, such that $ f(\theta)=\theta(1-\theta)$ on $[0,1)$. For $n\neq 0$ we have
\[
\hat f_n = \int_0^1 \theta(1-\theta)e^{-2\pi i n\theta}\,\mathrm d\theta.
\]
Integrating by parts (or using a standard Fourier integral computation) yields
\[
\hat f_n = -\frac{1}{2(\pi n)^2},\qquad n\neq 0,
\]
and
\[
\hat f_0 = \int_0^1 (\theta-\theta^2)\,\mathrm d\theta = \frac{1}{6}.
\]
Hence
\[
f(\theta) \sim \frac{1}{6} - \sum_{n\neq 0}\frac{e^{2\pi i n\theta}}{2(\pi n)^2}.
\]
so the sine terms cancel in the sum giving just cosine terms as we expect since our $ f $ function is even.
\subsection{Convergence of Fourier series}
This subject is extremely subtle.

\begin{definition}
	For $ f:\R\to \C $ an $ L $-periodic function we defined the \textit{partial Fourier series} as
	\begin{align*}
		(S_Nf)(\theta)&=\sum_{|n|<N}\hat f_ne^{2\pi in\theta /L} \\
			      &= \frac 12a_0+\sum_{n=1}^N\left[a_n\cos\left(\frac {2\pi n\theta}L\right)+b_n\sin\left(\frac{2\pi n\theta}L\right)\right]
	\end{align*}
\end{definition}
Natural to ask if $ (S_Nf)\to f $. For this we need to specify what type of functional convergence we're looking at. Pointwise? Uniform? Maybe they converge in the idea of our new norm?
\[
	||S_Nf-f||=\sqrt{\int_0^L|(S_Nf)(\theta)-f(\theta)|^2\mathrm d\theta}\to 0
\].
For simplicity, we will only consider pointwise convergence.
\begin{proposition}
  Let $ f:\R\to\C $ be an $ L $-periodic function for which on $ [0,L) $ we have the following,
  \begin{enumerate}
	  \item $ f $ has finitely many discontinuities.
	  \item $ f $ has finitely many local maxima and minima.
  \end{enumerate}
  Then for each $ \theta\in[0,1) $ we have
  \begin{align*}
	  \frac{\theta_++\theta_-}2 &= \lim_{n\to \infty}(S_Nf)(\theta)\\
				    &= \sum_n\hat f_n e^{2\pi in\theta/L}
  \end{align*}
where $ f(\theta_\pm) = \lim_{\varepsilon\to 0^+}f(\theta \pm \varepsilon) $. So at the points of continuity the Fourier series gives back the original function, and at points of discontunity the Fourier series gives back the average of the function at the disconunity neighbourhood.
\end{proposition}
We call functions which properties (i) and (ii) Dirichlet functions. For now on assume all functions are Dirichlet functions so that $ \sim $ means that the series on the RHS coincides with the function on the LHS at points of continuity and to the average at points of discontinuity.\par
\pf We'll prove the proposition only for functions in $ C^\infty(\R) $ (actually $ C^1(\R) $ will do.\\
Assume \textit{wlog} that $ L=2\pi $. Examine $ \lim S_Nf(\theta_0) $ for some $ \theta_0\in[0,2\pi) $. By replacing $ f(\theta) $ with $ f(\theta+\theta_0) $ can assume that $ \theta_0=0 $ \textit{wlog}.
\begin{align*}
	(S_Nf)(\theta)&=\sum_{|n|\le N}\hat f_ne^{in\cdot \theta} \\
		      &= \sum_{|n|\le N}\left(\frac{1}{2\pi}\int_{-\pi}^\pi f(\theta)e^{-in\theta}\mathrm d\theta\right)\\
		 &= \frac{1}{2\pi}\int_{-\pi}^\pi f(\theta)\left[\sum_{|n|\le N}e^{-in\theta}\right]\mathrm d\theta
\end{align*}
We can sum the series as a geometric series, so
\begin{align*}
	e^{-iN\theta}\sum_{n=0}^{2N}e^{-in\theta}=\frac{\sin[(N+\frac 12)\theta]}{\sin(\frac{\theta}{2})}
\end{align*}
when $ \theta\in \R\setminus2\pi\Z $ and the sum is $ 2N+1 $ when $ \theta\in2\pi\Z $.\\
Define the \textit{Dirichlet Kernal} as
\[
  D_N(\theta)=\begin{cases}
	  \frac{\sin[(N+\frac 12)\theta]}{\sin(\frac\theta 2)} & \theta\in \R\setminus 2\pi \Z \\
	  2N+1 & \text{otherwise}
  \end{cases}
\]
For each $ N\ge 0 $,
\begin{enumerate}
	\item $ D_N $ is continiuous, even $ 2\pi $ perioidic
	\item $ \int_{-\pi}^\pi D_N(\theta)\mathrm d\theta=2\pi $
\end{enumerate}
Property $ (ii) $ follows by intergrating $ \sum $ termwise, only $ 1 $ is non-zero. This means that
\[
	f(0)=\frac 1{2\pi}\int_{-\pi}^\pi D_N(\theta)f(\theta)\mathrm d\theta
\]
So
\[
	S_N(f)(0)=f(0)=\frac 1{2\pi}\int_{-\pi}^\pi D_N(\theta)[f(\theta)-f(0)]\mathrm d\theta
\]
now set $ F(\theta)=\frac{\theta}{\sin(\frac \theta 2)}\left[\frac{f(\theta)-f(0)}\theta\right] $
	so we get 
	\[
		(S_Nf)(0)=\frac 1{2\pi}\int_{-\pi}^\pi \sin[(N+\frac 12)\theta]F(\theta)\mathrm d\theta
	\]
	Note that $ \theta\to F(\theta) $ is smooth since
	\[
		\frac{f(\theta)-f(0)}{\theta}=\frac 1\theta\int_0^\theta f'(t)\mathrm dt=\frac 1\theta \int_0^1 f'(\tau\theta)\theta\mathrm d\tau
	\]
	Hence integrating by parts gives that
\begin{align*}
	(S_Nf)(0)-f(0)&=\frac{1}{N+\frac 12}\frac{1}{2\pi}\int_{-\pi}^\pi \cos[(N+\frac 12)\theta]F'(\theta)\mathrm d\theta \\
	&\to 0 \text{ as } N\to \infty
\end{align*}
For an example consider the function
\[
  f(\theta)=\begin{cases}
	  +1 & 0\le \theta < \pi \\
	  -1 & -\pi \le \theta < 0
  \end{cases}
\]
Since $ f $ is odd, $ a_n=0 $ for each $ n $ and
\begin{align*}
	b_n&=\frac{2}{2\pi}\int_{-\pi}^\pi f(\theta)\sin(n\theta)\mathrm d\theta \\
	   &= \frac 2\pi \int_0^\pi \sin(n\theta)\mathrm d\theta\\
	   &= \frac 2{n\pi}[1-(-1)^n]
\end{align*}
Thus
\[
	f(\theta)\sim \frac 4\pi \sum_{n \text{ odd}} \frac{\sin(n\theta)}n
\]
\subsection{Peridoic extensions: Cosine and sine series}
Given a function $ f:[0,L)\to \C $ we can define $ 2L $-periodic even/odd extensions called $ f_{even},f_{odd} $. Define,
\[
	f_{even}(\theta)=\begin{cases}
		f(\theta) & \theta\in[0,L)\\
		f(-\theta) & \theta\in[-L,0)\\
	\end{cases}
\]
and\[ 
f_{odd}(\theta)=\begin{cases}
		f(\theta) & \theta\in[0,L)\\
		-f(-\theta) & \theta\in[-L,0)\\
	\end{cases}
\].
Note that $ f(\theta)=f_{even}(\theta)=f_{odd}(\theta) $ if $ \theta\in [0,L) $.
\begin{align*}
	f_{even}(\theta)&\sim \frac 12 A_0+\sum_{n=1}^\infty A_n\cos\left(\frac{2\pi n \theta}{2L}\right)
	\\
	A_n&=\frac2{2L}\int_{-L}^Lf_{even}(\theta)cos\left(\frac{2\pi n\theta}{2L}\right)\mathrm d\theta\\
	   &= \frac 2L\int_0^Lf(\theta)cos\left(\frac{2\pi\theta}L\right)\mathrm d\theta
\end{align*}
simiarly we have that 
\begin{align*}
	f_{odd}(\theta)&\sim\sum_{n=1}^\infty B_n\sin\left(\frac{2\pi n\theta}{2L}\right)\\
	B_n&=\frac 2L\int_0^Lf(\theta)\sin\left(\frac{n\pi\theta}L\right)\mathrm d\theta
\end{align*}
\begin{definition}
	For $ f: [0,L)\to \C $ define its \textit{cosine} and \textit{sine} series by
	\begin{align*}
		\frac{1}2 A_0+\sum_{n=1}^\infty A_n\cos\left(\frac{n\pi\theta}L\right),\quad \sum_{n=1}^\infty B_n\sin\left(\frac{n\pi\theta}L\right)
	\end{align*}
	where $ A_n $ and $ B_n $ defined as before.
\end{definition}
For an example consider $ f(\theta)=1 $ on $ [0,\pi) $. For the sine series,
\begin{align*}
	B_n=\frac 2\pi \int_0^\pi \sin(n\theta)\mathrm d\theta=\frac2{n\pi}(1-(-1)^n)
\end{align*}
On the interval $ (0,\pi) $ we get that $ 1=f(\theta)=f_{odd}(\theta)=4\sum_{n\in \N}\frac{\sin(n\theta)}{n\pi} $. Whereas for the cosine series we get that 
\[
A_0=2,\quad A_n=0\quad n\ge 1
\]
So for $ \theta\in[0,\pi) $ we get that $ f_{even}=\frac 12\cdot 2 =1 =f(\theta) $.
\subsection{Regularity and decay of Fourier coefficients}
A true but non-examinable fact is that if $ g:[a,b]\to \C $ is integrable on $ [a,b] $ and $ \lambda\in \R $ then 
\[
	\int_a^be^{-i\lambda\theta}g(\theta)\mathrm d\theta\to 0 \text{ as } |\lambda|\to \infty. 
\]
IF $ f:\R\to \C $ is a $ L $-periodic function and integrable on $ [0,L) $ then
\begin{align*}
	\hat f = \frac 1L\int_0^Le^{-2\pi i n \theta/L}f(\theta)\mathrm d{\theta}
\end{align*}
so taking $ \lambda=\frac{2\pi n}L $ gives that $ \hat f_n\to 0 $ as $ n\to \infty $ by the Riemann-Lebesgue lemma. Also\[
a_n=\hat f_n+\hat f_{-n} \quad b_n=i(\hat f_n -\hat f_{-n}),\] 
both go to zero as $ n\to \infty $.\par
Suppose that $ f $ is $ L $-periodic and $ f\in C^k(\R) $.
\begin{align*}
	\hat f_n&=\frac 1L\int_0^Le^{-2\pi in\theta/L}f(\theta)\mathrm d\theta\\
		&=-\frac 1L\left(\frac{L}{2\pi in}\right)f(\theta)e^{-2\pi in\theta/L}\mathhuge|^L_{\theta=0}+\left(\frac{L}{2\pi in}\right)\frac 1L \int_0^Le^{-2\pi i n \theta/L}f'(\theta)\mathrm d\theta \\
		&= -\frac{L}{2\pi in}\left[\frac{f(L^-)-f(0^+)}L\right]+\frac{L}{2\pi in}\frac 1L\int_0^Le^{-2\pi in \theta}f'(\theta)\mathrm d\theta
\end{align*}
Since $ f $ is periodic and continuously differentiable we have that 
\[
  f(0^+)=f(L^+)=f(L^-)
\]
hence the boundary term cancels so repeating we get that 
\[
	\hat f_n=\left(\frac{L}{2\pi in}\right)^k\frac 1L\int_0^Le^{-2\pi in\theta/L}f^{(k)}(\theta)\mathrm d\theta
\]
and the integral is $ o(1) $ by the Rieman-Lebesgue lemma.\par
So we get that if $ f $ is $ C^k(\R) $ then $ \hat f_n = o\left(\frac 1{n^k}\right) $ as $ |n|\to \infty $.
\subsection{Termwise differentiation}
Suppose $ f $ is $ L $-periodic continuously differentiable on $ [0,L) $ with $ f'=g $ thne $ g $ is continuous on $ [0,L) $ so
\begin{align*}
	\hat g_n&=\frac 1L\int_0^Le^{-2\pi in\theta/L}f'(\theta)\mathrm d\theta\\
		&=\frac{f(L^-)-f(0^+)}L+\left(\frac{2\pi in}{L}\right)\frac 1L\int_0^Le^{-2\pi in\theta/L}f(\theta)\mathrm d\theta
\end{align*}
If $ f $ is continuous on $ \R $ then by periodicity we have that 
\begin{align*}
  f(0^+)=f(L^+)=f(L^-)
\end{align*}
so that 
\[
	\hat g_n=\left(\frac{2\pi in}L\right)\hat f_n
\]
i.e.
\[
	f'(\theta)=g(\theta)\sim \sum_n\left(\frac{2\pi in}L\right)\hat f_ne^{2\pi in\theta/L}
\]
\subsection{Parseval's theorem}
	If we have that \[f(\theta)\sim \sum_n\hat f_n e_n(\theta) \]
	and
	\[
	  g(\theta)\sim \sum_n\hat g_n e_n(\theta)
	\]
	then taking the inner product of both function we get that
	\begin{align*}
		\langle f,g\rangle &= \sum_{n,m}\hat f_n\overline{\hat g_n}\langle e_n,e_m\rangle\\
				   &= L\sum_n\hat f_n \overline{\hat g_n}
	\end{align*}
	finally that
	\begin{align*}
		\frac 1L\int_0^L f(\theta)\overline{g(\theta)}\mathrm d\theta=\sum_n \hat f_n \overline{\hat g_n}
	\end{align*}
	 and when $ f $ and $ g $ are the same we get that
	 \[
	   \frac 1L\int_0^L|f(\theta)|^2\mathrm d\theta=\sum_n|\hat f_n|^2
	 \]
	 \section{Sturm-Liouville Theory}
	 \subsection{Abstract eigenvalues problem}
	 Recall from IA Vectors and Matrices that a linear map $ A:V_N\to V_n $ was called \textit{Hermitian} if $ A^\dagger = A $ or equivalently we have that
	 \[
	   \mathbf x \cdot(A\mathbf y)=(A\mathbf x)\cdot \mathbf x
	 \]
	 for all $ \mathbf x,\mathbf y\in V_N $.\par
	 They had properties where all eigenvalues are real, eigenvectors with distinct eigenvalues were orthogonal, and that we could pick an porthogonal set of eigenvectors $ \{\mathbf v_i\}^N_{i=1} $ such that for each $ \mathbf x\in V_n $ we have that
	 \[
		 \mathbf x = \sum_{i=1}^N\hat{\mathbf x}_i\mathbf v_i
	 \]
	 where
	 \[
		 \hat{\mathbf x}_i=\frac{\mathbf x\cdot \mathbf y}{|\mathbf v_i|^2}.
	 \]
	 But now we're in $ N=\infty $, we can't assume everything we've learnt so far.\par
	 Use a vector space of nice functions, $ f:[a,b]\to \C $ with an inner product
	 \[
		 \langle f,g\rangle_w=\int_a^bf(x)\overline{g(x)}w(x)\mathrm dx.
	 \]
	 where $ w $ is real valued and $ w>0 $ on $ (a,b) $. We call $ w $ the \textit{weight function} associated with the inner product. This gives an associated norm
	 \[
		 ||f||=\sqrt{\langle f,f\rangle_w}
	 \]
	 when $ w(x)=1 $ we just write $ \langle \cdot, \cdot \rangle $.
	 \begin{definition}
		 (Self-adjoint) A linear differential operator, $ L $, is said to be \textit{self-adjoint} on $ (V,\langle \cdot,\cdot\rangle_w) $ if
		 \[
		   \langle Ly_1,y_2\rangle_w=\langle y_1,Ly_2\rangle_w\quad\forall y_1,y_2\in V.
		 \]
	 \end{definition}
	 \begin{definition}
		 (Eigenfunction/value) For $ (y,\lambda) \in (V\setminus\{0\}\times \C $ is an \textit{eigenfunction, eigenvalue} pair for $ L $ if $ Ly=\lambda y $.
	 \end{definition}
	 \begin{proposition}
	  If $ L $ is self-adjoint on $ (V,\langle \cdot,\cdot,\rangle_w) $ then:
	  \begin{enumerate}
		  \item Eigenvalues are real,
		  \item eigenfunctions with distinct eigenvalues are orthogonal,
		  \item there exists a complete orthogonal set of eigenfunctions $ \{y_n\}_{n=1}^\infty $ i.e. for each $ f \in V $ we can write,
			  \[
				  f=\sum_{n=1}^\infty \hat f_ny_n
			  \]
			  where
			  \[
				  \hat f_n=\frac{\langle f, y_n\rangle_w}{||y_n||_w^2}
			  \]
	  \end{enumerate}
	 \end{proposition}
	 \pf (For (i)) If $ Ly=\lambda y $ with $ y\ne 0 $ then
	 \begin{align*}
		 (\lambda-\overline\lambda)||y||_w^2&=\langle \lambda y,y\rangle_w-\langle y,\lambda y\rangle_w \\
						    &= \langle Ly, y\rangle_w - \langle y,Ly\rangle_w \\
						    &= 0 \implies \lambda = \overline \lambda
	 \end{align*}
	 (For (ii)) If $ Ly_1=\lambda_1y_1, Ly_2=\lambda_2y_2 $ with $ \lambda_1\ne \lambda_2 $,
	 \begin{align*}
		 (\lambda_1-\lambda_2)\langle y_1,y_2\rangle_w &= \langle \lambda_1y_1,y_2\rangle_w-\langle y_1,\lambda_2y_2\rangle _w\\
							       &= \langle Ly_1,y_2\rangle - \langle y_1,Ly_2\rangle_w \\
							       &= 0 \implies \langle y_1,y_2\rangle_w=0
	 \end{align*}
	 The third statement is too hard to prove for this course.\qed
\par
We will study problems of the form
\begin{align}
  \begin{cases}
	  Ly=\lambda y a<x<b \\
	  y \text{ satisfies some boundary conditions at } x=a,b
  \end{cases}
\end{align}
\begin{definition}
	(Sturm-Liouville operator) We say that $ L $ is a \textit{Sturm-Liouville operator} on $ (a,b) $ if it has the form
	\begin{align*}
		L&=\frac 1w\left[-\frac{\mathrm d}{\mathrm d x}\left(p\frac{\mathrm d \mathhuge\cdot}{\mathrm dx}\right)+q\mathhuge\cdot\right]\\
		 &= \frac 1w\left[-p\frac{\mathrm d^2\mathhuge \cdot}{\mathrm dx^2}-p^2\frac{\mathrm d \mathhuge \cdot}{\mathrm dx}+q\mathhuge\cdot\right]
		\end{align*}
		where $ p,q,w $ are real valued and $ p,w>0 $ on $ (a,b) $. We call $ w $ the \textit{weight function}.
\end{definition}
See that $ Ly=\lambda y $ is equvialent to
\[
	-\frac{\mathrm d}{\mathrm dx}\left(p\frac{\mathrm dy}{\mathrm dx}\right)+qy=\lambda wy\quad a<x<b.
\]
We will enforce boundary conditions by stipulating that $ y $ belongs to a suitable vector space of functions that appropriate behaviour at the boundaries.
\begin{definition}
	(Singular) For a Sturm-Liiouville operator on $ (a,b) $ say an endpoint $ c\in \{a,b\} $ is \textit{singular} if $ p(c)=0 $ and \textit{non-singular} otherwise. 
\end{definition}
We will impose real homogeneous boundary conditions of the form
\[
	c\in \{a,b\}\quad \alpha_cy(c)+\beta_cy'(c)=0
\]
at each non-singular endpoint, :w
for $ \alpha_c,\beta_c\in \R $ and $ \alpha_c^2+\beta_c^2\ne 0 $.\par
We will work on generic vector spaces of the form
\[
	V=\mathhuge{\{}
	  y\in C^2[a,b]: y \text{ satisfies real homogeneous boundary conditions at each non-singular endpoint }
  \mathhuge{\}}
\]
Let's look at the example
\[
	-\frac{\mathrm d}{\mathrm dx}\left[(1-x^2)\frac{\mathrm dy}{\mathrm dx}\right]=\lambda y\quad -1<x< 1.
\]
So we have that $ p=(1-x^2),q=0,w=1 $. Then $ x=\pm 1 $ both singular. Take $ V=\{y\in C^2[a,b]\} $ then
\[
	\langle f,g\rangle_w=\int_{-1}^1f(x)\overline{g(x)}\mathrm dx.
\]
\begin{proposition}
	If $ L $ is a Sturm-Lionville operator on $ (a,b)  $ with weight function $ w $ then if $ y_1,y_0\in C^2[a,b] $ we have that 
	\[
		\langle Ly_1,y_2\rangle_w-\langle y_1,Ly_2\rangle_w=p(x)W(y_1,\overline{y_2})(x)\mathhuge{|}^b_a
	\]
	where $ W $ is the Wronskian.
\end{proposition}
So if $ y_1,y_2\in V $ then $ L $ is self-adjoint on $ (V,\langle\cdot,\cdot\rangle_w) $.\par
\pf
\begin{align*}
	&\int_a^b\frac 1w\left[-(py')'+qy_1\right]\bar{y_2}w\mathrm dx-\int_a^by_1\frac 1w\left[-(p\bar{y_2})'+q\bar{y_2}\right]w\mathrm dx\\
&= \int_a^b\left[y_1(p\bar{y_2})'-\bar{y_2}(py'_1)'\right]\mathrm dx\\
	&= \int_a^b\frac{\mathrm d}{\mathrm dx}\left[p(x)W(y_1,\bar{y_2})(x)\right]\mathrm dx\\
	&= p(x)W(y_1,\bar{y_2})(x)\mathhuge{|}_a^b.
\end{align*}
Now assume that $ y_1,y_2\in V $. If $ x=c \in \{a,b\} $ is singular then $ p(c)=0 $ hence $ p(c)W(y_1,\bar {y_2})(c)=0 $. If $ c\in \{a,b\} $ non-singular then $ y_1,y_2 $ satisfy boundary conditions of the form
\[
  \alpha_cy(c)+\beta_cy'(c)=0,\quad \alpha_c,\beta_c\in \R, \alpha_c^2+\beta_c^2\ne 0.
\]
Since $ \alpha_c,\beta_c\in \R $ we know that $ \bar y $ also satisfies the same boundary conditions hence
\[
  \begin{pmatrix}
	  y_1(c) & y'_1(c) \\
	  \bar{y_2}(c) & \bar{y_2}'(c) \\
  \end{pmatrix}
  \begin{pmatrix}
    \alpha_c \\
    \beta_c \\
  \end{pmatrix}
  =0
\]
So the determinate of the matrix on the left is zero because $ \alpha_c $ and $ \beta_c $ don't both equal zero hence $ W(y_1,\bar y_2)(c) = \det(\cdots)=0 $ Hence we have that
 \begin{align*}
   \langle Ly_1,y_2\rangle_w-\langle y_1,Ly_2\rangle_w=0
 \end{align*}
 for all $ y_1,y_2\in V $.\qed
 \subsection{Sturm-Lioville Eigenvalue problems}
 We'll be studying problems of the form
 \[
	 -\frac{\mathrm d}{\mathrm dx}\left[p\frac{\mathrm dy}{\mathrm dx}\right] + qy = \lambda y\quad y\in V
 \]
 where
 \[
	 V=\left\{y\in C^2[a,b]:y\text{ satisfies real homogeneous BCs at each non-ingular end point} \right\}
 \]
 Equip $ V $ with an inner product with a weight function as before. Assume elements of $ V $ are real-valued \textit{wlog} since if $ y=u+iv $ and $ Ly=\lambda y $ then we can split up into
 \[
   Lu=\lambda u, \quad Lv=\lambda v
 \]
 since $ p,q,w,\lambda\in \R $. So
 \[
	 \langle y_1,y_2\rangle_w=\int_a^by_1(x)y_2(x)\mathrm dx.
 \]
 Since $ L $ is self-adjoint, we know there exists $ (y_n,\lambda_n)\in (V\setminus \{0\})\times \R $ such that $ Ly_n=\lambda_ny_n $ with $ \langle y_n,y_m\rangle_w=0 $ if $ \lambda_n\ne \lambda_m $ and for $ f\in V $ we have
 \begin{align*}
	 f(x)&=\sum_{n=1}^\infty \hat f_n y_n(x)\\
	 \hat f_n&=\frac{\langle f,y_n\rangle_w}{||y_n||^2_w}
 \end{align*}
 are the generalised Fourier coefficients of $ f $. It will also be the cases that $ \lambda_1<\lambda_2<\cdots $ with $ \lambda_n\to \infty $ as $ n\to \infty $. Let's look at an example. Take
 \[
   \begin{cases}
	   -y''=\lambda y & 0<x<L \\
	   y(0)=y(L)=0
   \end{cases}
 \]
 so $ p=w=1 $ and $ q=0 $ and $ V=\{y\in C^2[0,L]: y(0)=y(L)=0\} $.\par
 Solving $ y''+\lambda y= 0 $ then $ y=A\sin(\sqrt{\lambda}x)+B\cos(\sqrt{\lambda}x) $. If $ \lambda\le 0 $ we only get the trivial solution, so we must have that $ \lambda>0 $. If we use $ y(0)=0\implies B=0 $ and $ y(L)=0\implies A\sin(\sqrt{\lambda}L)=0 $ so other than the trivial solution, we have that
 \[
	 \sqrt\lambda = \frac{n\pi}L,\quad n=1,2,\dots
 \]
 So
 \[
	 \lambda = \left(\frac{n\pi}L\right)^2,\quad y_n(x)=\sin\left(\frac{n\pi x}L\right).
 \]
We can see that $ \lambda_n\to \infty $ and $ \lambda_1<\lambda_2<\cdots $ and
\begin{align*}
	\langle y_n,y_m\rangle &= \int_0^L\sin\left(\frac{n\pi x}L\right)\sin\left(\frac{m\pi x}L\right)\mathrm dx \\
			       &= \frac L2\delta_{nm}
\end{align*}
For $ f\in V $,
\begin{align*}
	f(x)&=\sum_{n=1}^\infty \hat f_n\sin\left(\frac{n\pi x}L\right)\\
	\hat f_n&=\frac{\langle f,y_n\rangle}{||y_n||^2}\\
		&= \frac 2L\int_0^Lf(x)\sin\left(\frac{n\pi x}L\right)\mathrm dx
\end{align*}
We have re-derived the Fourier sine series from the previous section.
\subsection{Reduction to Sturn-Lionville form}
Consider a general eigenvalue problem of the form
\begin{align*}
	\alpha(x)\frac{\mathrm d^2y}{\mathrm dx^2}+\beta(x)\frac{\mathrm dy}{\mathrm dx}+\gamma(x)y+\lambda y=0
\end{align*}
with $ \alpha(x)>0 $. Divide the equation by $ \alpha(x) $ and multiply by
\[
	I(x)=\exp\left[\int^x\frac{\beta(t)}{\alpha(t)}\mathrm dt\right]
\]
\begin{proposition}
  The equation
  \[
    \alpha(x)\frac{\mathrm d^2y}{\mathrm dx^2}+\beta(x)\frac{\mathrm dy}{\mathrm dx}+\gamma(x)y+\lambda y=0
  \]
  is equivalent to
  \[
	  -\frac{\mathrm d}{\mathrm dx}\left[p\frac{\mathrm dy}{\mathrm dx}\right] + qy=\lambda wy
  \]
  where
  \begin{enumerate}
	  \item $ p(x)=I(x) $,
	  \item $ q(x)=-\frac{I(x)\gamma(x)}{\alpha(x)} $,
	  \item $ w(x)=\frac{I(x)}{\alpha(x)} $.
  \end{enumerate}
\end{proposition}
\pf 
\begin{align*}
  -\frac{\mathrm d}{\mathrm dx}\left[p\frac{\mathrm dy}{\mathrm dx}\right] + qy-\lambda wy &= I\left[-\frac{\mathrm d^2y}{\mathrm dx^2}-\frac{\beta(x)}{\alpha(x)}\frac{\mathrm dy}{\mathrm dx}-\frac{\gamma(x)}{\alpha(x)}y-\frac{\lambda y}{\alpha(x)}\right]\\
\end{align*}
since $ I>0 $ we get that the equation is zero if and only if $ LHS=0 $.\qed\par
For an example consider
\begin{align*}
  \begin{cases}
	  y''=2y'+\lambda y= 0 & 0<x<1\\
	  y(0)=y'(1)=0
  \end{cases}
\end{align*}
So we have that 
\[
	I(x)=\exp\left[\int^x -\frac 21\right]=e^{-2x}
\]
So the ODE becomes
\[
	-\frac{\mathrm d}{\mathrm dx}\left[e^{-2x}\frac{\mathrm dy}{\mathrm dx}\right]=\lambda e^{-2x}y.
\]
So we get $ e^{-2x} $ as our weight function.\par
To solve put $ y\propto e^{-\alpha x} \implies \alpha=1\pm\sqrt{1-\lambda} $ So if $ \lambda \ne 1 $ we'll get solutions of the form
\[
	y=e^x\left[Ae^{x\sqrt{1-\lambda}}+Be^{-x\sqrt{1-\lambda}}\right]
\]
We need $ 1-\lambda < 0 $ for non-trivial solutions.\par
We can see $ y(0=0\implies B=0 $ and $ y'(1)=0\implies Ae\left[\sin \mu+\mu\cos\mu\right]=0 $ where $ \mu^2=\lambda -1 $ and $ \mu>0 $ \textit{wlog}. So $ \tan\mu=-\mu $. By plotting the graph we can see we have infinitely many solutions for the equation. Call $ \mu_1,\mu_2,\dots $ so we have $ \lambda_n=1+\mu_n^2 $. From the graph we have that $ \mu_n\to\infty $ hence $ \lambda_n\to \infty $. The corresponding eigenfunctions are
\[
	y_n(x)=e^x\sin(\mu_nx),\quad n=1,2,\dots
\]
Check that $ \langle y_n,y_m\rangle\propto \delta_{nm} $. For $ n\ne m $
\begin{align*}
	\langle y_n,y_m\rangle_w &= \int_0^1e^x\sin(\mu_n x)e^x\sin(\mu_m x)e^{-2x}\mathrm dx\\
				 &= \int_0^1 \sin(\mu_n x)\sin(\mu_m x)\mathrm dx\\
				 &=\frac 12\int_0^1\left[\cos((\mu_n-\mu_m)x)-cos((\mu_n+\mu_m)x)\right]\mathrm dx\\
				 &\quad\vdots\\
				 &= 0
\end{align*}
(ommitting a large amount of the algebra.)
\subsection{Legendre's Equation}
Consider an eigenvalue problem defined as
\[
	-\frac{\mathrm d}{\mathrm dx}\left[(1-x^2)\frac{\mathrm d y}{\mathrm dx}\right]=\lambda y\quad -1<x<1
\]
So $ p=1-x^2 $, $ q=0 $, $ w=1 $. Since both endpoints are singular, work on $ V=C^2[-1,1] $. Since $ x=0 $ is a regular point we can look for solutions in the form
\[
	y=\sum_{n=0}^\infty a_nx^n.
\]
By subbing in, we get that
\[
	a_{n+2}=\left[\frac{n(n+1)-\lambda}{(n+1)(n+2)}\right]a_n
\]
Which gives two linearly independent solutions.
\begin{align*}
	y_0&=a_0 \left[1+\frac{(-\lambda)x^2}{2!}+\frac{(-\lambda)(6-\lambda)x^3}{4!}+\cdots\right]\\
	y_1&=a_1 \left[x+\frac{(2-\lambda)x^3}{3!}+\frac{(2-\lambda)(12-\lambda)x^5}{5!}+\cdots\right].
\end{align*}
Note that $ y_0 $ collapses if $ \lambda=0,6 $. In general if $ \lambda=k(k+1) $ for $ k=0,1,2,\dots $ either $ y_0 $ or $ y_1 $ gives a polynomial. What if $ \lambda\ne k(k+1) $? Since the ratio $\left|\frac{a_{n+2}}{a_n}\right|\to 1 $ we know that both series will converge on $ |x|<1 $. This doesn't tell us about $ y(\pm 1) $. Let's look at $ y_0 $ only, $ y_1 $ is treated similiar. Let $ A_n=a_{2n} $, so
\[
	\frac{A_n}{A_{n+1}}=\frac{(2n+1)(2n+2)}{2n(2n+1)-\lambda}=1+\frac 1n+\varepsilon_n
\]
where $ |\varepsilon_n|\le M/n^2 $, $ M=M(\lambda)>0 $. In particular the RHS true for $ n $ sufficiently large, say $ n\ge N $. So $ \{A_n\} $ have the same sign for $ n\ge N $. Using $ e^x > 1+x $ for all $ x\in \R $ we get that
\begin{align*}
	\frac{|A_n|}{|A_{n+1}|}&\le e^{1/n}+|\varepsilon_n|\\
	\implies |A_{n+1}|&\ge \frac{e^{-1/n}|A_n|}{1+e^{-1/n}|\varepsilon_n|}\\
	\ge \frac{e^{-1/n}|A_n|}{1+|\varepsilon_n|}&\ge e^{-1/n}|A_n|e^{-|2n}
\end{align*}
So for $ n\ge N $ we can repeat to get that
\[
	|A_{n+1}|\ge |A_n|\exp\left[-\left(\frac 1n+ \frac 1{n-1}+\cdots + \frac 1N\right)-\left(|\varepsilon_n|+\cdots + |\varepsilon_N|\right)\right]
\]
hence we have that
\begin{align*}
	|A_{n+1}|\ge |A_N|e^{-H_n+H_{N-1}}e^{-M\pi^2/6}.
\end{align*}
Since $ H_n\le \log n +2\gamma $
\begin{align*}
	|A_{n+1}|&\ge |A_N|e^{H_{N-1}-M\pi^2/6}e^{-\log n-2\gamma}\\
		 &> \frac{c}{n+1}
\end{align*}
Hence we have that
\begin{align*}
	y_0=\sum_{n\le N }A_nx^{2n}+\sum_{n>N}A_nx^{2n}
\end{align*}
and since $ \{A_n\} $ have the same sign, assume all positive \textit{wlog}. Note that
\begin{align*}
	\sum_{n>N}A_nx^{2n}&>c\sum_{n=1}^\infty\frac{x^{2n}}n-\sum_{n\le N}\frac{x^{2n}}n.\\
			   &=C\left[\log\left(\frac1{1-x^2}\right)-\text{ (some polynomial in x)}\right]\to \infty\quad \text{as }x\to \pm 1.
\end{align*}
So $ y_0\notin V $ so we must have that $ \lambda_k=k(k+1) $. This gives an even polynomial of degree $ k $ from $ y_0 $. Make normalisation so $ y(1)=1 $ choosing $ a_0 $ and $ a_1 $ accordingly then the solutions are called Legendre polynomials.
\subsection{Bessel's Equation}
Fix an integer $ n\ge 0 $. Consider the eigenvalue problem
\[
	-\frac{\mathrm d}{\mathrm dr}\left[r\frac{\mathrm dy}{\mathrm dx}\right]+\frac {m^2}ry=\lambda ry
\]
with $ 0<r<1 $ and $ y(1)=0 $. We have $ p=r,q=\frac{m^2}r,w=r $. Expanding out derivatives gives that
\[
  r^2y''+ry'+(\lambda r^2-m^2)y=0.
\]\smallskip
Set $ z=\sqrt{\lambda}r $ (we can show that $ \lambda>0 $). Set $ R(z)=y(r) $. This gives that
\[
	z^2R''+zR'+(z^2-m^2)R=0 \quad 0<z<\sqrt{\lambda}, R(\sqrt{\lambda})=0
\].
This is \textit{Bessel's equation of order} $ m $.
Since $ x=0 $ is a regular singular point, get can get solutions in the form \[
	z\to z^\sigma\sum_{n=0}^\infty a_nz^n
\]
by Fuch's theorem. We get two linearly independent solutions only one of which is non-singular as $ z\to 0 $. Label the cooresponding solution $ R=J_m(z) $. We can show that
\[
	J_m(z)=\left(\frac z2\right)^m\sum_{n=0}^\infty\frac{(-1)^n}{n!(n+m)!}\left(\frac z2\right)^{2n}.
\]
These are \textit{Bessel functions of the first kind} of order $ m $. We can show that $ J_n(z) $ has infinitely many zeros on the $ z $ axis, we label them $ j_{mk} $. Since we require that $ J_m(\sqrt{\lambda})=0 $, solutions to the equation are
\[
	y_k(r)=J_m(j_{mk}r),\quad \lambda_k=j_{mk}^2
\]
for $ k=1,2,3,\dots $
\subsection{Inhomogeneous Problems}
Let $ L $ be a Sturm-Liouville operator. Consider problems of the form
\begin{align*}
	\text{find } y\in V : Ly=f\in V.
\end{align*}
\textit{wlog}, $ w=1 $. Let $ \{y_k\} $ be normalised eigenfunctions of $ L $. Be completeness we can write that
\begin{align*}
	y&=\sum A_ky_K,\quad f=\sum B_ky_k\\
	 &\implies \sum_{k=1}^\infty (\lambda_kA_k-B_k)y_k=0\\
	 &\implies \lambda_kA_k=B_k\quad k=0,1,2,\dots
\end{align*}
So if $ \lambda_k\ne 0 $, $ A_k=B_k/\lambda_k $, we get have
\[
	y(x)=\sum_{k=1}^\infty\frac{B_k}{\lambda_k}y_k(x),\quad B_k=\int_a^bf(\xi)y_k(\xi)\mathrm d\xi
\]
Putting the $ B_k $ into $ y $ and changing sums and integrals we get that
\[
	y(x)=\int_a^bG(x;\xi)f(\xi)\mathrm d\xi
\]
where
\[
	G(x;\xi)=\sum_{k=1}^\infty\frac{y_k(\xi)y_k(x)}{\lambda_k}
\]
is called the Green's function.
\section{Linear PDEs and Seperation of Variables}
\subsection{Superposition}
We will be interested in solving boundary value problems (BVP) and initial boundary value problems (IBVP)
\[
	(\dagger) \begin{cases}
	  P\psi(\mathbf x)=0&\mathbf x\in\Omega\\
	  \text{some B.Cs} & \mathbf x\in\partial\Omega
  \end{cases}
\]
\[
	(\dagger\dagger) \begin{cases}
		Q\phi(\mathbf x,t)=0&(\mathbf x,t)\in \Omega\times (0,T)\\
		\text{some I.Cs} & (\mathbf x,t)\in \Omega\times\{t=0\}\\
		\text{some B.Cs} & (\mathbf x,t)\in\partial\Omega\times (0,T)
	\end{cases}
\]
where $ P,Q $ are \textit{linear} partial differentiable operators and $ \Omega $ will be bounded on an open subset of $ \R^n $ for $ n=1,2,3 $.
\begin{remark}
  We can split $ (\dagger\dagger) $ into
  \[
    \begin{cases}
	    Q\phi_1(\mathbf x,t)=0 \quad Q\phi_2(\mathbf x,t)=0 & (\mathbf x,t)\in\cdots \\
	    \text{I.Cs} =0 \quad \text{ some I.Cs} & \vdots \\
	    \text{Some B.Cs} \quad \text{B.Cs} = & (\mathbf x,t)\in \cdots 
    \end{cases}
  \]
\end{remark}
In this course, $ \Omega $ will always be (possibly after a change of variables) a line/rectangle/cuboid. So \textit{wlog} we can always deal with B.Cs that are zero everywhere apart from on one endpoint/edge/face. For example
\[
	(\dagger\dagger\dagger)=\begin{cases}
		P\psi(\mathbf x)=0& \mathbf x\in (0,1)\times (0,1) \\
		\psi = f_1 & \text{ on side }i\text{ for } i = 1,2,3,4
	\end{cases}
\]
We could look at 4 problems for $ \{\psi_i\}_{i=1}^4 $
\[
  \begin{cases}
	  P\psi_i(\mathbf x)=0 & \mathbf x\in (0,1)\times (0,1) \\
	  \psi_i=0 & \text{on side } \ne i \\
	  \psi_i=f_i & \text{on side } = i
  \end{cases}
\]
Then $ \psi=\psi_1+\cdots+\psi_4 $ solves $ (\dagger\dagger\dagger) $.
\subsection{Laplace's Equation}
Recall for $ \varphi:\R^n\to \R $, Laplace's equation is
\[
  \Delta \varphi = 0
\]
where $ \Delta=\nabla\cdot\nabla=\nabla^2 $. So on the Cartesian coordinates,
\[
	\Delta = \frac{\partial^2}{\partial x^2}+\cdots + \frac{\partial^2}{\partial z^2}.
\]
We say that $ \varphi $ is \textit{harmonic} if $ \Delta\varphi=0 $. Harmonic functions are always infinitely differentiable. Let's look at an example.\par
If $ \mathbf u:\R^3\to \R^3 $ is the velocity of an incompressible fluid (so $ \nabla\cdot \mathbf u=0 $) that is irrotational, i.e. $ \nabla\times \mathbf u = 0 $ then we can solve Laplace's equation. Since $ \mathbf u $ is irrotational on the whole of $ \R^3 $ there exists a scalar potential such that $ \mathbf u =\nabla \varphi $. Then $ \Delta\varphi=\nabla\cdot(\nabla \varphi)=\nabla\cdot\mathbf u= 0$.\par
We will consider  BVPs of the following
\[
  \begin{cases}
	  \Delta\varphi(\mathbf x)=0&\mathbf x \in \Omega\\
	  B\varphi=f(\mathbf x)& \mathbf x \in \partial\Omega
  \end{cases}
\]
where $ B\varphi\equiv \varphi $ (Dirichlet) or $ B\varphi=\frac{\partial \varphi}{\partial \mathbf n} $ (Neumann), or even $ B\varphi = \varphi + \frac{\partial \varphi}{\partial\mathbf n} $ (Robin).
\subsubsection{Serpation of variables on the square}
Consider
\[
  \begin{cases}
	  \varphi_{xx}+\varphi_{yy}=0 & (x,y)\in(0,1)\times (0,1) \\
	  \varphi(x,y)=0 & \text{on } x=0,x=1,y=0\\
	  \varphi(x,1)=f(x) & \text{otherwise}
  \end{cases}
\]
Try a separable solution of the form $ \varphi=X(x)Y(y) $. Then we get that
\[
  X''(x)Y(y)+X(x)Y''(y)=0.
\]
Dividing through by $ XY $ gives that
\begin{align*}
	\frac{X''(x)}{X(x)}+\frac{Y''(y)}{Y(y)}=0,
\end{align*}
hence there exists a $ \lambda\in\R $ such that
\[
	\frac{X''}X = -\lambda,\quad \frac{Y''}Y=\lambda.
\]
Since $ \varphi=0 $ at $ x=0,1 $ looking just at the $ X $-equation we get that
\[
  \begin{cases}
	  X''+\lambda X=0 & 0< x< 1\\
	  X(0)=0\\
	  X(1)=0
  \end{cases}.
\]
This is a Sturm-Liouville problem. So there exists $ (X_n,\lambda_n)^\infty_{n=1} $ solutions with $ \lambda_1<\lambda_2<\cdots $ and $ \langle X_n,X_m\rangle=\int_0^1X_n(x)X_m(x)\mathrm dx\propto \delta_{nm} $.\par
We check that we require $ \lambda>0 $ for non-trivial solutions. General solutions are
\[
	X(x)=A\sin(\sqrt{\lambda}x)+B\cos(\sqrt{\lambda}x)
\]
with $ X(0)=0\implies B=0 $ and $ X(1)=0\implies A\sin(\sqrt{\lambda})=0\implies \lambda=\lambda_n=(n\pi)^2 $. So we get that $ X_n(x)=\sin(n\pi x) $ with eigenvalues $ \lambda_n=(n\pi)^2 $ and that $ \langle X_n,X_m\rangle =\frac 12\delta_{nm} $. The $ Y $ problem becomes $ Y''-(n\pi)^2Y=0 $ with $ Y(0)=0 $ which gives that
\[
  Y=A\sinh(n\pi y)+B\cosh(n\pi y).
\]
Now $ Y(0)=0\implies B=0 $, so $ Y_n(y)=A_n\sinh(n\pi y) $. So we have functions $ \{\varphi_n\}_{n=1}^\infty $ with
\[
  \varphi_n(x,y)=A_n\sin(n\pi x)\sinh(n\pi y)
\]
and each satisfies $ \Delta\varphi_n=0 $ in $ (0,1)\times (0,1) $ and $ \varphi_n=0 $ on $ x=0,x=1,y=0 $. So same is true for their sum
\[
	\varphi(x,y)=\sum_{n=1}^\infty A_n\sin(n\pi x)\sinh(n\pi y).
\]
We still want that $ \varphi(x,1)=f(x) $ so we set
\[
	f(x)=\sum_{n=1}^\infty A_n\sin(n\pi x)\sinh(n\pi)
\]
we need to find the $ A_n $s to use get equality.\par
By orthogonality
\begin{align*}
	\langle f,X_n\rangle &= \sum_{n=0}^\infty A_n{\langle X_n,X_m\rangle}\sinh(m\pi)\\
	&= \frac{A_n}2\sinh(n\pi)
\end{align*}
So our final solution is
\[
	\varphi(x,y)=\sum_{n=1}^\infty A_n\sin(n\pi x)\sinh(n\pi y)
\]
where
\[
	A_n &=\frac 2{\sinh(n\pi)}\langle f,X_n\rangle\\
	    &= \frac2{\sinh(n\pi)}\int_0^1f(x)\sin(n\pi x)\mathrm dx
\]
\subsubsection{Seperation of variables in a disc/annulus}
We want to solve Laplace's equation in the region $ r_1<|\mathbf x|<r_2 $ in the $ (x,y) $ plane. Use plane polar coordinates $ (r,\theta) $ so that Laplace's equation becomes
\[
	\Delta\varphi=\frac 1r\frac{\partial}{\partial r}\left(r\frac{\partial\varphi}{\partial r}\right)+\frac1{r^2}\frac{\partial ^2 \varphi}{\partial \theta^2}=0.
\]
Look for seperable solutions in the form $ \varphi=R(r)\Theta(\theta) $. So
\[
	\frac{r(rR')'}R+\frac{\Theta''}\Theta=0
\]
so there exists a $ \lambda\in \R $ such that
\begin{align*}
	r(rR')' &= \lambda R\\
	\Theta'' + \lambda \Theta = 0.
\end{align*}
The solution to the $ \Theta $-equation is going to be
\[
  \Theta(\theta)=\begin{cases}
	  A\cos(\sqrt\lambda\theta) + B\sin(\sqrt\lambda\theta) & \lambda >0 \\
	  A\theta +B & \lambda =0 \\
	  A\cosh(\sqrt\lambda\theta) + B\sinh(\sqrt\lambda\theta) & \lambda <0
  \end{cases}.
\]
We need $ \Theta(\theta+2\pi)=\Theta(\theta) $ for all $ \theta $. This forces $ \Theta $ to be a constant or $ \lambda>0 $ with $ \lambda = n^2 $ for $ n\in \N \cup \{0\} $. So
\begin{align*}
	\Theta_0(\theta)&=A\\
	\Theta_n(\theta)&=C_n\cos(n\theta)+D_n\sin(n\theta)
\end{align*}
Plug $ \lambda=n^2 $ into the $ R $-equation. So
\begin{align*}
  r(rR')'=n^2R
\end{align*}
For $ n=0 $ we have that $ rR' $ is constant, integrating gives that
\[
  R_0(r)=A+B\log r.
\]
And for $ n>0 $ we try a solution in the form $ R(r)=r^\alpha $. Plugging this gives that $ \alpha^2=n^2 $ so $ \alpha=\pm n $,
\[
	R_n(r)=A_nr^n+B_nr^{-n}
\]
so we have the general solution
\[
	\varphi(r,\theta)=A+B\log r+\sum_{r=1}^\infty\left[A_nr^n+B_nr^{-n}\right]\left[C_n\cos(n\theta)+D_n\sin(n\theta)\right].
\]
If the point $ r=0 $ belongs to our domain we have to throw out the $ r^{-n} $ and $ \log r $ terms since they're not defined. So we must take $ B=B_n=0 $ for each $ n $.\par
Let's see an example.\\
Solve
\[
  \Delta\varphi=0\quad r_1<r<r_2
\]
with $ \varphi=0 $ on $ r=r_1 $ and $ \varphi=f(\theta) $ on $ r=r_2 $. We can repeat analysis but require $ R_n(r)=0 $ where $ r=r_1 $ for $ n=0,1,2,\dots $. Then $ R_0(r)=\log\left(\frac rr_1\right) $ and $ R(r)=\left(\frac r{r_1}\right)^n-\left(\frac{r_1}r\right)^n $ to get solutions of the form
\[
	\varphi(r,\theta)=C_0\log\left(\frac r{r_1}\right)+\sum_{n=1}^\infty \left[\left(\frac r{r_1}\right)^n-\left(\frac{r_1}r\right)\right]\left[A_n\cos(n\theta)+B_n\sin(n\theta)\right].
\]
The boundary condition $ r=r_2 $ gives that
\[
	f(\theta)=C_0\log\left(\frac {r_2}{r_1}\right)+\sum_{n=1}^\infty \left[\left(\frac {r_2}{r_1}\right)^n-\left(\frac{r_1}{r_2}\right)\right]\left[A_n\cos(n\theta)+B_n\sin(n\theta)\right].
\]
which can be written as
\[
	f(\theta)=\frac 1na_0+\sum_{n=0}^\infty \left[ a_n\cos(n\theta) + b_n\sin(n\theta)\right]
\]
i.e. the right hand side should be a Fourier series for $ f $. So $ a_n $ and $ b_n $ are given by
\begin{align*}
	a_n&=\frac 1\pi\int_0^{2\pi} f(\theta)\cos(n\theta)\mathrm d\theta \\
	b_n&= \frac 1\pi\int_0^{2\pi} f(\theta)\sin(n\theta)\mathrm d\theta.
\end{align*}
For a more general problem, where $ \varphi $ takes the values of a function $ g(\theta) $ on the interior $ r=r_1 $, we write that $ \varphi=\varphi_1+\varphi_2 $ where $ \varphi_i=0 $ on $ r_i $ and use superposition to split our task up for two Fourier series computations.
\subsubsection{Seperation of variables on a ball/shell (anti-symmetric case)}
We want to solve $ \Delta\varphi=0 $ in the region $ a<|\mathbf x|<b  $ in $ \R^3 $ but under the restriction that the problem is symmetric about the $ z $-axis. We'll work in spherical polar coordinates, so
\begin{align*}
	\frac 1{r^2}\frac\partial{\partial r}\left[r^2\frac{\partial \varphi}{\partial r}\right]+\frac 1{r^2\sin\theta}\frac{\partial}{\partial \theta}\left[\sin\theta\frac{\partial \varphi}{\partial\theta}\right]+\frac{1}{r^2\sin^2\theta}\frac{\partial^2\varphi}{\partial \phi^2}=0.
\end{align*}
Here the last term vanishes using symmetry about the $ z $-axis. Look for a solution in the form $ \varphi=R(r)\Theta(\theta) $ so
\[
	\frac{[r^2R']'}R+\frac1 {\Theta\sin\theta}[\sin\theta\cdot\theta']'=0
\]
so there exists a $ \lambda\in\R $ such that
\begin{align*}
	[r^2R']'=\lambda R-[\sin\theta\cdot \Theta']'=\lambda\sin\theta\cdot\Theta
\end{align*}
which then can be solved using the techniques discussed earlier.
\subsection{Wave Equation}
Consider a taut string, under constant tension $ \tau $ clamped at ends $ x=0 $ and $ x=L $. Let $ y =y(x,t)$ denote vertical displacement of the string. Assume that oscillations are transverse and that the slope $ |y_x|\ll 1 $. Note that
\begin{align*}
|y(x,t)|&=\left|\int_0^x y_x(s,t)\mathrm ds\right|\\
	&\le \int_0^L |y_x|\mathrm ds \ll 1.
\end{align*}
Take a diagram of a string with tension $ \tau $ arcing upwards. Let there be two points $ x_A $ and $ x_B $ with midpoint $ x $. Let $ \theta_A $ and $ \theta_B $ be the subtended angles from the string to the horizontal respectively. Then resolving forces horizontally we get that (given no transverse motion) that
\[
  \tau\cos\theta_B-\tau\cos\theta_A=0.
\]
This is consistant since that $ \tan\theta_A=\left(\frac{\partial y}{\partial x}\right)_A $ so we get that $ \cos\theta_A=\frac1{\sqrt{1+(\frac{\partial y}{\partial x})_A^2}}\approx 1 $. Also the mass of the string is proportional to its length so
\[
	\int_{x_A}^{x_B}\mathrm ds=\int_{x_A}^{x_B}\sqrt{1+y_x^2}\mathrm dx\approx \delta x.
\]
So reasonable to assume that mass is $ \mu\delta x $ where $ \mu>0 $ is density. Resolving vertically and using Newton's second law gives that
\[
	\frac{\mu\delta x}{\tau}\frac{\partial^2y}{\partial x^2}=\frac{\tau\sin\theta_B}{\tau\cos\theta_B}-\frac{\tau\sin\theta_A}{\tau\cos\theta_A}=\left(\frac{\partial y}{\partial x}\right)_B-\left(\frac{\partial y}{\partial x}\right)_A.
\]
Divide by $ \tau $ to ge that $ \tau=\tau\cos\theta_A=\tau\cos\theta_B $ to leading order. Hence by MVT we get that
\[
	\frac{\mu}\tau\delta x\frac{\partial ^2y}{\partial^2t}=\frac{\partial^2y}{\partial x^2}\delta x.
\]
where the first partial is evaluated at $ x $ and the second is evaluated at some $ \xi\in (x_A,x_B) $. Divide by $ \delta x $ and take $ \delta x\to 0 $ and $ \xi\to x $ giving that 
\[
	\frac 1{c^2}\frac{\partial^2y}{\partial t^2}=\frac{\partial ^2y}{\partial x^2},\quad c^2=\frac \tau\mu.
\]
call $ c $ the wave speed. We have boundary conditions given by $ y(0,t)=y(L,t)=0 $ and Newton's second law gives initial conditions that $ y(x,0)=f(x) $ and $ y_t(x,0)=g(x) $.
\subsubsection{Waves on a string}
Solve IBVP
\[
  \begin{cases}
	  y_tt -c^2y_xx=0 & (x,t)=(0,L)\times (0,\infty) \\
	  y(0,t)=0 & t\in (0,\infty) \\
	  y(L,t)=0 & t\in (0,\infty)\\
	  y(x,0)=f(x) & x\in (0,L) \\
	  y_t(x,0)=g(x) & x\in (0,L)
  \end{cases}
\]
Try a solution in the form $ y=X(x)T(t) $ with $ X(0)=0 $ and $ X(L)=0 $. We get that
\[
	\frac{\ddot{T}}{c^2T}=\frac{X''}X
\]
so there must exists some $ \lambda\in \R $ such that we have that
\begin{align*}
  X''+\lambda X=0\\
  X(0)=X(L)=0
\end{align*}
and
\begin{align*}
  \ddot T+\lambda c^2T=0.
\end{align*}
The solutions to the $ X $ equation is a S-L problem, which has known solutions with
\[
	X_n(x)=\sin(\frac{n\pi x}L),\quad \lambda_n=\left(\frac{n\pi}L\right)^2,\quad n=1,2,\dots
\]
The $ T $-equation becomes
\[
	\ddot T+\left(\frac{n\pi c}L\right)^2T=0
\]
which we solve as
\[
	T_n(t)=A_n\cos(\frac{n\pi ct}L)+B_n\sin(\frac{n\pi ct}L)
\]
so by superposition,
\begin{align*}
	y(x,t)=\sum_{n=1}^\infty \sin(\frac{n\pi x}L)\left[A_n\cos(\frac{n\pi ct}L)+B_n\sin(\frac{n\pi ct}L)\right]
\end{align*}
solves the wave equation with $ y(0,t)=y(L,t)=0 $. The initial conditions gives that
\[
	f(x)=\sum_{n=1}^\infty A_n\sin(\frac{n\pi x}L),\quad g(x)=\sum_{n=1}^\infty \left(\frac{n\pi c}L\right)B_n\sin(\frac{n\pi x}L).
\]
which look like the sine series. By orthogonality $ \langle X_n,X_m\rangle=\frac L2\delta_{nm} $, so
\begin{align*}
	A_n&=\frac 2L\int_0^Lf(x)\sin(\frac{n\pi x}L)\mathrm dx\\
	B_n&=\left(\frac{L}{n\pi c}\right)\frac 2L\int_0^Lg(x)\sin(\frac{n\pi x}L)\mathrm dx
\end{align*}
\subsubsection{Waves on a drum}
The higher dimensional analogue of the wave equation is
\[
	\frac 1{c^2}\frac{\partial^2\varphi}{\partial t^2}=\Delta \varphi
\]
Solving the IBVP on a drum,
\[
	\Omega=\{(r,\theta): 0\le r < 1, 0\le \theta < 2\pi\}
\]
\[
  \begin{align}
	  \varphi_{tt}-c^2\Delta \varphi=0 & \Omega\times (0,\infty)\\
	  \varphi=0 & \partial\Omega\times(0,\infty)\\
	  \varphi=f & \Omega\times{t=0}\\
	  \varphi_t=g & \Omega\times {t=0}
  \end{align}
\]
For simplicity assume that $ f=f(r) $, $ g=g(r) $. So that $ \varphi=\varphi(r,t) $. Wave equation becomes
\begin{align*}
	\frac 1{c^2}\frac{\partial^2 \varphi}{\partial t^2}=\frac 1r\frac{\partial}{\partial r}\left(r\frac{\partial \varphi}{\partial r}\right)+\frac1{r^2}\frac{\partial^2 \varphi}{\partial \theta^2}.
\end{align*}
Where the last term is zero since the solution is independent of $ \theta $. So we can try a solution in the form $ \varphi=R(r)T(t) $. Hence
\[
	\frac{\ddot T}{c^2 T}=\frac{[rR']'}{rR}.
\]
So there exists a $ \lambda\in \R $ such that
\begin{align*}
	-\frac{\mathrm d}{\mathrm dr}\left[r\frac{\mathrm R}{\mathrm r}\right]&= \lambda rR \qquad 0<r < 1, R(1)=0\\
	\ddot T+c^2\lambda T &= 0.
\end{align*}
So the $ R $-equation is the Bessel problem with $ m=0 $. This gives solutions
\[
	R_k(r)=J_0(j_{0k}r),\quad\lambda_k=j_{0k}^2.
\]
The $ T $-equation becomes
\[
	\ddot T+(cj_{0k})^2T=0
\]
so we get a solution in the form
\[
	\varphi(r,t)=\sum_{k=1}^\infty J_0(j_{0k}r)\left[A_k\cos(j_{0k}ct)+B_k\sin(j_{0k}ct)\right]
\]
which solves the PDE and boundary conditions. The initial conditions are
\begin{align*}
	f(r)=\sum_{k=1}^\infty A_kJ_0(j_{0k}r)\\
	g(r)=\sum_{k=1}^\infty B_kj_{0k}cJ_0(j_{0k}r)
\end{align*}
Recall that $ \langle R_k,R_\ell\rangle_w=\int_0^1 J_0(j_{0k}r)J_0(j_{0\ell r})r\mathrm dr = \frac 12 J_0'(j_{0k})^2\delta_{k\ell} $, so by orthogonality we get that
\begin{align*}
	A_k&=\frac 2{J_0'(j_{0k})}^2\int_0^1f(r)J(j_{0k}r)r\mathrm dr\\
		B_k&=\frac 2{J_0'(j_{0k})^2}\frac 1{cj_{0k}}\int_0^1g(r)J_0(j_{0k}r)r\mathrm dr
\end{align*}
\par
Missed Lecture - 03.11.25
\par
\subsection{The Heat Equation}
The temperature of a conductive material, $ \varphi(\mathbf x,t) $ satisfies the \textit{heat equation} which is
\[
	\frac{\partial \varphi}{\partial t}=\kappa\Delta\varphi
\]
where $ \kappa>0 $ is a constant. We are interested in the IBVP
\[
	(\dagger\dagger) \begin{cases}
	  \varphi_t-\kappa\Delta\varphi=0 & \Omega\times (0,\infty) \\
	  \varphi = 0 & \partial\Omega\times (0,\infty \\
	  \varphi = f & \Omega \times \{t=0\}
  \end{cases}.
\]
We'll try a solution in the form $ \varphi=T(t)\psi(\mathbf x) $. Plugging in, for some $ \mu \in \R $ we get that 
\[
  \dot T+\kappa\mu = 0
\]
and \[ -\Delta\psi = \mu \psi \].
We get that $ T(t)=e^{-\kappa\mu t} $. We can see that $ T $ does not vanish on the boundary (unless $ T $ is trivial), hence we can impose the vanishing boundary condition onto $ \psi $. So we're now solving
\[
  \begin{cases}
	  -\Delta\psi = \mu\psi & \mathbf x\in \Omega\\
	  \psi = 0 & \mathbf x\in \partial \Omega
  \end{cases}.
\]
Solutions to this depend on the geometry of $ \Omega $.
\subsubsection{Heat conduction on a square sheet}
Take $ \Omega=\{(x,y)\in (0,L)\times (0,L)\} $. Try a solution seperable in $ x $ and $ y $, $ \psi=X(x)Y(y) $. So we get that
\[
	\frac{X''}X+\frac{Y''}Y+\mu = 0.
\]
So there exists a $ \lambda\in \R $ such that $ X''+\lambda X=0 $ and $ Y''+(\mu-\lambda)Y=0 $. We also have the requirement that $ X(0)=X(L)=Y(0)=Y(L)=0 $. The $ X $-equation gives that
\[
	X_n(x)=\sin\left(\frac{n\pi x}L\right),\quad \lambda_n=\left(\frac{n\pi}L\right)^2
\]
and the $ Y $-equation gives that
\[
	Y=A\sin(y\sqrt{\mu-\lambda_n})+B\cos(y\sqrt{\mu-\lambda_n})
\]
So $ Y(0)=0\implies B=0 $ and $ Y(L)=0 $ gives that
\[
	\mu_{mn}-\lambda_n=\left(\frac{m\pi}L\right)^2
\]
so
\[
	Y_n(y)=\sin(\frac{m\pi y}L), \quad \mu_{mn}=\left(\frac{n\pi}L\right)^2+\left(\frac{m\pi}L\right)^2
\]
so by superposition we get that
\[
	\varphi(x,y,t)=\sum_{m,n=1}^\infty A_{mn}e^{-\kappa \mu_{mn}t}\sin(\frac{n\pi x}L)\sin(\frac{m\pi y}L)
\]
satisfies the heat equation and the boundary condition $ \varphi=0 $ on $ \partial \Omega $. Now to impose the initial condition,
\[
	f(x,y)=\sum_{n,m=1}^\infty A_{mn}\sin(\frac{n\pi x}L)\sin(\frac{m\pi y}L).
\]
So using $ \langle X_n,X_k\rangle =\frac 12 \delta_{nk} $ we get that
\[
	A_{mn}=\frac 4{L^2}\int_0^L\mathrm dx\int_0^L\mathrm dy f(x,y)\sin(\frac{n\pi x}L)\sin(\frac{m\pi y}L).
\]
\subsubsection{Heat flow down a pipe}
In cylindrical polars,
\[
	\Omega=\{(\rho,\phi,z):0\le \rho < 1, 0\le \phi<2\pi, 0<z<L\}
\]
Want to solve
\[
	(\dagger\dagger) \begin{cases}
	  \varphi_t-\kappa\Delta\varphi=0 & \Omega\times (0,\infty) \\
	  \varphi = 0 & \partial\Omega\times (0,\infty \\
	  \varphi = f & \Omega \times \{t=0\}
  \end{cases}.
\]
For simplicity we'll assume that $ f=f(\rho, z) $. We'll look for solutions $ \varphi=T(t)\psi(\rho,z) $. So
\begin{align*}
  &-\Delta\psi = \mu \varphi \\
	\implies &\frac 1\rho\frac{\partial}{\partial \rho}\left(\rho\frac{\partial \psi}{\partial \rho}\right)+\frac{\partial ^2 \psi}{\partial z^2}+\mu \psi=0
\end{align*}
We'll try $ \psi(\rho,z)=P(\rho)Z(z) $. So there exists a $ \lambda\in \R $ such that
\[
	-\frac 1{\rho P}[\rho P']'=\lambda,\quad Z''+(\mu-\lambda)Z=0.
\]
i.e.
\[
	-\frac{\mathrm d}{\mathrm d\rho}\left[\rho\frac{\mathrm dP}{\mathrm d\rho}\right]=\lambda\rho P\quad 0<p<1,\quad P(1)=0
\]
This is Bessel's problem with $ m=0 $.
\begin{align*}
	P_k(\rho)=J_0(j_{0k}\rho),\quad k=1,2,\dots\\
	\lambda_k=j_{0k}^2.
\end{align*}
This $ Z $-equation becomes
\begin{align*}
  Z''+(\mu-\lambda_k)Z=0,\quad Z(0)=Z(L)=0
\end{align*}
Hence we get that
\[
	Z_n(t)=\sin(\frac{n\pi z}L)
\]
with $ \mu_{kn}-\lambda_k=\left(\frac{n\pi}L\right)^2 $ for $ n=1,2,\dots $. By superposition we get that
\[
	\varphi(\rho,z,t)=\sum_{n,k=1}^\infty B_{nk}e^{-\kappa \mu_{kn}t}J_0(j_{0k}\rho)\sin(\frac{n\pi z}L)
\]
is a solution to the heat equation, and the boundary condition $ \varphi=0 $ on $ \partial \Omega $. For the initial conditions we need,
\[
	f(\rho,t)=\sum_{n,k=1}^\infty B_{nk}J_0(j_{0k}\rho)\sin(\frac{n\pi z}L).
\]
Recall that
\[
	\int_0^1J_0(j_{0k}\rho)J_0(j_{0\ell}\rho)\rho\mathrm d\rho=\frac 12J_0'(j_{0k})^2\delta_{k\ell}
\]
We get that
\[
	B_{nk}=\frac 4{LJ_0'(j_{0k})^2}\int_0^L\mathrm d\rho \int_0^L\mathrm dz\rho f(\rho z)J_0(j_{0k}\rho)\sin(\frac{n\pi z}L)
\]
\subsubsection{Heat loss and uniqueness}
Recall again our problem
\[
	(\dagger\dagger) \begin{cases}
	  \varphi_t-\kappa\Delta\varphi=0 & \Omega\times (0,\infty) \\
	  \varphi = 0 & \partial\Omega\times (0,\infty \\
	  \varphi = f & \Omega \times \{t=0\}
  \end{cases}.
\]
is the solution to $(\dagger\dagger) $ unique? Define the energy $ Q $ of the system as
\[
	Q(t)=\frac 12\int_\Omega \varphi(\mathbf x,t)^2\mathrm dV.
\]
Then
\begin{align*}
	Q'(t)&=\int_\Omega \varphi_t\varphi\mathrm dV\\
	     &=\int_\Omega \kappa\varphi\Delta\varphi\mathrm dV\\
	     &=\kappa\int_\Omega\left[\nabla\cdot(\varphi\nabla\varphi)-|\nabla\varphi|^2\right]\mathrm dV\\
	     &= \kappa\int_{\partial \Omega}\varphi\frac{\partial \varphi}{\partial \mathbf n}\mathrm dS-\kappa\int_\Omega|\nabla \varphi|^2\mathrm dV
\end{align*}
The first integral is zero by the boundary condition, and the second integral is clearly non-negative, so $ Q'(t)\le 0 $. So $ Q(t)\le Q(0)=\frac 12 \int_\Omega f(\mathbf x)^2\mathrm dV $.
\begin{proposition}
  The solution to the problem in $ (\dagger\dagger) $ is unique.
\end{proposition}
\pf Suppose $ \varphi_1,\varphi_2 $ satisfy $ (\dagger\dagger) $ and set $ \varphi=\varphi_1-\varphi_2 $. Then $ \varphi $ satisfies $ (\dagger\dagger) $ with $ f=0 $. So
\[
  \int_\Omega\varphi(\mathbf x,t)^2\mathrm dV \le Q(0)=0
\]
hence $ \varphi(\mathbf x,t)=0 $ on $ \Omega\times(0,\infty) $ hence $ \varphi_1=\varphi_2 $.\qed










\end{document}

